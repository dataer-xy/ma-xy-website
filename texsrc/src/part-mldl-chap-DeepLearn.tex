% % \part{机器学习与深度学习}
% % \chapter{深度学习}

\chapter{深度学习}
\section{深度置信网络DBN}
    \par
    Hinton于2006年首次提出深度置信网络(deep belief network, DBN)，从而引起了深度学习的热潮。之后，深度学习模型又发展出了深度玻尔兹曼机DBM、堆积自动编码器SAE、卷积神经网络CNN、用于语音和文本处理的RNN以及对抗生成网络GAN等等。在开发DBN之前，多层前向神经网络MLP往往只有3到4层的深度，太深的网络被认为是难以优化的，直到DBN出现后，在MNIST数据集上准确率超过(核)支持向量机，才使得深度网络开始得到认可。尽管DBN与其它深度网络相比，已经失去了研究者和工业开发者的青睐，我们还是应该标注一下，除了表示敬意之外，也可以由此开启深度学习之旅。顺带一提的是，深度学习工具有许多，并且它们的更新很快，所以后面大部分内容我们都只介绍深度模型的理论。同时，由于深度学习的发展速度很快，基本上是日新月异的，每天都有新成果、新应用，这使得我们想要全面学习它变得困难。我们不得不挑选一些具有里程碑意义的网络来进行介绍。
    \subsection{DBN网络结构}
        \par
        我们知道，限制玻尔兹曼机RBM是没有网络层次结构的，如果要将其分层，可以分为可视层$v$和隐含层$h$。基本的RBM网络结构如图(\ref{fig:RBM网络结构图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/RBM_net_structure.jpg}
            \caption{RBM网络结构图}
            \label{fig:RBM网络结构图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：RBM网络结构图}\\
        形式上有$v,h$两层。现在，我们考虑能否把多个RBM网络“堆积”在一起？虽然多个BP网路“堆积”而成MLP不易于训练，但是多个RBM堆积未必不可以训练，因为RBM网络的训练方式并不是基于反向传播算法的。
        \par
        我们先来将2个RBM堆积在一起，如图(\ref{fig:2个RBM堆积图})所示，其中：第一个$RBM_{1}$和隐含层$h^1$是第二个$RBM_{2}$的可见层，其权重为$W^1,W^2$。
\begin{figure}[H]
  \centering
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=3cm]{images/2RBM_accumulation1.jpg}
  \end{varwidth}
  \qquad\qquad
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=3cm]{images/2RBM_accumulation2.jpg}
  \end{varwidth}
  \caption{2个RBM堆积图}
  \label{fig:2个RBM堆积图}
\end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：2个RBM堆积图}\\
        图(\ref{fig:2个RBM堆积图})中的神经元连接方式是无向连接/双向连接的，并且不考虑阈值$b$。我们先训练$RBM_1$，当这个$RBM_1$收敛到数据集时，我们得到其权重$W^1$，并得到$RBM_1$的隐含层激活模式(样本/向量)。我们将每个隐含层激活模式作为数据集来训练第2个$RBM_2$。一个有趣的事情是：如果$v$中的神经元数目和$h^2$相等，那么我们训练完$RBM_2$得到$W^2$是$W^1$的转置，$RBM_2$可以是$h^1$的一个很好的模型。
        \par
        现在将底层$RBM_1$的权重改变一下，准确的说是将其连接方式改变一下，我们只保留$h^1\rightarrow v$方向上的权重，而不要$v\to h^1$方向的权重。这样，网络就变成了一个有向网络，如图(\ref{fig:2个RBM的右向网络图})(a)所示
\begin{figure}[H]
  \centering
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=4cm]{images/2RBM_right_net1.jpg}
  \end{varwidth}
  \qquad\qquad
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=4cm]{images/2RBM_right_net2.jpg}
  \end{varwidth}
  \caption{2个RBM的右向网络图}
  \label{fig:2个RBM的右向网络图}
\end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：2个RBM的右向网络图}\\
        至于为什么这样做，以后有机会再讨论。我们将其扩展到4层，如图(\ref{fig:2个RBM的右向网络图})(b)所示，只有在顶部的$RBM_3$中是真的双向连接，而在$RBM_2,RBM_1$中，只有下行权重，所以网络也不再是RBM网络了。它更像logistics置信网络(1992.Neal)，称这种由RBM和logistics置信网络混合的深度网络为深度置信网络DBN。
        \par
        下面，我们考虑如何运行DBN。以图(\ref{fig:2个RBM的右向网络图})(b)为示例，为了从这个模型中生成数据，或者说为了让这个模型来拟合样本的分布，首先，通过顶层$RBM _3$在$h^2,h^3$中进行热平衡采样，结束之后，就有了$h^2$。这里的$h^2$是$RBM_3$定义的$h^2$的先验分布，然后，将$h^2$通过权重$W^2$传递到$h^1$，无论$h^1$中得到什么样的二值状态，紧接着通过$W^1$传递给$v$，来得到生成数据。所以，我们执行一个从$h^2$开始自顶而下的传播，去得到其它各层的状态，就像在一个sigmoid置信网络中一样。
        \par
        现在，我们考虑一个深层的DBN，由$L$个RBM堆积而成，如图(\ref{fig:L层DBN示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/L_layer_DBN_illustration.jpg}
            \caption{L层DBN示意图}
            \label{fig:L层DBN示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：L层DBN示意图}\\
        图中共有$L$个RBM。整体来看，DBN有1个可视层$v$和$L$个隐含层$h^{(l)}(l=1,2,\dots,L)$，并且有$L$个权重矩阵$W^{(l)}(l=1,2,\dots,L)$，有$L+1$个阈值$b^{(l)}(l=0,1,\dots,L)$。其中：$b^{(0)}$是可视层$v$的偏置。 假设我们已经有了所有的权重$W = \{W^{(l)}\}$和阈值$b= \{b^{(l)}\}$，令$\theta\triangleq (W,b)$，于是有下面的概率公式
        \begin{align*}
        & p(h^{(L)},h^{(L-1)}) \propto \exp\left(b^{(L)}{}^\mathrm{T} h^{(L)} + b^{(L-1)}{}^\mathrm{T} h^{(l-1)} + h^{(L-1)}{}^\mathrm{T}W^{(L)}h^{(L)}\right)\\
        & p(h_i^{(l)}=1|h^{(l+1)}) = \sigma  \left( b_i^{(l)} + W_{\cdot i}^{(l+1)}{}^\mathrm{T}h^{(l+1)} \right)  \quad l=1,2,\dots,L-2\\
        & p(v_i = 1| h^{(1)}) = \sigma \left( b_i^{(0)}+W_{\cdot i}^{(1)}{}^\mathrm{T}h^{(1)} \right)
        \end{align*}
        \par
        如果$v$不是二值01，而是实值$v_i\in R$，可以用下式来是实现高斯RBM
        \begin{align*}
        v\sim N(v|b^{(0)}+ W^{(1)}{}^\mathrm{T}h^{(1)} ,\beta^-1)
        \end{align*}
        其中：$\beta$是协方差矩阵，是一个对角矩阵。这里我们不详细介绍高斯RBM。上面，我们说过从$h^3$开始，如何生成$v$，其联合概率分布为
        \begin{align*}
        p(v,h^1,h^2,\dots,h^L) = p(v|h^1)p(h^1|h^2)\cdots p(h^{L-2}|h^{L-1})p(h^{L-1}|h^{L})
        \end{align*}
        \par
        虽然是DBN，但是我们的目标仍然是求$\theta$使样本概率最大，即样本的似然函数最大。现在的问题是：样本$v$的概率是多少呢？

    \subsection{DBN学习算法}
        \par
        对于分类问题$x,y$，DBN的学习一般分为2个过程：
        \begin{enumerate}
        \item 使用无标签数据$x$(只用$x$，不用$y$)无监督的训练DBN。这里，关于无监督的训练DBN，可以采用2006.Hinton提出的贪心逐层算法，即对每一个RBM进行训练。在无监督训练DBN后，得到参数$\theta\triangleq (W,b)$。
        \item 使用有监督数据$x,y$进行$\theta$的微调。在无监督$\theta$的基础上，将$\theta$视为网络初始参数，将整个网络视为前向网络，用BP算法对网络权重$W$和阈值$b$进行微调。
        \end{enumerate}
        \par
        采用贪心逐层算法训练DBN是容易实现的，我们将DBN分为$L$个RBM，对每个RBM进行训练，并得到权重和阈值$W^{(l)},b^{(l)}$
        \begin{align*}
        & \mathbb{E} _{v\sim P_{data}} \log p(v)\\
        & \mathbb{ E}_{v\sim P_{data}} \mathbb{E}_{h^{(1)}\sim p^{(1)}(h^{(1)}|v)} \log p^{(2)}(h^{(2)})\\
        & \qquad \vdots
        \end{align*}
        其中：$p^{(1)}$是第一个RBM表示的的概率分布。在大多数应用中，对DBN进行贪心逐层训练后，需要再花费时间进行联合训练，训练好的DBN可以直接用于生成任务。如果要将其用于分类任务，我们可以将贪心算法求得的参数$\theta$作为网络参数的初始值，搭建如图(\ref{fig:DBN的权重微调网络})的多层前向神经网络MLP
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/DBN_Weighted_Micro_Transformation_Net.jpg}
            \caption{DBN的权重微调网络}
            \label{fig:DBN的权重微调网络}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：DBN的权重微调网络}\\
        并且
        \begin{align*}
        & h^{(1)} = \sigma \left( b^{(1)} + v^\mathrm{T}W^{(1)} \right) \\
        & h^{(l)} = \sigma \left( b_i^{(l)} + h^{(l+1)}{}^\mathrm{T} W^{(l)} \right) \quad l = 2,3,\dots,L
        \end{align*}
        然后，用BP等算法来对MLP 网络进行训练，微调其参数$\theta$。


\section{深度玻尔兹曼机DBM}
    \subsection{DBM网络结构}
        \par
        DBM(Deep Boltzmann Machine)是另一种深度\underline{生成模型}，由Salakhutdinov和Hinton于2009年开发。与DBM不同的是，它是一个完全无向的网络。以一个含有两个隐含层的DBM为例，其网络结构示意图如图(\ref{fig:3层DBM网络结构示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/3DBM_net_structure.jpg}
            \caption{3层DBM网络结构示意图}
            \label{fig:3层DBM网络结构示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：3层DBM网络结构示意图}\\
        DBM是一个基于能量的模型，这意味这模型中变量(神经元)的联合概率分布可以由能量函数表示：在参数$\theta$给定下，网络的能量函数(忽略偏置$b$)为
        \begin{align*}
        E_\theta(v,h^{(1)},h^{(2)}) = -v^\mathrm{T}W^{(1)}h^{(1)} - h^{(1)}{}^\mathrm{T} W^{(2)}h^{(2)}
        \end{align*}
        由此，网络的联合概率分布(Boltzmann分布)为
        \begin{align*}
        p(v,h^{(1)},h^{(2)}) = \frac{1}{Z_\theta} \exp \left( -E_\theta(v,h^{(1)},h^{(2)}) \right)
        \end{align*}
        \par
        与全连接的BM相比，DBM拥有一些和RBM相似的特点，比如：由于层内神经元无连接，联合概率分布等于边缘概率分布的乘积。对DBM而言，这种独立性表现在：在给定相邻层神经元的状态之后，可以写出中间层的条件概率分布。比如：对$h^{(1)}$层而言，相邻层$v,h^{(2)}$的神经元状态值给定后，$h^{(1)}$层内各神经元相互独立。于是，条件联合概率分布等于各分量条件分布的乘积
        \begin{align*}
        p \left( h^{(1)}|v,h^{(2)} \right)  = \prod _jp \left( h_j^{(1)}|v,h^{(2)} \right)
        \end{align*}
        而单一神经元$h_j$取值为0和1的概率值为
        \begin{align*}
        & p \left( h_j^{1}=1|v,h^{(2)} \right)  = \sigma \left( v^\mathrm{T}W_{\cdot i}^{(1)} + W_{i\cdot}^{(2)}h^{(2)} \right) \\
        & p \left( v_i=1|h^{(1)} \right)  = \sigma \left( W_{i\cdot}^{(1)}h^{(1)} \right) \\
        & p \left( h_k=1^{(2)}|h^{(1)} \right) = \sigma \left( h^{(1)}{}^\mathrm{T} W_{\cdot k}^{(2)} \right)
        \end{align*}
        \par
        上面说明$p(v|h^{(1)},p(h^{(1)}|v,h^{(2)}),p(h^{(2)}|h^{(1)})$是可以确定的。但是，$p(h^{(1)},h^{(2)}|v)$是不能确定的，或者说给定$v$后，$h^{(1)}$层和$h^{(2)}$层的各神经元之间不是独立的，因此，DBM可以看成是介于BM和RBM之间的网络。
        \par
        上述性质使得吉布斯采样能够在DBM中运行，吉布斯采样每次只更新一个神经元。由于我们给定一层$h^{(1)}$的邻层$v$和$h^{(2)}$后，$h^{(1)}$的概率也就确定了，那么，对于一个$L$层的DBM而言，可以将DBM分为两部分：奇数层和偶数层。给定偶数层，关于奇数层的分布是平衡的。因此，可以作为两部分同时且独立地采样。
        \par
        无论是DBN还是DBM，我们的目标都是求解参数$\theta$，使样本$S=\{v^k\}$出现的概率最大，即$\max_\theta P(S|\theta)$，可以简写为$\max_\theta P(S)$
        \begin{align*}
        P(S) = \prod_{k=1}^m p(v^k)
        \end{align*}
        上式取对数后，有
        \begin{align*}
        \max_\theta \ \ln L(\theta) = \log P(S) = \sum_{k=1}^m \log p(v^k)
        \end{align*}
        \par
        引入一个条件分布函数$q(h|v)$(在后面的VAE部分，我们会详细介绍EM算法和变分近似推断)，并且由于$\sum_hq(h|v) = 1$，有
        \begin{align*}
        \log p(v) &= \left( \sum_hq(h|v)  \right) \log p(v)\\
        &= \sum_h q(h,v)\log \frac{p(v,h)}{p(h|v)} \frac{q(h|v)}{q(h|v)}\\
        &=H(q) + \sum_hq(h|v) \log p(v,h) + \sum_hq(h|v)\log \frac{q(h|v)}{p(h|v)}\\
        &=\mathrm{KL}\Big(q(h|v)||p(h|v)\Big) + H(q) + \sum_h q(h|v) \left( \log p(h)+ \log p(v|h) \right)
        \end{align*}
        其中：$q(h|v)$可视为$p(h|v)$的近似函数
        \begin{align*}
        q(h|v) = q(h^1,h^2,\dots,h^L|v) \approx p(h^1,h^2,\dots,h^L|v) = p(h|v)
        \end{align*}
        于是
        \begin{align*}
        \log p(v)  \geqslant H(q) + \sum_hq(h|v) \Big( \log p(h) + \log p(v|h)\Big) =:L(q)
        \end{align*}
        当且仅当$p = q$时，上式等号成立。即$L(q)$是(单样本)对数极大似然函数$\ln p(v)$的下界。由于$p(h^1,h^2,\dots,h^L|v)$不易求解，所有原极大似然估计方法不易求解，我们转而求极大下界
        \begin{align*}
        \max_\theta  \ \sum_{k=1}^m L(q)
        \end{align*}
        由于$q$是一个函数，所以这是一个变分问题。
        \par
        我们通过一些简单的分布族来近似特定的目标函数$p(h|v)$，在具体的2个隐含层的DBM中，$p(h|v)$写为$p(h^{(1)},h^{(2)}|v)$。在均匀场近似的情况下，近似分布族是隐含层神经元条件独立的分布，即
        \begin{align*}
        q(h^{(1)},h^{(2)}|v) = \prod_{j} q(h_j^{(1)}|v) \prod_kq(h_k^{(2)}|v)
        \end{align*}
        均匀场近似的目标是着多最适合真实后验分布$p(h^{(1)},h^{(2)}|v)$的近似分布$q(h^{(1)},h^{(2)}|v)$。并且，每次使用新样本$v$后，必须再次运行推断过程，从新找到不同的分布$q$。我们可以找到许多衡量$q$和$p$近似程度的方法，均匀场方法是最小化二者的KL距离
        \begin{align*}
        \min_q \ \mathrm{KL}(q||p) = \sum_hq(h^{(1)},h^{(2)}|v) \log \left( \frac{q(h^{(1)},h^{(2)}|v)}{p( h^{(1)},h^{(2)}|v)} \right)
        \end{align*}
        将$q$作为伯努利分布的乘积进行参数化(对于泛函问题，我们一般采用参数化方法)，即将$h^{(1)}$的每个神经元的概率与一个参数相关联。具体来说对每个神经元$j$，$\hat{h}_j^{(1)} = q(h_j^{(1)}=1|v)$，其中：$\hat{h}_j^{(1)}\in [0,1]$。另外，对每个神经元$k$，$\hat{h}_k^{(2)} = q(h_K^{(2)}=1|v)$，其中：$\hat{h}_K^{(2)}\in [0,1]$。因此，我们有下面的近似后验
        \begin{align*}
        q(h^{(1)},h^{(2)}|v) & = \prod_{j} q(h_j^{(1)}|v) \prod_kq(h_k^{(2)}|v)\\
        & =\prod_j \left( \hat{h}_j^{(1)} \right) ^{h_j^{(1)}} \left( 1- \hat{h}_j^{(1)}\right) ^{1- h_j^{(1)}} \times  \prod_k \left( \hat{h}_k^{(2)} \right) ^{h_k^{(2)}} \left( 1- \hat{h}_k^{(2)}\right) ^{1- h_k^{(2)}}
        \end{align*}
        \par
        现在已经制定了近似分布$q$的函数族(即函数空间转化为参数空间)，下面的工作就是在参数空间中寻找最优的参数，来使$q$和$p$的KL距离最小。在之前的偏微分方程中，我们通过在样本点形成方程组来求解求解参数，这里用均匀场方程来指定参数，均匀场方程式通过求解变分下界导数为0的位置而推到出的。
        \begin{align*}
        L(q) & = \sum_{h^{(1)},h^{(2)}} q(h^{(1)},h^{(2)}|v) \log \left( \frac{p(v,h^{(1)},h^{(2)};\theta)}{q(h^{(1)},h^{(2)}|v)} \right) \\
        & = \sum_{h^{(1)},h^{(2)}} q(h^{(1)},h^{(2)}|v) E(v,h^{(1)},h^{(2)};\theta) - \log Z(\theta) + H(q)
        \end{align*}
        其中：$Z$是一个归一化因子，$H$为熵。我们希望求解$q(h^{(1)},h^{(2)}|v)$来最大化$L(q)$。将$q(h^{(1)},h^{(2)}|v)$带入到$L(q)$中，有
        \begin{align*}
        L(q) = \sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)} - \ln Z(\theta) + H(q)
        \end{align*}
        上式关于$\hat{h}_j^{(1)},\hat{h}_k^{(2)}$求导，令导数为0，得到拟合点方程为
        \begin{align*}
        & \frac{\partial }{\partial \hat{h}_j^{(1)}} L(q) = 0\quad j = 1,2,\dots,n\\
        & \frac{\partial }{\partial \hat{h}_k^{(2)}} L(q) = 0\quad k = 1,2,\dots,m
        \end{align*}
        \par
        我们来看其中的一个$\frac{\partial }{\partial \hat{h}_j^{(1)}} L(q)$
        \begin{align*}
        \frac{\partial }{\partial \hat{h}_j^{(1)}} L(q) &= \frac{\partial }{\partial \hat{h}_j^{(1)}} \left[ \sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)} - \ln Z(\theta) + H(q) \right]\\
        &= \frac{\partial }{\partial \hat{h}_j^{(1)}} \bigg[ \sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)} - \ln Z(\theta) \\
        &\qquad - \sum_j \left( \hat{h}_j^{(1)}\ln \hat{h}_j^{(1)} + (1-\hat{h}_j^{(1)}) \ln(1-\hat{h}_j^{(1)})  \right) \\
        &\qquad - \sum_k \left( \hat{h}_k^{(2)}\ln \hat{h}_k^{(2)} + (1-\hat{h}_k^{(2)}) \ln(1-\hat{h}_k^{(2)})  \right) \bigg]\\
        &=\sum_{i}v_iW_{ij}^{(1)}+\sum_kW_{jk}^{(2)}\hat{h}_k^{(2)} - \ln \left( \frac{\hat{h}_j^{(2)}}{1-\hat{h}_j^{(2)}} \right)
        \end{align*}
        令上式等于0，有
        \begin{align*}
        \hat{h}_j^{(1)}=\sigma \left( \sum_i v_i W_{ij}^{(1)} + \sum_kW_{jk}^{(2)}\hat{h}_k^{(2)} \right)
        \end{align*}
        同样处理$\frac{\partial }{\partial \hat{h}_k^{(2)}} L(q)$，有
        \begin{align*}
        \hat{h}_k^{(2)}=\sigma \left( \sum_jW_{jk}^{(2)}\hat{h}_j^{(1)} \right)
        \end{align*}
        综上，我们得到如下更新规则(不考虑偏置$b$)
        \begin{align*}
        & \hat{h}_j^{(1)}=\sigma \left( \sum_i v_i W_{ij}^{(1)} + \sum_kW_{jk}^{(2)}\hat{h}_k^{(2)} \right)\quad \forall j\\
        & \hat{h}_k^{(2)}=\sigma \left( \sum_jW_{jk}^{(2)}\hat{h}_j^{(1)} \right)\quad \forall k
        \end{align*}
        在该方程组的不动点(解)处，我们有变分下界$L(q)$ q的局部极大值。并且要注意的是，我们是交替更新$h_j^{(2)},h_k^{(2)}$。
    \subsection{DBM学习方法}
        \par
        在上面的分析中，给出了变分推断找到$p(h|v)$的近似$q(h|v)$，然后通过最大化$L(v,q,\theta)$来进行学习。对于有两个隐含层的DBM，目标函数$L$为
        \begin{align*}
        L(q,\theta) = \sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)} - \ln Z(\theta) + H(q)
        \end{align*}
        上述表达式中仍然包含配分函数(归一化因子)$Z(\theta)$。上面的$L(q,\theta)$是极大似然函数$p(v|\theta)$的下界，\underline{是一个函数$q$和参数$\theta$的函数}(这种情况我们在前面多次见到过)，我们希望通过最大化这个下边界来提高似然函数。我们考虑采用EM算法来实现最大化：E步，解$\hat{h}^{(1)}$和$\hat{h}^{(2)}$；M步，最大化参数$\theta$。前面的分析，我们仅考虑了E步求解$\hat{h}^{(1)}$和$\hat{h}^{(2)}$，下面，来求$\theta$使$L(q,\theta)$最大
        \begin{align*}
        \nabla _\theta L(q,\theta) & = \frac{\partial }{\partial \theta} \left(\sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)} - \ln Z(\theta) + H(q)\right) \\
        & = \frac{\partial }{\partial \theta} \left( \sum_i\sum_j v_iW_{i{j}}^{(1)}\hat{h}_j^{(1)} + \sum_j\sum_k\hat{h}_j^{(1)} W_{jk}^{(2)} \hat{h}_k^{(2)}  \right) -\frac{\partial }{\partial \theta} \ln Z(\theta)
        \end{align*}
        上式中的$\hat{h}^{(1)},\hat{h}^{(2)}$在E步中已经计算得到了，带入即可；关键是后面的$\frac{\partial Z(\theta)}{\partial \theta}$。通过随机极大化算法(SML)来进行求解，SML的伪代码如下(\ref{code:SML})
        \begin{algorithm}[htbp]
            \caption{SML for DBM two hidden layers}\label{code:SML}
            \begin{algorithmic}[1]
                \State 初始化：样本集$D_m = \{v^k\}_{k=1}^m$，$N$，初始权重$W^1,W^2$，容许误差$\varepsilon$，学习率$\eta$，Gibbs steps $N$，初始虚拟样本$\{\tilde{v},\tilde{h}^{(1)},\tilde{h}^{(2)}\}$(每个都是$m$行的随机矩阵)。
                \While {未达到停止准则}
                    \State $//$停止准则可以是最大迭代次数或者梯度$\Delta W < \varepsilon$。
                    \State 从样本集$D_m$中随机挑选$M_b$个样本的小批量$v = \left\{v^{(1)},v^{(2)},\dots,v^{(M_b)}\right\}$。
                    \State 初始化矩阵$\hat{h}^{(1)}$和$\hat{h}^{(2)}$。
                    \While {没有收敛(均匀场推断循环)}
                        \begin{align*}
                        & \hat{h}^{(1)} \leftarrow \sigma \left( vW^{(1)}+\hat{h}^{(2)}W^{(2)}{}^\mathrm{T} \right) \\
                        & \hat{h}^{(2)} \leftarrow \sigma \left( \hat{h}^{(1)}W^{(2)} \right)
                        \end{align*}
                    \EndWhile
                    \begin{align*}
                    & \Delta W^{(1)} \leftarrow \frac{1}{M_b} v^\mathrm{T} \hat{h}^{(1)}  \\
                    & \Delta W^{(2)} \leftarrow \frac{1}{M_b} \hat{h}^{(1)}{}^\mathrm{T} \hat{h}^{(2)}
                    \end{align*}
                    \For {$n \gets 0;n<N;n \gets n+1$(吉布斯采样) }
                        \State Gibbs block 1:
                        \begin{align*}
                        & \tilde{v}_{ij} \sim p(\tilde{v}_{ij} = 1 ) = \sigma \left( W_{j\cdot}^{(1)} \tilde{ h}_i^{(1)}{}^\mathrm{T} \right)  \quad \forall i,j \\
                        & \tilde{h}_{ij}^{(2)} \sim p(\tilde{h}_{ij}^{(2)} = 1 ) = \sigma \left( \tilde{ h}_i^{(1)} W_{\cdot j}^{(2)} \right)  \quad \forall i,j
                        \end{align*}
                        \State Gibbs block 2:
                        \begin{align*}
                        \tilde{h}_{ij}^{(1)} \sim p(\tilde{h}_{ij}^{(1)} = 1 ) = \sigma \left( \tilde{v}_i W_{\cdot j}^{(1)} + \tilde{ h}_i^{(2)} W_{\cdot j}^{(2)}{}^\mathrm{T} \right)  \quad \forall i,j
                        \end{align*}
                    \EndFor
                    \State 计算
                    \begin{align*}
                    & \Delta W^{(1)} \leftarrow \Delta W^{(1)} - \frac{1}{M_b}\sum_{t=1}^{M_b} v^\mathrm{T}\tilde{h}^{(1)}\\
                    & \Delta W^{(2)} \leftarrow \Delta W^{(2)} - \frac{1}{M_b}\sum_{t=1}^{M_b} \tilde{h}^{(1)}{}^\mathrm{T}\tilde{h}^{(2)}
                    \end{align*}
                    \State 更新权重
                    \begin{align*}
                    & W^{(1)} \leftarrow W^{(1)}  + \eta \Delta W^{(1)}\\
                    & W^{(2)} \leftarrow W^{(2)}  + \eta \Delta W^{(2)}
                    \end{align*}
                \EndWhile
                \State 输出：$W^{(1)},W^{(2)}$.
            \end{algorithmic}
        \end{algorithm}
    \subsection{DBM的预训练}
        \par
        不幸的是，随机初始化后使用SML(随机极大似然算法)的DBM通常是失败的。在某些情况下，DBM可以很好的表示分布，但是，它没有比仅使用RBM获得更高的似然值。目前，已经开发了一些联合训练技术，一般而言，克服DBM的联合训练问题最初的和最流行的方法是贪心逐层预训练技术。我们将DBM中的每两层视为一个RBM，进行预训练，在训练完成后，可以用PCD训练DBM。DBM的贪心逐层预训练方法与DBN不同，每个单独的RBM的参数可以直接复制到DBN，而在DBM中，RBM的参数在复制到DBM之前，必须进行修改。RBM仅使用自底向上的输入进行训练，但是在DBM中，某层(比如：$h^{(1)}$)将同时接受上层$h^{(2)}$和下层$v$的输入。为了解决这一问题，Salakhutdinov和Hinton(2009)提出：在将RBM堆积成DBM之前，将RBM的网络参数除以2(底部和顶部除外)。
        \subsubsection{生成式预训练}
            \par
            在DBN和DBM中，我们都有逐层预训练，都要将$L$个RBM单独训练，然后再组装成深度网络。其实RBM不是唯一可以预训练组装的模型，后面介绍的自动编码器及其变体也是可以堆积的，关于这一点，我们将在后面介绍。
        \subsubsection{监督式预训练}
            \par
            另外，无论是RBM还是AE，都是生成式预训练技术，还可以使用鉴别式预训练来鉴别性的初始化网络参数，例如：我们可以使用BP来确定权重。\ding{172}使用有标签样本数据$x,y$来训练第一个隐含层$h^{(1)}$，如图(\ref{fig:BP预训练示意图})(a)所示
\begin{figure}[H]
  \centering
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=4cm]{images/BP_pretraining1.jpg}
  \end{varwidth}
  \qquad\qquad
  \begin{varwidth}[t]{\textwidth}
    \vspace{0pt}
    \includegraphics[height=4cm]{images/BP_pretraining2.jpg}
  \end{varwidth}
  \caption{BP预训练示意图}
  \label{fig:BP预训练示意图}
\end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：BP预训练示意图}\\
            得到权重$W^{(1)}$；\ding{173}接着在$h^{(1)}$和输出层之间插入一个新的隐含层$h^{(2)}$，再用BP算法训练$v,h^{(1)},h^{(2)},y$，得到$W^{(2)}$；\ding{174}如此下去，知道插入$h^L$个隐含层，收敛后得到$W^{(L)}$。对于采用哪个$W^{(1)}$来进行\ding{173}的训练，我们可以：使用\ding{173}中训练的$W^{(2)}$，在堆积成DBM时不用此$W^{(2)}$；可以都采用\ding{173}中的$W^{(2)}$；可以采用\ding{172}中的$W^{(1)}$，在\ding{173}中不对$W^{(1)}$训练。
            \par
            逐层BP和逐层贪心算法相似，但在BP算法中，每次新的隐含层加入时，所有的层都联合更新，而在逐层贪心算法中，底层权重对上层权重一无所知，因而，大多数情况下，BP算法是较优的。然而，逐层BP有一个缺点：一些隐含层节点可能在训练收敛后处于饱和状态，因此，当新的隐含层加入训练时，很难进行更新。为了解决这个问题，我们可以是用数据的$\frac{1}{L}$来进行训练。
        \subsubsection{混合式预训练}
            \par
            前面提到过生成式预训练和监督式预训练，自然想到将二者合并。已经证明生成式预训练有助于训练深层结构。然而，随着深度的增加，鉴别式预训练同样表现的很好，甚至更好。混合预训练则要优于二者。我们已经注意到，当训练集足够大时，预训练就变得不那么重要了。
        \subsubsection{丢弃式预训练}
            \par
            可以把dropout视为通过随机丢弃神经元来减小DNN容量的方法，也可以把dropout视为一种打包技术，它可以对大量绑定参数的模型做平均，换句话所，与不适用dropout的DNN相比，dropout能够生成更加平滑的目标平面，与一个陡峭的目标平面相比，一个平滑的目标平面有较少的劣性局部最优点，这样，不容易陷入局部极小点。这启发我们可以使用dropout预训练快速找到一个较好的起始点，然后不用dropout来微调DNN。

    \subsection{高斯RBM}
        \par
        前面讨论的BM、RBM、DBN和DBM其输入数据都要求是01二值数据，并且网络中的神经元状态都是01随机变量，即伯努利分布。下面将介绍一些实值RBM，其概率取值不再是01，而是实值。
        \paragraph{高斯-伯努利RBM}在伯努利RBM中，条件概率$p(h|v),p(v|h)$定义为
        \begin{align*}
        & p(h|v) = \sigma (vW +a)\\
        & p(v|h) = \sigma (W^\mathrm{T}h+b)
        \end{align*}
        现在将$v$改为高斯分布，即
        \begin{align*}
        p(v|h) =N(v|Wh,\beta^{-1})
        \end{align*}
        其中：$\beta^{-1}$为协方差矩阵，是一个对角矩阵。注意，这里我们仅将$v$层改为高斯分布，$h$层仍为伯努利分布。对上面的分布取对数，有
        \begin{align*}
        \log N(v|Wh,\beta^{-1}) = -\frac{1}{2} (v-Wh)^\mathrm{T}\beta (v-Wh) + f(\beta)
        \end{align*}
        其中：$f$封装了所有参数，但不包含模型中的随机变量。我们可以忽略$f$，因为它唯一的作用是归一化分布。如果在能量函数中包含$\log N$中涉及到$v$的所有项，并且不添加其它涉及$v$的项，那么，我们的能量函数就能表示想要的条件分布$p(v|h)$。其它条件分布$p(h|v)$比较自由。注意到$\log N$中包含一项
        \begin{align*}
        \frac{1}{2} h^\mathrm{T}W^\mathrm{T}\beta Wh
        \end{align*}
        该项中已经包含$h_i,h_j$项，这一项不能被包含在其中，因为它对应着隐含层单元的边，如果包含这些项，将得到一个线性因子模型，而不是RBM。在RBM中，我们简略的去掉$h_i,h_j$的交叉项，并且忽略这些想不改变条件分布$p(v|h)$。如果我们使用精确地对角矩阵$\beta^{-1}$，会发现对于每个隐含层神经元$h_i$，有
        \begin{align*}
        \frac{1}{2}h_i \sum_j \beta_j W_{ji}^2
        \end{align*}
        \par
        如果在能量函数中包含此项，则当该单元的权重较大且以高进度连接到可见单元时，偏置$h_i$将自动关闭，是否包含该项不影响模型可以表示的分布族，但它会影响模型的学习动态，包含它可以帮助隐含层神经元保持合理激活。因此，在高斯-伯努利RBM中，能量函数定义为
        \begin{align*}
        E(v,h) = \frac{1}{2} v^\mathrm{T}(\beta \odot v) - (v\odot \beta)^\mathrm{T} Wh -a^\mathrm{T} h
        \end{align*}
        并且，我们还可以添加额外项。注意到，上面并没有在可视层$v$中添加偏置。关于如何确定$\beta^{-1}$，可以根据样本数据给出，也可以通过模型估计出。
    \subsubsection{条件协方差无向模型}
        \par
        虽然高斯RBM已经成为实值数据的标准能量模型，但2010.Ranzato认为，高斯RBM不能很好的适应某些类型的实值数据中存在的统计变化，特别是自然图像。图像中的大多数有用的信息在于像素之间的关系，而不是原始像素值。由于高斯RBM反对给定$h$的输入$v$的改建均值建模，所以它不能捕获条件协方差信息。为了解决这一问题，Ranzato提出mean and covariance RBM(mcRBM)、mean product of student-distribution(mPoT)和pike and slab RBM(ssRBM)。
        \paragraph{mcRBM} mcRBM使用隐含层神经元单独的编码所有可视层神经元的条件均值和协方差。具体来所，mvRBM的隐含层分成两组：均值神经元和协方差神经元。对条件均值建模的那组神经元是简单的高斯RBM，另一半是协方差RBM(Ranzato.2010)。对条件协方差的结构进行如下建模：将$h$分为二值均值神经元$h^{(m)}$和二值协方差神经元$h^{(c)}$，mcRBM的能量函数定义为二者的组合
        \begin{align*}
        E_{mc}(x,h^{(m)},h^{(c)}) = E_m(x,h^{(m)}) +　E_c(x,h^{(c)})
        \end{align*}
        其中：$E_m$为高斯-伯努利RBM的能量函数
        \begin{align*}
        E_m(x,h^{(m)})  = \frac{1}{2} x^\mathrm{T}x - \sum_j x^\mathrm{T}W_{\cdot j}h_h^{(m)} - \sum_ja_j{(m)}h_j^{(m)}
        \end{align*}
        $E_c$为cRBM的能量函数
        \begin{align*}
        E_c(x,h^{(c)})  = \frac{1}{2} \sum_j h_j^{(c)} \left( x^\mathrm{T}r ^{(j)} \right) ^2 - \sum_ja_j^{(c)} h_j^{(c)}
        \end{align*}
        参数$r^{(j)}$是与$h^{(j)}$关联的协方差权重向量，$a^{(c)}$是一个协方差偏置向量。
        \par
        组合后的能量函数定义的联合分布为
        \begin{align*}
        P_{mc}(x,h^{(m)},h^{(c)}) = \frac{1}{Z}\exp\{-E_{mc}(x,h^{(m)},h^{(c)})\}
        \end{align*}
        给定$h^{(m)}$和$h^{(c)}$后，关于数据的条件分布为(多元高斯分布)
        \begin{align*}
        P_{mc}(x|h^{(m)},h^{(c)})  = N \left( x\ \Big| \ C_{x|h}^{mc} \Big( \sum_jW_{\cdot j}h_j^{(m)} \Big),C_{x|h}^{mc}   \right)
        \end{align*}
        注意，协方差矩阵$C_{x|h}^{mc} = (\sum_j h_j^{(c)}r^{(j)} r^{(j)}{}^\mathrm{T}+I)^{-1}$是非对角矩阵，且$W$是与对条件均值建模的高斯RBM相关联的权重矩阵，对于非对角的条件协方差接哦古，难以通过对比散度(CD)或持续对比散度(PCD)来训练mcRBM。CD和PCD要从$x,h^{(m)},h^{(c)}$的联合分布中采样，这在标准RBM中是通过吉布斯在条件分布上采样实现的，但是在mcRBM中，从$P_{mc}(x|h^{(m)},h^{(c)})$中抽样需要在学习的每个迭代步中计算$(C^{mc})^{-1}$。当样本数据很大时，这是不易的。2010.Ranzato和Hinton通过使用mcRBM自由能上的哈密顿混合蒙特卡罗直接从边缘分布$p(x)$中采样。\\
        注：自由能FreeEnergy(x)定义为
        \begin{align*}
        FreeEnergy(x) = -\log \sum_h e^{-E(x,h)}
        \end{align*}

        \paragraph{学生t分布均值乘积模型}mPoT模型是由2010.Ranzato以类似mcRBM扩展cRBM的方式扩展了PoT模型(2003.Welling)。与mcRBM一样，样本上的PoT条件分布为多元高斯分布，具有非对角的协方差；与mcRBM不同的是，隐含变量的补充条件分布是由条件独立的Gamma分布给出的。mPoT的能量函数为
        \begin{align*}
        &E_{mPoT} \left( x,h^{(m)},h^{(c)} \right) \\
        ={}& E_m \left( x,h^{(m)} \right) + \sum_j \left( h_j^{(c)}\left( 1+\frac{1}{2}\left( r^{(j)}x \right)^2  \right)+ \left( 1-r^{(j)} \right) \log h_j^{(c)}   \right)
        \end{align*}
        其中：$r^{(j)}$是与神经元$h_j^{(c)}$相关联的协方差权重向量。和mcRBM一样，mPoT也无法从非对角高斯条件分布$P_{mPoT}(x|h^{(m)},h^{(c)})$中采样，Ranzato etal(2010)同样采用哈密顿混合蒙特卡洛直接从边际分布$p(x)$中采样。

\section{自动编码器AE}
    \subsection{基础自动编码器AE}
        \par
        我们从主成分分析PCA谈起(不详，可以参考其它的机器学习书籍或者多元统计教材)。设共有$n$个变量和$m$个样本，样本集为$S=\{x^1,x^2,\dots,x^m\}$，$x^k = (x_1^k,x_2^k,\dots,x_n^k)\in R^n$。主成分分析的目标是(仅对无标签数据而言)：
        \begin{align*}
        & h_1 = w_{11}x_1 + w_{12}x_ 2+ \dots + w_{1n}x_n = \sum_{i=1}^n w_{1i}x_i\\
        & h_2 = w_{21}x_1 + w_{22}x_ 2+ \dots + w_{2n}x_n = \sum_{i=1}^n w_{2i}x_i\\
        & \qquad \vdots\\
        & h_n = w_{n1}x_1 + w_{n2}x_ 2+ \dots + w_{nn}x_n = \sum_{i=1}^n w_{ni}x_i
        \end{align*}
        换句话说，我们对原本的$n$个变量进行了$n$次(不同的)线性变换，重新得到了$n$个变量(成分)$h_i(i=1,2,\dots,n)$，由于要在$n$个$h_i$中挑去一部分重要的$h_i$，所以叫做主成分。可以对原始变量$x = (x_1,x_2,\dots,x_n)$进行任意的线性变换，显然不能这么做，我们希望$h_i = w_i^\mathrm{T}x$的方差尽可能大，而且各个$h_i$之间相互独立，由于
        \begin{align*}
        Var(h_i) = Var(w_i^\mathrm{T}x) = w_i^\mathrm{T}\Sigma w_i
        \end{align*}
        其中：$\Sigma$为$x$的协方差矩阵。而对于$\forall c$，有
        \begin{align*}
        Var(cw_i^\mathrm{T}x) = cw_i^\mathrm{T}\Sigma w_i c = c^2w_i^\mathrm{T}\Sigma w_i
        \end{align*}
        如果不对$w_i$加以限制，则$Var(h_i)$可以任意增大，问题将变得没有意义。为此，我们要求：\ding{172}
        \begin{align*}
        w_i^\mathrm{T}w_i = 1 \quad i=1,2,\dots,n
        \end{align*}
        即
        \begin{align*}
        w_{i1}^2+w_{i2}^2+\dots+w_{in}^2 = 1 \quad i=1,2,\dots,n
        \end{align*}
        \ding{173}$h_1$是$x_1,\dots,x_n$的线性组合中方差最大的，$h_2$为$x$线性组合的方差第二大，且$h_2$与$h_1$不相关$\dots$，称$h_1,h_2,\dots,h_n$为$x_1,x_2,\dots,x_n$的$n$个主成分。可以将PCA表示成如图(\ref{fig:PCA网络结构示意图})网络结构
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/PCA_net_structure.jpg}
            \caption{PCA网络结构示意图}
            \label{fig:PCA网络结构示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：PCA网络结构示意图}
        \par
        将PCA写成矩阵的形式，有
        \begin{align*}
        h = W^\mathrm{T}x
        \end{align*}
        样本数据$X$是多大，返回的$n$个主成分$h$的数据矩阵$H$就是多大。我们说这些主成分$h_1,h_2,\dots,h_n$中包含了$x$的所有信息，$h_1$是主要成分，$h_2$是第二主要成分。我们自然希望通过$h$来还原$x$，如果考虑所有主成分，则
        \begin{align*}
        x = W^{-1}h
        \end{align*}
        这样就把$x$还原回来了，无损失还原，$x$还是$x$。但是，既然PCA叫做主成分，我们自然希望去掉一些成分，仅保留少量的主成分。这样，还原回来的$x$不再是原本的$x$，但是其主要特征还在。这里，我们打算用$n_k<n$个主成分来还原$x$，还原回来的$x$记为$\hat{x}$，显然$x$和$\hat{x}$不相等。设从$h$到$\hat{x}$的映射为$\hat{x} = g(h)$，画出其网络结构，如图(\ref{fig:PCA网络结构示意图2})
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/PCA_net_structure2.jpg}
            \caption{PCA网络结构示意图}
            \label{fig:PCA网络结构示意图2}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：PCA网络结构示意图2}\\
        其中：输入层$x$有$n$个神经元，输出层$\hat{x}$有$n$个神经元，隐含层/主成分层$h$有$n_h<n$个神经元。输入层到隐含层的权重为$W$，隐含层到输出层的权重为$V$，阈值分别为$a,b$。
        \par
        主成分分析是对变量$x$的有损是压缩与还原的过程：$x\xrightarrow{\text{压缩}}h\xrightarrow{\text{还原}}\hat{x}$。或者说PCA是编码和解码过程：将$x$编码到低维空间$h$，在解码到高维空间$\hat{x}$。并且，值得一提的是，如果$x_1,x_2,\dots x_n$之间不相关，只要$n_h<n$，就不能完全还原$x$。现在，将这种思想一般化：编码解码。自动编码器AE即是基于这种思想的神经网络。
        \par
        自动编码器即对自身$x$进行编码解码后还原到$x$。当然，像上面分析的那样，如果对$h$不做任何约束，那么$\hat{x} = g(h) = g(f(x))$是没有任何意义的，因为总会存在映射$f$，将$x$编码解码后还原到$x$。但如果我们对隐含层/特征层$h$加以约束，就会使$h$尽可能保留$x$的特征，以便于还原。使用上面的网络格式
        \begin{align*}
        & h = f(W^\mathrm{T}x+a)\\
        & \hat{x} = g(V^\mathrm{T}h+b)
        \end{align*}
        其中：$f$为编码器，$g$为解码器。进一步，可以写为
        \begin{align*}
        \hat{x} = g(f(x))
        \end{align*}
        由于输入$x$和输出$\hat{x}$的大小相同，我们将AE的网络结构进行折叠，折叠前后的网络结构如图(\ref{fig:AE折叠的网络结构})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/AE_fold_net_tructure.jpg}
            \caption{AE折叠的网络结构}
            \label{fig:AE折叠的网络结构}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：AE折叠的网络结构}
        \par
        AE的网络结构已经建立起来了，下面的工作就是求解编码器$f$和解码器$g$。这里的函数$f,g$是事先确定的，所以我们的目标是求$W,V,a,b$。我们仍然假设有样本集$S = \{x^{1},x^{2},\dots,x^{m}\}$，$x^{k} = (x_1^k,x_2^k,\dots,x_n^k)\in R^n$。此数据为无标签/无目标的用于无监督的数据。像BP神经网络那样，我们自然想到：求$\theta\triangleq (W,V,a,b)$，来使“离差平方和”尽可能小
        \begin{align*}
        \min_\theta \ J(W,V,a,b) = \sum_{k=1}^m||x^k -\hat{x}^k|| = \sum_{k=1}^m e_k^\mathrm{T}e^k
        \end{align*}
        注意到，这里的离差$e$是一个和$x$同大小的矩阵，$e_k$为$e$的第$k$行，是一个向量。当然，我们可以将目标$J(\theta)$进行正则化，有
        \begin{align*}
        \min_\theta \ J(W,V,a,b) = \sum_{k=1}^m ||x^k - \hat{x}^k|| + \frac{1}{2} ||W||^2 + \frac{1}{2}||V||^2
        \end{align*}
        我们将上述目标一般化，有
        \begin{align*}
        \min_\theta \ J(\theta)= \sum_{k=1}^m \ell(x^k,\hat{x}^k) + \Omega (\theta) = L(x,\hat{x}) + \Omega(\theta)
        \end{align*}
        其中：$\ell$为损失函数，$\Omega(\theta)$为正则项/罚项。\\
        注：1.对$h$的要求：可以令$n_h < n$，也可以要求$h$具有稀疏性；2.此网络深度可以像BP网络那样加深，同样，也可以对其进行堆积。
        \par
        下面来求上述目标$J(\theta)$。从自动编码器的网络结构来看，其网络层数明显可以加深。我们设其层数为$L$，第$l$层的权重为$W^{l},l=1,2,\dots,L$，第$l$层的阈值为$b^{l},l=2,3,\dots,L$。各层神经元数目为$n^{l},l=1,2,\dots,L$，且$n^{1} = n^{L} = n$。优化目标为
        \begin{align*}
        \min_\theta\ J(W,b) = \sum_{k=1}^m ||x^k - \hat{x}^k||^2 + \frac{1}{2}\sum_{l=1}^L||W^l||^2
        \end{align*}
        将$J$关于$\theta$求导，有
        \begin{align*}
        \frac{\partial J}{\partial \theta} = \sum_{k=1}^m\frac{\partial }{\partial \theta}||x^{k} - \hat{x}^k||^2 + \frac{1}{2}\sum_{l=1}^L \frac{\partial }{\partial \theta}||W^l||^2
        \end{align*}
        我们来看
        \begin{align*}
        \frac{\partial }{\partial \theta}||x^{k} - \hat{x}^k||^2  = \frac{\partial }{\partial \theta}\sum_{j=1}^{n}(x_j^k - \hat{x}_j^k)^2
        \end{align*}
        其解法与前面的BP神经网络相似，这里就不再介绍了。
    \subsection{稀疏自动编码器Sparse AE}
        \par
        在前面的AE中，要求$n_h<n$，现在考虑$n_h \geqslant n$。对此，如果不加限制，则编码器不能很好的工作，所以要对$h$加以限制/约束。我们给$h$中神经元加上稀疏约束，具体而言，当神经元的输出接近1的时候，我们认为它被激活，而输出值接近0的时候，它被限制。我们使$h$中的神经元大部分时间都被限制，此即为$h$的稀疏性约束。设$f$为sigmoid(如果是tanh，则当输出为-1时神经元被限制)，记稀疏性惩罚为$\Omega(h)$，则目标变为
        \begin{align*}
        J_{sparse}(W,b) = J(W,b) + \Omega (h)
        \end{align*}
        其中：如果仅考虑一个隐含层$h$，则$W = (W^{(1)},W^{(2)})$，$b= (b^{(1)},b^{2})$。
        \par
        用$a_j$表示隐含层神经元$j$得到激活度(输出)，但这并未标明是哪一个样本$x^k$带来的激活度(每输入一个样本，都会有一个神经元$j$都会有一个激活度)。所以，我们用$a_j(x^k)$表示样本$x^k$带来的激活度。进一步，用
        \begin{align*}
        \hat{\rho}_j = \frac{1}{m} \sum_{k=1}^m \left( a_j(x^k) \right)
        \end{align*}
        表示$h$的第$j$个神经元的样本平均激活度。我们可以近似的加入一些限制，比如
        \begin{align*}
        \hat{\rho}_j = \rho
        \end{align*}
        其中：$\rho$为稀疏性常数，一般设置为$0.05$。换句话说，我们想让$j$的平均激活度为0.05。为了满足这一要求，隐含层$j$的激活度庇护接近于0。现在，我们写出稀疏性罚因子$\Omega(h)$的具体形式
        \begin{align*}
        \sum_{j=1}^{n_h} \left[ \rho\log\frac{\rho}{\hat{\rho}_j}+ (1-\rho)\log\frac{1-\rho}{1-\hat{\rho}_j}  \right]
        \end{align*}
        注意，我们仅考虑一个隐含层的AE，$n_h$为隐含层神经元个数。其实，上式是一个以$\rho$为均值和一个以$\hat{\rho}_j$为均值的2个伯努利随机变量之间的相对熵
        \begin{align*}
        KL(\rho||\hat{\rho}_j) = \left[ \rho\log\frac{\rho}{\hat{\rho}_j}+ (1-\rho)\log\frac{1-\rho}{1-\hat{\rho}_j}  \right]
        \end{align*}
        在KL中，当$\hat{\rho}_j = \rho$时，它达到最小值0，而当$\hat{\rho}_j$靠近0或者1时，相对熵KL会变的非常大。所以这个$\Omega(h)$是有效的，于是目标写为
        \begin{align*}
        J_{sparse}(W,b) &= J(W,b) + \Omega (h)\\
        &= \sum_{k=1}^m ||x^k-\hat{x}^k||^2 + \frac{\beta}{2}\sum_{j=1}^{n_h}KL(\rho||\hat{\rho}_j)
        \end{align*}
        注意；上面的目标中不包含正则项，或者说$KL$就是正则项。现在求$J_{sparse}$的导数，$J_{sparse}$求导由两部分组成：一个是$J(W,b)$求导，一个是$KL$求导。$J(W,b)$的求导和BP相似，所以下面主要介绍$KL$的求导。
        \par
        记$S(W,b) = \sum_{j=1}^{n_h}KL(\rho||\hat{\rho}_j)$，我们要求导
        \begin{align*}
        & \frac{\partial S(W,b)}{\partial W_{ij}^{(l)}}\\
        & \frac{\partial S(W,b)}{\partial b_i^{(l)}}
        \end{align*}
        \par
        首先，我们将$S(W,b)$展开，有
        \begin{align*}
        S(W,b) = \sum_{j=1}^{n_h}KL(\rho||\hat{\rho}_j) =\sum_{j=1}^{n_h} \left[ \rho\log\frac{\rho}{\hat{\rho}_j}+ (1-\rho)\log\frac{1-\rho}{1-\hat{\rho}_j}  \right]
        \end{align*}
        其中：
        \begin{align*}
        \hat{\rho}_j = \frac{1}{m} \sum_{k=1}^m a_j(x^k) = \frac{1}{m}\sum_{k=1}^m f \left( \sum_{i=1}^{n^1}x^k_i W_{ij}^{(1)}  + b_j^{(1)}\right)
        \end{align*}
        由上式可知：
        \begin{enumerate}
        \item 当$l \neq 1$时，$\frac{\partial S(W,b)}{\partial W_{ij}^{(l)}} = 0
        ,\frac{\partial S(W,b)}{\partial b_j^{(l)}}=0$；
        \item
        \begin{align*}
        & \frac{\partial S(W,b)}{\partial W_{ij}^{(l)}} = \frac{\partial }{\partial W_{ij}^{(l)}}\sum\limits_{j=1}^{n_h} KL(\rho||\hat{\rho}_j) = \frac{\partial KL(\rho||\hat{\rho}_j)}{\partial W_{ij}^{(l)}}\\
        & \frac{\partial S(W,b)}{\partial b_j^{(l)}} = \frac{\partial }{\partial b_j^{(l)}}\sum\limits_{j=1}^{n_h} KL(\rho||\hat{\rho}_j) = \frac{\partial KL(\rho||\hat{\rho}_j)}{\partial b_j^{(l)}}
        \end{align*}
        \end{enumerate}
        由上述两条，我们有
        \begin{align*}
        \frac{\partial S(W,b)}{\partial W_{ij}^{(1)}} & = \frac{\partial KL(\rho||\hat{\rho}_j)}{\partial W_{ij}^{(1)}}\\
        & = \frac{\partial }{\partial W_{ij}^{(1)}} \left[ \rho\log\frac{\rho}{\hat{\rho}_j}+ (1-\rho)\log\frac{1-\rho}{1-\hat{\rho}_j}  \right]\\
        &= \frac{\partial }{\partial W_{ij}^{(1)}} \Big\{ \rho(\log\rho - \log \hat{\rho}_j) + (1-\rho)[\log(1-\rho) -\log(1-\hat{\rho}_j)  ]  \Big\}\\
        &= \rho \left( 0- \frac{1}{\hat{\rho}_j} \frac{\partial \hat{\rho}_j}{\partial W_{ij}^{(1)}} \right) (1-\rho) \left( 0+\frac{1}{1-\hat{\rho}_j}\frac{\partial \hat{\rho}_j}{\partial W_{ij}^{(1)}} \right) \\
        &= \left( -\frac{\rho}{\hat{\rho}_j }+ \frac{1-\rho}{1-\hat{\rho}_j} \right) \frac{\partial \hat{\rho}_j}{\partial W_{ij}^{(1)}}
        \end{align*}
        类似的，有
        \begin{align*}
        \frac{\partial S(W,b)}{\partial b_j^{(1)}} =  \left( -\frac{\rho}{\hat{\rho}_j }+ \frac{1-\rho}{1-\hat{\rho}_j} \right) \frac{\partial \hat{\rho}_j}{\partial b_j^{(1)}}
        \end{align*}
        \par
        接下来，只需要求出$\hat\rho_j$的导数即可。由$\hat\rho_j$的计算公式，我们有
        \begin{align*}
        \hat{\rho}_j = \frac{1}{m} \sum_{k=1}^m a_j(x^k) = \frac{1}{m}\sum_{k=1}^m f \left( \sum_{i=1}^{n^1}x^k_i W_{ij}^{(1)}  + b_j^{(1)}\right)
        \end{align*}
        为书写方便，令
        \begin{align*}
        & z_j^{(2)} =z_j^{(2)}(x^k)= \sum_{i=1}^{n^1}x^k_i W_{ij}^{(1)}  + b_j^{(1)}\\
        & a_j(x^k)= f \left( z_j^{(2)} \right)
        \end{align*}
        于是有
        \begin{align*}
        \frac{\partial \hat{\rho}_j}{\partial W_{ij}^{(1)}} & = \frac{1}{m} \sum_{k=1}^m f'\left( z_j^{(2)} \right) \frac{\partial z_i^{(2)}}{\partial W_{ij}^{(1)}}\\
        & = \frac{1}{m} \sum_{k=1}^m f'\left( z_j^{(2)} \right) x_i^k
        \end{align*}
        类似的，有
        \begin{align*}
        \frac{\partial \hat{\rho}_j}{\partial b_j^{(1)}} & = \frac{1}{m} \sum_{k=1}^m f'\left( z_j^{(2)} \right) \frac{\partial z_i^{(2)}}{\partial b_j^{(1)}}\\
        & = \frac{1}{m} \sum_{k=1}^m f'\left( z_j^{(2)} \right)
        \end{align*}
        至此，求导工作结束。作为练习，可以将上述内容写为矩阵形式。
    \subsection{降噪自动编码器Denoising AE}
        \par
        Denoise AE由Vincent\cite{2008.Vincent}于2008年提出。其主要思想是：首先，对样本数据$S= \{x^k\}_{k=1}^m$加入噪声。然后，基于有噪声的输入向量(样本)做编码解码。要求解码后的向量尽可能保持在原输入向量周围。如果AE对干扰后的数据都能很好的还原，则此网络具有很好的鲁棒性。
        \par
        设原始数据为$x$，加入噪声后的输入为$\tilde{x}=x+noise$，然后将$\tilde{x}$通过编码函数$f$映射到$h$，在解码$h$到$\hat{x} = g(h)$，表达式写为
        \begin{align*}
        & h = f(\tilde{x}) = \sigma (W\tilde{x}+a)\\
        & \hat{x} = g(h) = \sigma (Vh+b)
        \end{align*}
        \par
        损失函数用$\hat{x}$与$x$来定义，而非$\hat{x}$与$\tilde{x}$，有
        \begin{align*}
        J_{DAE}(W,b) = \sum_{k=1}^m \ell(x^k,\hat{x}^k)
        \end{align*}
        其中：$W=(W^{(1)}, W^{(2)}) = (W,V) $。Denoise AE的关键是对输入$x$加干扰，目前常用的干扰有2种：\ding{172}
        \begin{align*}
        & \tilde{x} = x+\varepsilon\\
        & \varepsilon \sim N(0,\sigma^2I)
        \end{align*}
        \ding{173}就单一样本而言，以概率$p$将输入向量$x^k$的部分量设置为0，其余不变。\\
        注：前面的AE我们都是采用离差平方和最小，还可以考虑极大似然方法，这一点很重要！
    \subsection{边缘降噪自动编码器mDAE}
        \par
        Chen.M于2014年开发了边缘降噪自动编码器(Marginalized Denoising AE,mDAE)\cite{2014.Chen}。在Denoise AE中，目标函数定义为
        \begin{align*}
        J_{DAE}(\theta) = \sum_{k=1}^m \ell \left( x^k,g(f(\tilde{x})) \right)
        \end{align*}
        令上式中的$g(f(\tilde{x})) = f_\theta(\tilde{x})$(这里的$f_\theta$不是$f$)，$\mu_x = \mathbb{E}_{p(x|\tilde{x})}[\tilde{x}]$，其中：$\tilde{x}$为$x$的干扰项，$\mu_x$是$\tilde{x}$的期望值。我们的目标是
        \begin{align*}
        \frac{1}{m} \sum_{k=1}^m \frac{1}{n} \sum_{j=1}^n \ell \left( x_j^k,f_\theta \left( \tilde{x}_j^k \right)  \right)
        \end{align*}
        当隐含层$h$的神经元个数很多时，会使得学习速度变得很慢。上面的目标本质是
        \begin{align*}
        \frac{1}{m} \sum_{k=1}^k \mathbb{E}_{p(\tilde{x}^k|x^k)}[\ell (x^k,f_\theta(\tilde{x}^k))  ]
        \end{align*}
        将损失函数$\ell$在$\tilde{x}$处二阶泰勒展开，有
        \begin{align*}
        \ell \left( x^k,f_\theta(\tilde{x}^k) \right) \approx \ell (x,f_\theta(\mu_x))+(\tilde{x} - \mu_x)^\mathrm{T}\nabla_{\tilde{x}} \ell+ \frac{1}{2}(\tilde{x} - \mu_x)^\mathrm{T}\nabla_{\tilde{x}}^2 \ell \cdot (\tilde{x} - \mu_x)
        \end{align*}
        其中：$\nabla_{\tilde{x}}\ell,\nabla_{\tilde{x}}^2\ell$是$\ell$在$\tilde{x}$处的一阶导数和二阶导数。
        \par
        对$\tilde{x}$取期望
        \begin{align*}
        \mathbb{E} [\ell(x,f_\theta(\tilde{x}))] \approx \ell (x,f_\theta(\mu_x)) + \frac{1}{2} \mathrm{tr} \left( \mathbb{E}[(\tilde{x} - \mu_x)(\tilde{x} - \mu_x)^\mathrm{T} ]\nabla_{\tilde{x}}^2 \ell\right)
        \end{align*}
        其中：$\mathbb{E}[\tilde{x}] = \mu_x$。令$\Sigma_x = \mathbb{E}[(\tilde{x} - \mu_x)(\tilde{x} - \mu_x)^\mathrm{T} ]$，则上式写为
        \begin{align*}
        \mathbb{E} [\ell(x,f_\theta(\tilde{x}))] \approx \ell (x,f_\theta(\mu_x)) + \frac{1}{2} \mathrm{tr} \left(\Sigma_x \nabla_{\tilde{x}}^2 \ell \right)
        \end{align*}
        上式即为损失函数。它只需要基于干扰项$\tilde{x}$的一阶泰勒展开和二阶泰勒展开即可。并且，在$x$中添加噪声时，由于每一个样本是单独加入噪声的，所以$\Sigma_x$可简化为对角矩阵。因此，只需要计算Hesse矩阵$\nabla_{\tilde{x}}^2 \ell$的对角项即可。
        \par
        Hesse矩阵的缩放依赖于数据的维度，但是对角矩阵的缩放是线性的，这种简化可以节省计算量，特别是对于高维数据而言。我们设第$k$个Hessi矩阵的对角为
        \begin{align*}
        \frac{\partial ^2\ell}{\partial \tilde{x}^k{}^2} = \left( \frac{\partial z}{\partial \tilde{x}^k} \right) ^2 \frac{\partial ^2\ell}{\partial z^2} \frac{\partial z}{\partial \tilde{x}^k} +  \left( \frac{\partial \ell}{\partial z} \right) ^\mathrm{T}\frac{\partial ^2z}{\partial \tilde{x}^k{}^2}
        \end{align*}
        其中：$z$为隐含层的输出。按LeCun(1998)提出的方法，将上式的最后一项省略，前一项是一个二次项，矩阵$\nabla_z^2\ell = \frac{\partial ^2\ell}{\partial z^2}$表示$\ell$关于$z$的Hesse矩阵，并且这个矩阵是正定的，所以可以利用正定性进一步简化矩阵的非负对角项。简化之后，该Hessi矩阵的对角项计算公式为
        \begin{align*}
        \frac{\partial ^2\ell}{\partial \tilde{x}^k{}^2} \approx \sum_{j=1}^{n_h}\frac{\partial ^2 \ell}{\partial z_j^2} \left( \frac{\partial z_j}{\partial \tilde{x}^k} \right) ^2
        \end{align*}
        其中：$n_h$为隐含层神经元个数；$z_j$为$h$中第$j$个神经元的输出。经过上面的简化计算之后，mDAE的最终目标函数为
        \begin{align*}
        J_{mDAE}(\theta) = L(x,f_\theta(\mu_x)) + \frac{1}{2}\sum_{k=1}^m \sigma_{x^k}^2 \sum_{j=1}^{n_h}\frac{\partial ^2 \ell}{\partial z_j^2} \left( \frac{\partial z_j}{\partial \tilde{x}^k} \right) ^2
        \end{align*}
        其中：$\sigma_{x^k}^2$是第$k$个样本$x^k$干扰的方差，也即$\Sigma_x$对角矩阵的第$k$个元素。
    \subsection{收缩自动编码器Contractive AE}
        \par
        CAE\cite{2011.Salah}由Salah Rifai等于2011年提出。对于一般的AE，在目标/损失函数后加正则项，其目标函数变为
        \begin{align*}
        J_\Omega(\theta) = L(x,\hat{x})+\Omega(\theta)  = \sum_{k=1}^m\ell(x^k,\hat{x}^k)+\Omega(\theta)
        \end{align*}
        其中：$\Omega(\theta)$为参数$\theta$的正则项，网络的编码解码过程为
        \begin{align*}
        & h=f(Wx^k+a)\\
        & \hat{x^k} = g(Vh+b) = g(Vf(Wx^k+a)+b) = g(f(x^k))
        \end{align*}
        我们这里直接对$\theta$进行惩罚，一般而言，$\Omega(\theta) = \sum_{ij}W_{ij}^2$。
        \par
        现在，仍然对$h$隐含层进行处理，令
        \begin{align*}
        \Omega(h) & = ||J_f(x)||_{\mathcal{F}}^2 =\sum_{ij} \left( \frac{\partial h_j(x)}{x_i} \right)
        \end{align*}
        其中：$J_f(x)$是隐含层输出值关于权重$W$的Jacobi矩阵，$||J_f(x)||_{\mathcal{F}}^2$表示该Jacobi矩阵的$\mathcal{F}$范数的平方，即矩阵中的每个元素求平方再求和，具体写为
        \begin{align*}
        ||J_f(x)||_{\mathcal{F}}^2 = \sum_{i=1}^{n_h} (h_i(1-h_i))^2 \sum_{j=1}^nW_{ij}^2
        \end{align*}
        其计算复杂度为$O(n\times n_h)$。此时的目标函数变为
        \begin{align*}
        J_{CAE}(\theta) = \sum_{k=1}^m \left[ \ell \left( x^k,g(f(x^k)) \right)  + \lambda ||J_f(x^k)||_{\mathcal{F}}^2 \right]
        \end{align*}
        \par
        解释：去噪自动编码器DAE和CAE之间存在一定的联系，Alian和Bengio(2013)指出：在引入小的高斯噪声时，DAE的重构误差与CAE的收缩惩罚因子$\Omega (h)$是等价的，也就是说，CAE具有抵抗微小干扰的能力。CAE只是局部收缩，对样本$x$的所有扰动都映射到$f(x)$的附近。从全局来看，2个不同点$x,x'$，会分别被映射到远离原点的两个点$f(x),f(x')$。CAE对数据中的小扰动敏感性较小，且重构特征不受惩罚因子的影响。但是CAE只对数据中极小扰动有鲁棒性。为此，我们可以进一步惩罚不同阶的偏差，将其目标函数改为
        \begin{align*}
        J_{CAE+h} = \sum_{k=1}^m \ell \left( x^k,g(f(x^k)) \right) + \lambda ||J_f(x)||_{\mathcal{F}}^2+ \gamma \mathbb{E}_\varepsilon [ ||J(x) - J_f(x+\varepsilon)||_{\mathcal{F}}^2  ]
        \end{align*}
        其中：$\varepsilon \sim N(0,\sigma^2 I)$，$\gamma,\lambda$为权重参数，$x+\varepsilon = \tilde{x}$。
        \par
        经过上面的改进，CAE-h的鲁棒性进一步提高。但由于基于鲁棒理论的CAE较为复杂，构建训练的难度较大，因而针对CAE的引用较少。
    \subsection{堆积自动编码器 Stacked AE}
        \par
        1986.Rumelhart提出自动编码器AE；2006.Hinton提出深度置信网络DBN；2007.Bengio提出稀疏自动编码器；2008.Vincont提出去噪自动编码器；2010.Salah提出收缩自动编码器；2011.Jonathan提出卷积自动编码器；2013.Telmo研究了不同代价函数训练得到的深度堆积自动编码器的性能。
        \par
        回忆一下我们是怎样搭建前2个深度网络DBN和DBM的？DBM是一个个小的RBM模型堆积而成，对样本进行学习时，先训练每个小的RBM，然后把它们组合在一起进行微调。即Henton提出的贪心逐层训练算法。其实，AE和RBM存在很多相似的地方：它们都可以用来生成数据(对样本分布进行估计)，并且AE也可以表示成RBM的网络形式，如图(\ref{fig:AE折叠成RBM的网络形式})
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/AE_fold_into_RMB_net.jpg}
            \caption{AE折叠成RBM的网络形式}
            \label{fig:AE折叠成RBM的网络形式}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：AE折叠成RBM的网络形式}\\
        那么自然想：能否将AE堆积形成深度网络？可以的，把AE堆积而成的深度网络称为Deep AE或者stacked AE(注意：这里的AE可以是AE的衍生模型，如CAE和后面介绍的VAE)。
        \par
        DBM是在RBM的隐含层$h$后再添加网络层，那么，AE应该在$h$层/特征层还是在$\hat{x}$层后再加网络层呢？即下一个AE的输入是上一个AE的$h$层还是$\hat{x}$层？在回答这个问题之前，我们来记一下AE
        \begin{align*}
        & h = f(Wx+a)\\
        & \hat{x} = g(Vh+b)
        \end{align*}
        一般情况下，$\hat{x}$不是$x$的精确重构，它只是在满足一定分布的条件概率$p(x|\hat{x})$下，最大程度的接近$x$。因此，AE的目标不仅可以是离差平方和，还可以用极大似然估计，特别是在去噪自动编码器中，$\hat{x}$是有明显(条件)分布的。并且
        \begin{align*}
        \ell (x,\hat{x}) \propto -\log (x|\hat{x})
        \end{align*}
        \par
        如果$x\in R^n$，则$x|\hat{x} \sim N(\hat{x},\sigma^2I)$，这时可以采用离差平方和作为目标$||x-\hat{x}||^2$；如果$x\in \{0,1\}^n$，则$x|\hat{x}\sim B(\hat{x})$，这时就不能用$||x-\hat{x}||$作为目标，就要使用交叉熵等(这个在logistics回归中有介绍)
        \begin{align*}
        \ell (x,\hat{x}) = -\sum_j \left[ x_j\log \hat{x}_j + (1-x_j)\log (1-\hat{x}_j)  \right] = H(B(x)||B(\hat{x}))
        \end{align*}
        \par
        现在考虑我们的问题：下一个AE的输入是上一个AE的$h$层还是$\hat{x}$层？(1)如果是将隐含层$h$作为下一层的输入，那么，预训练(无监督)逐层训练应该为：将第一个AE训练好后，有$W^{(1)},V^{(1)},a^{(1)},b^{(1)}$；然后，将样本再次输入到第一个AE中，每个样本$x^k$都会有一个$h^k,\hat{x}^k$，我们把$h = \{h^k\}_{k=1}^m$作为输入，输入到第二个AE中进行训练，训练后有$W^{(2)},V^{(2)},a^{(2)},b^{(2)}$；然后将$h$在此输入，如此下去，直到最后一层。这样，就完成了stacked AE的预训练，也就得到了深层网络的初始权重和阈值。如果要进行分类任务，可以在预训练之后，运用BP等算法对网络参数进行微调(联合训练)。如图(\ref{fig:SAE的训练过程图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/SAE_training_process.jpg}
            \caption{SAE的训练过程图}
            \label{fig:SAE的训练过程图}
            \end{figure}
        % \textcolor[rgb]{ 1 0 0}{todo:图片：SAE的训练过程图}\\
        注：如果设置$V^\mathrm{T} = W$，那么网络的训练会变得简单易行。(2)如果是将输出层$\hat{x}$作为下一个AE的输入，则其深层网络如图(\ref{fig:AE第二种堆积网络})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/the_second_accumulation_net_of_AE.jpg}
            \caption{AE第二种堆积网络}
            \label{fig:AE第二种堆积网络}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：AE第二种堆积网络}\\
        其训练过程和(1)的情况是相似的。
    \subsection{变分自动编码器 VAE}
        \par
        记样本数据为$D=\{x^1,x^2,\dots,x^m\}$，$D$是域$S\in R^n$中的采样\footnote{我们可以在实值$R^n$上讨论$x$，也可以在$\{0,1\}^n$上进行讨论。}，$x^k = (x_1^k,x_2^k,\dots,x_n^k)\in R^n$称为样本点。并且，我们假设是$n$随机变量$x = (x_1,x_2,\dots,x_n)$，所以$S$上应该有这$n$个随机变量的分布函数$p(x)$。
        \par
        假设AE的隐含层$z\overset{\Delta}{=}h$有$n_h$个神经元，神经元之间可以互相连接，也可以不连接(独立)。记全体隐含层神经元为$z = (z_1,z_2,\dots,z_{n_h})$。假设AE网络的参数$\theta$已经给出，我们可以说：给定$x$后就有了$z$，或者给定$z$之后就有了$x$，因为二者之间是一个编码$f$和解码$g$的过程
        \begin{align*}
        & z = f(x;\theta')\\
        & \hat{x} = g(z;\theta'')
        \end{align*}
        令$\theta \overset{\Delta}{=}(\theta',\theta'')\overset{\Delta}{=}(W,V,a,b)$。值得一提的是，我们可以将$f,g$扩展为任意函数形式，比如MLP, CNN等网络形式。也可以将$z$设置为任意结构，$z$中的神经元之间可以连接、不连接以及部分连接，这样AE模型的范围就变得大了许多。
        \par
        AE网络中的参数$\theta$是待求的，关于$\theta$的求解，大致可分为3个方向：\ding{172}基于参数估计得极大似然估计ML；\ding{173}基于贝叶斯方法的最大后验估计MAP；\ding{174}离差平方最小的最小二乘OLS。三者的共同之处是，它们都是一个优化问题。前面我们讨论了\ding{174}离差平方和方法，下面先来看极大似然估计。
        \par
        在假设样本独立同分布情况下，如果已经知道了单一样本$x^k$的分布 $p_\theta(x^k)\overset{\Delta}{=}p(x^k|\theta) $，可以直接写出极大似然的目标
        \begin{align*}
        \max_\theta\ J(\theta) = \log P(x|\theta) = \log \prod_{k=1}^mp(x^k;\theta) = \sum_{k} \log p(x^k;\theta)
        \end{align*}
        如果样本的分布$p(x^k;\theta)$形式已知，直接求导即可。但是现在的问题是：$p(x;\theta)$不易求解，但是存在一个潜随机变量$z$，$p(x,z;\theta)$是可求的(就像在RBM中遇到的那样)。
        \par
        抛弃我们的模型，如果已知$p(x,z)$，如何求$p(x)$？从联合分布$p(x,z)$中采样$\{x^k,z^k\}$，然后求和/积即可。回到我们的模型中，发现只有部分样本$\{x^k\}$，称$\{x^k,z^k\}_{k=1}^m$为整体样本，$\{x^k\}_{k=1}^m$为部分样本。关于潜变量$z$的取值，仅来源于后验概率分布$p(z|x;\theta)$(即我们建立的模型)。我们记$x$的概率分布为$p(x;\theta)$，$z$的概率分布为$q(z;\theta)$，联合概率分布为$p(x,z;\theta)$，条件分布为$p(x|z;\theta)$和$p(z|x;\theta)$。
        \par
        既然$p(x;\theta)$不易找到，考虑将其用联合分布表示
        \begin{align*}
        p(x;\theta) = \int_zp(x,z;\theta)\mathrm{d}z
        \end{align*}
        于是，单一样本的$x \overset{\Delta}{=}x^k$最大似然目标为
        \begin{align*}
        J(\theta) = \log p(x;\theta) = \int_zp(x,z;\theta)\mathrm{d}z
        \end{align*}
        由条件概率关系
        \begin{align*}
        p(x,z) = p(x)p(z|x) = q(z)p(x|z)
        \end{align*}
        并且我们求$p(x)$，可以得到
        \begin{align*}
        J(\theta) &= \log \int_z p(x,z;\theta)\mathrm{d}z\\
        &=\log \int_z q(z)p(x|z)\mathrm{d}z
        \end{align*}
        注意：上面的概率分布函数都忽略了参数$\theta$。本应写为$p(x;\theta),q(z;\theta)$，并且，如果在贝叶斯框架，则写为$p(x|\theta),q(z|\theta)$。上式的难点在于$q(z)$和$p(x|z)$。下面介绍EM算法和变分估计，并用这两种方法求解上述问题。
        \subsubsection{EM算法}
            \par
            EM算法是Dempster等于1997年提出的，用于求解含有潜变量$z \overset{\Delta}{=}h$的参数极大似然估计或最大后验概率估计。我们假设在$t$次迭代后，参数值为$\theta^t$，现在，我们要求$\theta^{t+1}$。我们自然希望新的参数$\theta$能使目标$J(\theta)$增加，即$J(\theta)>J(\theta^t)$。为此，我们考虑二者的差
            \begin{align}
            \label{极大目标迭代差量}
            J(\theta) - J(\theta^t) = \log \int_z q(z)p(x|z)\mathrm{d}z - \log p(x;\theta^t)
            \end{align}
            \begin{lemma}[Jensen不等式]
            设$\varphi$为凸函数，则
            \begin{align*}
            \varphi(\mathbb{E}(x)) \leqslant \mathbb{E}(\varphi(x)) \Leftrightarrow\varphi \left( \sum_{i=1}^ng(x_i) \lambda_i\right) \leqslant \sum_{i=1}^n\varphi(g(x_i))\lambda_i
            \end{align*}
            其中：$x = (x_1,x_2,\dots,x_n)$，$\sum_i\lambda_i = 1$，$\lambda_i \geqslant 0$。
            \end{lemma}
            注：Jensen不等式给出了积分的凸函数值和凸函数的积分值之间的关系。其实，在SVM部分有简单的介绍过Jensen不等式。
            \par
            将Jensen不等式应用到(\ref{极大目标迭代差量})中，有
            \begin{align*}
            J(\theta) - J(\theta^t) &= \log \int_z q(z)p(x|z)\mathrm{d}z - \log p(x;\theta^t)\\
            &=\log \int_zp(z|x;\theta^t) \frac{p(x|z)q(z)}{p(z|x;\theta^t)}\mathrm{d}t - \log p(x;\theta^t)\\
            & \geqslant \int_zp(z|x;\theta^t) \log\frac{p(x|z;\theta) q(z;\theta)}{p(z|x;\theta^t)}\mathrm{d}t - \log p(x;\theta^t)\\
            &=\int_zp(z|x;\theta^t) \log\frac{p(x|z;\theta) q(z;\theta)}{p(z|x;\theta^t)p(x;\theta^t)}\mathrm{d}t
            \end{align*}
            于是有
            \begin{align*}
            J(\theta) \geqslant J(\theta^t) + \int_zp(z|x;\theta^t) \log\frac{p(x|z;\theta) q(z;\theta)}{p(z|x;\theta^t)p(x;\theta^t)}\mathrm{d}t
            \end{align*}
            令
            \begin{align*}
            B(\theta,\theta^t) = J(\theta^t) + \int_zp(z|x;\theta^t) \log\frac{p(x|z;\theta) q(z;\theta)}{p(z|x;\theta^t)p(x;\theta^t)}\mathrm{d}t
            \end{align*}
            则$B(\theta,\theta^t)$是目标$J(\theta)$的下界，且由$B(\theta^t,\theta^t) = J(\theta^t)$可知，对于任意的$\theta$，如果$\theta$使$B(\theta ,\theta^t)>B(\theta^t,\theta^t)$，则$J(\theta)>J(\theta^t)$。为了使$J(\theta)$尽可能增大，选择$\theta^{t+1}$是$B(\theta,\theta^t)$最大。
            \begin{align*}
            \theta^{t+1} & = \arg \max_\theta B(\theta,\theta^t)\\
            & = \arg \max_\theta J(\theta^t) + \int_zp(z|x;\theta^t) \log\frac{p(x|z;\theta) q(z;\theta)}{p(z|x;\theta^t)p(x;\theta^t)}\mathrm{d}t\\
            & = \arg \max_\theta \int_z p(z|x;\theta^t) \log p(x|z;\theta)q(z;\theta)\mathrm{d}t\\
            & \overset{\Delta}{= } \int_z p(z|x;\theta^t)\log p(x,z;\theta)\mathrm{d}z
            \end{align*}
            令
            \begin{align*}
            Q(\theta,\theta^t) & = \int_z p(z|x;\theta^t)\log p(x,z;\theta)\mathrm{d}z\\
            & \overset{\Delta}{=} \sum_z p(z|x;\theta^t)\log p(x,z;\theta)
            \end{align*}
            $Q$是完整数据$(x,z)$的对数似然函数$\log p(x,z;\theta)$的期望。可以给出如下的EM算法：\\
            \textbf{Step1}.初始化。$D = \{x^k\}_{k=1}^m$。初始网络AE，初始参数$\theta^0$，联合分布函数$p(x,z;\theta)$，迭代次数$t:=0$，$t_{max}$，容许误差$\varepsilon_1,\varepsilon_2$。\\
            \textbf{Step2}.对第$t$次迭代，已经有了$\theta^t$，现在来求$\theta^{t+1}$。
            \begin{enumerate}
            \item E步：计算概率$p(z|x;\theta^t)$；
            \item M步：计算
            \begin{align*}
            & Q(\theta,\theta^t)= \int_z p(z|x;\theta^t)\log p(x,z;\theta)\mathrm{d}z\\
            & \theta^{t+1} = \arg\max_\theta Q(\theta,\theta^t)
            \end{align*}
            \end{enumerate}
            \textbf{Step3}.终止条件。如果$||\theta^{t+1} - \theta^t||<\varepsilon_1$或者$||Q^{t+1} - Q^t||<\varepsilon_2$则终止；否则，则置$t:=t+1$，返回Step2.
            \par
            现在的问题是，如何求解$p(z|x;\theta^t)$、$p(x,z;\theta)$以及$\int_z p\log p\mathrm{d}z$？假设前面已经直达了$p(x,z;\theta)$和$p(z|x;\theta^t)$，现在的关键是如何求积分。我们用数值积分公式计算$Q(\theta,\theta^t)$中的积分，有
            \begin{align*}
            Q(\theta,\theta^t) \approx \frac{1}{N} \sum_{i=1}^N\log p(x,z^i;\theta)
            \end{align*}
            其中：$N$为$z^i$的样本数。这里涉及到按照某分布$p(z|x)$对$z$进行采样$\{z^i\}_{i=1}^N$，我们可以采用MCMC等采样方法。
            \paragraph{MCMC采样}
            MCMC适用于处理给定分布$p(z|x;\theta^t)$，从中采样$z$的问题。由于马尔科夫链能收敛到平稳分布，如果我们能够着一个转移矩阵为$P$的马氏链，使得该马氏链的平稳分布恰好为$p(z|x;\theta^t)$，那么，我们从任意的初始状态$z_0$出发，沿马氏链转移，得到一个转移序列$\{z_0,z_1,\dots,z_n,z_{n+1}\dots\}$。如果马氏链的第$n$步已经收敛了，就得到了$p(z|x)$的样本$\{z_{n},z_{n+1},\dots\}$。
            \par
            这正是前面模拟退火算法或者BM网络的思路，由Metropolis于1953年提出。MCMC采样的关键点是如何构建转移矩阵$P$，使得平稳分布为$p(z|x;\theta^t)$。下面，给出概率分布$p(x)$的MCMC采样：假设已经有了转移概率$q(x_i,x_j)$(从状态$x_i$转移到$x_j$的概率)，以及接受概率$ \alpha(x_i,x_j)$(以概率$\alpha$接受这个转移)，则MCMC描述为
            (\ref{code:MCMC})
            \begin{algorithm}[htbp]
                \caption{MCMC for $p(x)$}\label{code:MCMC}
                \begin{algorithmic}[1]
                    \State 初始化：初始状态$X_0 = x_0$，$t:=0$，$t_{max}$。
                    \For {对$t=1,2,\dots$循环一下采样步骤}
                        \State 第$t$时刻的马氏链状态为$X_t = x_t$，采样$y\sim q(x|x_t)$；
                        \State 从均匀分布中采样$u\sim U(0,1)$；
                        \State 如果$u < \alpha(x_t,y) = p(y)q(x_t|y)$，则接受转移$x_{t}\to y$，即$X_{t+1} = y$，否则，不接受转移$X_{t+1} = x_t$
                    \EndFor
                \end{algorithmic}
            \end{algorithm}
            \par
            Metropolis-Hastings采样只是将上述算法中的$\alpha(x_t,y)$变为
            \begin{align*}
            \alpha(x_t,y) = \min\left\{ \frac{p(y)q(x_t|y)}{p(x_t)p(y|x_t)} ,1\right\}
            \end{align*}
            关于MCMC更多的介绍可以参考《高等数理统计》茆诗松P441。
        \subsubsection{变分近似推断}
            \par
            将目标函数进行如下分解(在DBN处有介绍)
            \begin{align*}
            J(\theta) = \log p(x;\theta) = L(q,\theta) + KL(q||p)
            \end{align*}
            其中：
            \begin{align*}
            & L(q,\theta) = \sum_zq(z) \log \frac{p(x,z;\theta)}{q(z)}\\
            & KL(q||p) = -\sum_zq(z) \ln \frac{p(z|x;\theta)}{q(z)}
            \end{align*}
            注意，上式中的$q(z)$的函数形式未知，所以$L(q,\theta)$是一个关于$q$函数和参数$\theta$的泛函。
            又因为$KL(q||p) \geqslant 0$，当且仅当$q=p$时等号成立，所以，$L(q,\theta)$是目标$\log p(x;\theta)$的一个下界，只有当$p=q$时，$\log p(x;\theta)=L(q,\theta)$。
            \par
            在上面的EM算法中，给定当前参数$\theta^t$，\ding{172}在E步，我们求下界$L(q|\theta^t)$关于$q$取最大值，即求函数$q$使$L(q,\theta^t)$最大。注意到$\ln p(x;\theta^t)$不依赖于$q(z)$是一个定量，为$L(q,\theta^t)$的上界，所以$L(q,\theta^t)$的最大值出现在$L(q,\theta^t)= \ln p(x;\theta^t)$。换句话说，出现在$KL(q||p)=0$时，即$q(z) = p(z|x;\theta^t)$时。这样，就找到了$q$使$L(q,\theta^t)$最大；\ding{173}在M步，$q$函数保持不变，下界$L(q,\theta)$关于$\theta$进行最大化，从而得到$\theta^{t+1}$。将$q= \ln p(z|x;\theta^t)$带入$L(q,\theta)$，然后再关于$\theta$最大，有
            \begin{align*}
            L(q,\theta) &= \sum_zp(z|x;\theta^t)\ln p(x,z|\theta) - \sum_zp(z|x;\theta^t)\ln p(z|x;\theta^t)\\
            &=Q(\theta,\theta^t) + H(q)
            \end{align*}
            这里的$ Q(\theta,\theta^t)$和EM算法中的一致，我们在M步中将其最大化。$Q$是完整数据$(x,z)$的对数似然函数的期望。如果$p(x,z;\theta)$是由指数分布族的成员组成，或者由其乘积组成，例如$p(x,z)$是$n+n_h$元高斯分布，则$\log$运算会抵消指数运算，从而使得M步通常比最大化$\log p(x;\theta)$要容易的多。
            \par
            下面介绍变分法的思想
            \begin{align*}
            \ln p(x) = L(q)+KL(q|| p)
            \end{align*}
            其中：
            \begin{align*}
            & L(q) = \int q(z) \ln \frac{p(x,z)}{q(z)}\mathrm{d}z = \mathbb{E}_{q(z)} \left[\ln  \frac{p(x,z)}{q(z)}\right]\\
            & KL(q||p) = -\int q(z) \ln \frac{p(z|x)}{q(z)}\mathrm{d}z
            \end{align*}
            \par
            与之前一样，求$q(z)$使$L(q)$最大，这等于求$q(z)$使$KL$最小。如果允许$q$为任意函数，那么下界$L$的最大值出现在$KL$等于0的时候，即$q(z) = p(z|x)$，然而，在实际的模型当中，往往对$q(z)$有一定的要求。在函数域$Q$中寻找最优的$q(z)$来使KL距离最小。一个会有的想法是$q(z)\approx p(z|x)$，即找$p(z|x)$来近似充当$q(z)$。在微分方程部分，常用参数化方法来处理泛函问题，我们不在函数空间中寻找$q$，而是在参数空间中寻找$q$。现在，引入参数$\phi$，每一个具体的参数$\phi$对应一个函数$q(z;\phi)$，于是求$q$就变为求$\phi$。将参数化的函数空间$Q$记为$Q=\{q(z;\phi)\}$，即$q_\phi(z)$是某一分布族。
            \par
            上面，无论是在EM算法还是在变分推断，都是在变量$x,z$或者所有样本$\{x^k\}$上进行的，下面，将在单独某一个样本$x^k$(或小批量样本)中进行分析。
            \begin{align*}
            \log p(x;\theta) = \log \prod_{k=1}^m p(x^k;\theta) =\sum_{k=1}^m\log p_\theta(x^k)
            \end{align*}
            并且
            \begin{align*}
            \log p_\theta(x^k) = L(\theta,\phi;x^k)+KL(q_\phi(z|x^k)||p_\theta(z|x^k))
            \end{align*}
            其中：$L(\theta,\phi;x^k)$是$\log p_\theta(x^k)$的下界。我们的目标仍然是求参数$\theta,\phi$，使下界$L(\theta,\phi;x^k)$最大。
            \begin{align*}
            \log p(x^k) \geqslant L(\theta,\phi;x^k) & = \mathbb{E}_{q_\phi(z|x^k)} \left[\log p_\theta(x^k,z) - \log q_\phi(z|x^k)  \right]\\
            & =\int _z q_\phi(z|x^k) \log \frac{p_\theta(x^k,z)}{q_\phi(z|x^k)}\mathrm{d}z
            \end{align*}
            在$x$和$z$独立时，将$L(\theta,\phi;x^k)$中的$p_\theta(x^k,z)$拆分
            \begin{align*}
            p_\theta(x^k,z) = p_\theta(z|x^k)p_\theta(x^k)
            \end{align*}
            有
            \begin{align}
            \label{VAE的目标L}
            L &= \int _z q_\phi(z|x^k) \log \frac{p_\theta(z|x^k)p_\theta(x^k)}{q_\phi(z|x^k)}\mathrm{d}z\notag \\
            & =\int_z q_\phi(z|x^k) \log \frac{p_\theta(z|x^k)}{q_\phi(z|x^k)}\mathrm{d}z + \int_z q_\phi(z|x^k)\log p_\theta (x^k)\mathrm{d}z\notag \\
            &= -KL(q_\phi(z|x^k)||p_\theta(z|x^k))+\mathbb{E} _{q_\phi(z|x^k)} \left[ \log p_\theta(x^k|z) \right]
            \end{align}
            \par
            \ding{172}对$L$(\ref{VAE的目标L})中的第一项。边界$L(\theta,\phi,x^k)$包含$-KL(q_\phi(z|x^k)||p_\theta(z|x^k))$项，这一项可以解析的求出。我们在高斯情况下讨论：设$p_\theta(z|x^k)$为标准正态分布，$p_\theta(z|x^k) = N(0,I)$，$q_\phi(z|x^k)$是正态分布，并且要求$q$的各维变量$(z_1,z_2,\dots,z_{n_h})$是相互独立的。$q_\phi(z|x^k)$中的参数$\phi$为$\mu,\sigma$(这里的$\mu$为均值向量$\mu=(\mu_1,\mu_2,\dots,\mu_{n_h})$，$\sigma$也为方差向量$\sigma=(\sigma_1,\sigma_2,\dots,\sigma_{n_h})$，下面的$\mu,\sigma$都是向量哦)，随机变量$z_1$的分布是均值为$\mu_1$，方差为$\sigma^2$的正态分布。因此
            \begin{align*}
            \int q_\phi(z|x^k) \log p(z|x^k)\mathrm{d}z &= \int N(z;\mu,\sigma^2)\log N(z;0,I)\mathrm{d}z\\
            &= -\frac{n_h}{2} \log(2\pi) - \frac{1}{2} \sum_{j=1}^{n_h}(\mu_j^2+\sigma_j^2)
            \end{align*}
            \begin{align*}
            \int q_\phi(z|x^k) \log q_\phi(z|x^k)\mathrm{d}z &= \int N(z;\mu,\sigma^2)\log N(z;\mu,\sigma^2)\mathrm{d}z\\
            &= -\frac{n_h}{2} \log(2\pi) - \frac{1}{2} \sum_{j=1}^{n_h}(1+\sigma_j^2)
            \end{align*}
            最后，我们有
            \begin{align*}
            -KL(q_\phi||p_\theta) &= \int q_\phi(z|x^k)\log \frac{p_\theta(z|x^k)}{q_\phi(z|x^k)}\mathrm{d}z\\
            &= \frac{1}{2} \sum_{j=1}^{n_h} \left( 1+\log \sigma_j^2 -\mu_j^2- \sigma_j^2 \right)
            \end{align*}
            \par
            通过上面的分析，我们得到了式(\ref{VAE的目标L})$L$中的第一项$-KL(q_\phi||p_\theta)$。我们要求$\theta,\phi$使$L$最大，第一项$-KL(q_\phi||p_\theta)$关于$\theta,\phi$的求导是没问题的，但是式(\ref{VAE的目标L})第二项$\mathbb{E} _{q_\phi(z|x^k)} \left[ \log p_\theta(x^k|z) \right]$的求导就有问题了，一般的MCMC求解梯度为
            \begin{align*}
            \nabla_\phi \mathbb{E} _{q_\phi(z)} [f(z)] = \mathbb{E}_{q_\phi(z)} \left[ f(z)\nabla_{q_\theta(z)} \log q_\phi(z)  \right] \approx \frac{1}{L} \sum_{l=1}^L f(z^l)\nabla_{q_\theta(z^l)} \log q_\phi(z^l)
            \end{align*}
            其中：$L$为$z$的采样数，$z^l$为样本，$z^l\sim q_\phi(z|x^k)$。对每一个样本点$x^k$，$z$都要有$L$次采样$z^l \sim q_\phi(z|x^k) = N(\mu,\sigma^2)$，这导致梯度估计量的方差非常大，并且，我们无法关于参数$\phi$求导(如果设$q_\phi(z|x^k) = N(\mu,\sigma^2)$，则$\phi \overset{\Delta}{=}(\mu,\sigma^2)$，则不能对$\mu,\sigma$求导。)
            \par
            以$p_\theta(z|x^k) - N(0,I)$，$q_\phi(z|x^k) = N(\mu,\sigma^2)$为示例，VAE的网络结构如图(\ref{fig:VAE网络结构示意图1})所示
            \begin{figure}[H]
            \centering
            \includegraphics[width=12cm]{images/VAE_net_structure1.jpg}
            \caption{VAE网络结构示意图1}
            \label{fig:VAE网络结构示意图1}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：VAE网络结构示意图1}
            \par
            \ding{173}对式(\ref{VAE的目标L})$L$中的第二项。由于$z$是采样而来的，$z\sim q(z|x) = N(\mu,\sigma^2)$，因而$L$不能关于$\phi \overset{\Delta}{=}(\mu,\sigma)$求导。如果$z$是其它操作(非采样操作，例如$z = (A+B)C$等)，那么求导是没问题的。我们希望把采样($\sim$)这个随机操作变为某种确定性操作(例如$z = g_\phi(\cdot)$)，可以进行如下确定性变换
            \begin{align*}
            z = g_\phi(\epsilon,x)
            \end{align*}
            其中：$\epsilon$是一个外来的随机变量，其概率分布为$p(\epsilon)$；$g_\phi(\cdot)$是一个关于参数$\phi$的向量值函数。
            \par
            假设$z_1,z_2,\dots,z_{n_h}$之间相互独立，则
            \begin{align*}
            \mathrm{d}z = \mathrm{d}z_1\mathrm{d}z_2\dots\mathrm{d}z_{n_h} = \prod_{i=1}^{n_h}\mathrm{d}z_i
            \end{align*}
            于是有
            \begin{align*}
            q_\phi(z|x)\mathrm{d}z \overset{\Delta}{=} q_\phi(z|x) \prod_{i=1}^{n_h}\mathrm{d}z_i = p(\epsilon) \mathrm{d} \epsilon
            \end{align*}
            于是
            \begin{align*}
            \int q_\phi(z|x) f(z)\mathrm{d}z = \int p(\epsilon) f(z)\mathrm{d}\epsilon
            \end{align*}
            将$z = g_\phi(\epsilon,x)$带入上式，有
            \begin{align*}
            \int q_\phi(z|x) f(z)\mathrm{d}z = \int p(\epsilon) f(g_\phi(\epsilon,x))\mathrm{d}\epsilon
            \end{align*}
            由此，我们就可对$L$(\ref{VAE的目标L})中的第二项$\int q_\phi(z|x)f(z)\mathrm{d}z$构建一个可微的估计量
            \begin{align*}
            \int q_\phi (z|x)f(z)\mathrm{d}z \approx \frac{1}{L}\sum_{l=1}^L f(g_\phi (x,\epsilon^l)) \quad \epsilon^l \sim p(\epsilon)
            \end{align*}
            现在可以对上式求导了。例：我们用高斯分布作为示例，设$z\sim p(z|x) = N(\mu,\sigma^2)$，一个有效的转化是$z = \mu + \sigma \epsilon$，其中：$\epsilon \sim N(0,1)$，因此
            \begin{align*}
            \mathbb{E} _{N(z;\mu,\sigma^2)}[f(z)] = \mathbb{E}_{N(\epsilon;0,1)}[f(\mu+\sigma \epsilon)] \approx \frac{1}{L} \sum_{l=1}^L f(\mu+\sigma \epsilon^l)
            \end{align*}
            其中：$\epsilon^l \sim N(0,1) $。对于上面的这种“确定性变换”，我们自然考虑：哪些$q_\phi(z|x)$可以进行可微转换$g_\phi(\cdot)$呢？并且有$\epsilon \sim p(\epsilon)$呢？关于这个问题，可以参考\cite{2014.Kingma}P5。
            \par
            上面的是在所有样本$x$上进行的，对于单一样本$x^k$，只要将$x$变为$x^k$即可。现在可以用MCMC来估计函数$f(z)$关于$q_\phi(z|x^k)$的期望了
            \begin{align*}
            \mathbb{E} _{q_\phi(z|x^k)}[f(z)] = \mathbb{E}_{p(\epsilon)}[f(g_\phi(\epsilon,x^k))] \approx \frac{1}{L} \sum_{l=1}^L f(g_\phi(\epsilon^l,x^k))
            \end{align*}
            其中：$\epsilon^l\sim p(\epsilon)$。我们将这种确定性转换技术应用到下界$L(\theta,\phi;x^k)$。\ding{172}考虑下界$L$的第一个写法
            \begin{align*}
            L(\theta,\phi;x^k)& = \mathbb{E}_{q_\phi(z|x^k)} \left[ \log p_\theta(x^k,z) - \log q_\phi(z|x^k) \right]\\
            & \approx \frac{1}{L} \sum_{l=1}^L \left[ \log p_\theta(x^k,z^l) - \log q_\phi (z^{k,l}|x^k) \right]
            \end{align*}
            其中：$z^{k,l} = g_\phi(\epsilon^{k,l},x^k)$，$\epsilon ^k \sim p(\epsilon)$。记此估计量为$\tilde{L}^A(\theta,\phi;x^k)$。\\
            \ding{173}考虑下界$L$的第二个写法
            \begin{align*}
            L(\theta,\phi;x^k) = - KL(q_\phi(z|x^k)||p_\theta(z|x^k)) + \mathbb{E}_{q_\phi(z|x^k)} \left[ \log p_\theta(x^k|z) \right]
            \end{align*}
            上式得$-KL$项在前面已经分析过了，可以对$\mu,\sigma$求导，但后面的积分项(期望值)不行，我们将确定性变换$z = g_\phi(\epsilon,x)$技术用上来，就变为
            \begin{align*}
            L(\theta,\phi;x^k) = -KL(q_\phi(z|x^k) || p_\theta(z|x^k))+ \frac{1}{L}\sum_{l=1}^L \log p_\theta(x^k|z^{k,l})
            \end{align*}
            其中：$z^{k,l} = g_\phi(\epsilon^{k,l},x^k)$，$\epsilon^l\sim p(\epsilon)$。我们记此估计量为$\tilde{L}^B(\theta,\phi;x^k)$。
            \par
            现在，$\tilde{L}^B(\theta,\phi;x^k)$和$\tilde{L}^A(\theta,\phi;x^k)$可以对$\phi$求导了。上面是单一样本$x^k$，对于批量样本而言，设$x^M$是从样本集中随机挑选的$M$个样本，则其估计量为
            \begin{align*}
            L(\theta,\phi;x^M) \approx \tilde{L}^M(\theta,\phi;x^M) = \frac{m}{M} \sum_{k=1}^M \tilde{L}(\theta,\phi;x^k)
            \end{align*}
            批量样本的SGVB算法如下(\ref{code:SGVB})
            \begin{algorithm}[htbp]
                \caption{SGVB for VAE}\label{code:SGVB}
                \begin{algorithmic}[1]
                    \State 初始化：$M$，$S = \{x^k\}_{k=1}^m$，MC链长$L =1$，初始参数$\theta^0,\phi^0$，迭代次数$t$，$t_{max}$，容许误差$\varepsilon$，学习率$\eta $。
                    \While {未达到终止条件 $t>t_{max}\ |\ ||\theta^{t+1},\phi^{t+1} - \theta^t,\phi^t||<\varepsilon$}
                        \State 随机挑选$M$个样本$x^M$；
                        \State $\epsilon \sim p(\epsilon)$；
                        \State $g \gets \nabla_{\theta,\phi}\tilde{L}^M(\theta,\phi;x^M,\epsilon)$；
                        \State $\theta,\phi \gets \theta,\phi + \eta g$
                    \EndWhile
                \end{algorithmic}
            \end{algorithm}
            \par
            仍然以$p_\theta(z|x^k) = N(0,I)$，$q_\phi(z|x^k)= N(\mu,\sigma^2)$为示例，经过确定性变化后，VAE的网络结构如图(\ref{fig:VAE网络结构示意图2})所示
            \begin{figure}[H]
            \centering
            \includegraphics[width=12cm]{images/VAE_net_structure2.jpg}
            \caption{VAE网络结构示意图2}
            \label{fig:VAE网络结构示意图2}
            \end{figure}
            % \textcolor[rgb]{1  0 0}{todo:图片：VAE网络结构图2}

        \subsubsection{VAE的梳理}
            \par
            下面来捋一下VAE。假设$p_\theta(z|x^k)$为多元正态分布$N(0,I)$；如果样本为实值，则设$p_\theta(x|z)$为多维高斯分布，如果样本是01二值的，则设$p_\theta(x|z)$为多维二项分布。假设$q_\phi(z|x^k)$是多维高斯分布$N(\mu^k,\sigma^k{}^2)$，这里$\mu^k,\sigma^k$为向量，$\mu^k = (\mu_1^k,\mu_2^k,\dots,\mu_{n_h}^k)$。
            \par
            对于某一个样本$x^k$，将$x^k$输入到VAE网络中，通过编码器$f$，可以得到其均值向量和方差向量$\mu^k,\sigma^k$，于是，我们得到了$q_\phi(z|x^k)$
            \begin{align*}
            q_\phi(z|x^k) = N(z;x^k,\sigma^{k2}I)
            \end{align*}
            然后要在$q_\phi(z|x^k)$中选取$L$个样本，$z^{k,l} \sim q_\phi(z|x^k)$，为了使其可导，我们用确定性转化技术
            \begin{align*}
            z^{k,l} = g_\phi(x^k,\epsilon^l) = \mu^k+\sigma^k\odot \epsilon^l
            \end{align*}
            其中：$\epsilon^l \sim N(0,I)$；$\odot$是元素操作。于是，我们可以得到下界
            \begin{align*}
            L(\theta,\phi;x^k) = \frac{1}{2}\sum_{j=1}^{n_h} \left( 1+\log(\sigma_j^k)^2 - (\mu_j^k)^2 - (\sigma_j^k)^2 \right) + \frac{1}{L}\sum_{l=1}^L \log p_\theta(x^k|z^{k,l})
            \end{align*}
            关于$p_\theta(x^k|z)$的计算，可以用MLP来充当decoder：\ding{172}如果$x$是01二值的，则$p_\theta(x|z)$为多维伯努利分布，其MLP的结构如图(\ref{fig:MLP充当解码器示意图1})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/MLP_acts_as_decoder1.png}
            \caption{MLP充当解码器示意图1}
            \label{fig:MLP充当解码器示意图1}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：MLP充当解码器示意图1}\\
            图(\ref{fig:MLP充当解码器示意图1})中的$\hat{x}$为
            \begin{align*}
            \hat{x} = f_\sigma (W_2\mathrm{tanh}(W_1z+b_1)+b_2)
            \end{align*}
            令$\theta \overset{\Delta}{=} (W_1,W_2,b_1,b_2)$，tanh和$f_\sigma$为传递函数，于是，得到样本的概率为
            \begin{align*}
            \log p_\theta(x|z) = \sum_{i=1}^m x_i \log \hat{x}_i + (1-\hat{x}_i)\log (1-\hat{x}_i)
            \end{align*}
            \ding{173}如果$x$不是01变量，而是实值变量，设$p_\theta(z|x)$为多维高斯分布。为多维伯努利分布，其MLP的结构如图(\ref{fig:MLP充当解码器示意图2})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/MLP_acts_as_decoder2.png}
            \caption{MLP充当解码器示意图2}
            \label{fig:MLP充当解码器示意图2}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：MLP充当解码器示意图2}\\
            图(\ref{fig:MLP充当解码器示意图2})中的变量为
            \begin{align*}
            & h=\mathrm{tanh}(W_3z+b_3)\\
            & \mu=W_4h+b_4\\
            & \log \sigma^2 W_5h+b_5\\
            & \log p_\theta (x|z) = \log N(x;\mu,\sigma^2I)
            \end{align*}
            将\ding{172}或\ding{173}中的$\log_\theta p(x|z)$变为单一样本的情况，有
            \begin{align*}
            \log p_\theta (x^k|z^{k,l})
            \end{align*}
    \subsection{重要性加权自动编码器IWAE}
        \subsubsection{深层VAE}
            \par
            Importance Weighted Autoencoders是Burda等人于2015年提出的改进版的VAE。在介绍IWVAE之前，先来把VAE的层数加深。在前面的VAE中，只有一个随机层/隐含层$z$，现在，将随机层$z$加深到$I$层，即共有$I$个随机层，并且假设$p_\theta(z_i|z_{i+1})$为多维正态分布，于是
            \begin{align*}
            & p_\theta(z) = p_\theta(z_I) \prod_{i=1}^{I-1}p_\theta(z_i|z_{i+1}) = p_\theta(z_I) p_\theta(z_{I-1}|z_I) \dots p_\theta(z_1|z_2)\\
            & p_\theta(z_I) = N(z_I|0,I)\\
            & p_\theta(z_i|z_{i+1}) = N(z_i|\mu_i,\sigma_i^2)\\
            & p_\theta(x|z_1) = N(x|\mu(z_1),\sigma^2(z_1)) \quad \mathrm{or} \quad p_\theta(x|z_1) = B(z|\mu(z_1))
            \end{align*}
            其中：$\mu_i,\sigma_i$是向量。上面是解码过程(生成)，下面，给出在编码过程中模型的条件分布情况，仍然假设$q_\phi(z_i|z_{i-1})$是高斯分布
            \begin{align*}
            & q(z|x) = q_\phi(z_1|x) \prod_{i=1}^Iq_\phi(z_i|z_{i-1})\\
            & q_\phi(z_1|x) = N(z_1|\mu(x),\sigma^2(x))\\
            & q_\phi(z_i|z_{i-1}) =N(z_i|\mu(z_{i-1}),\sigma^2(z_{i-1}))\quad i=2,3,\dots,I
            \end{align*}
            \par
            我们继续讨论目标函数(对数似然)的变分下界，由Jensen不等式，有
            \begin{align*}
            \log p(x) = \log \mathbb{E}_{q_\phi(z|x)} \left[ \frac{p(x,z)}{q_\phi(z|x)}  \right] \geqslant \mathbb{E}_{q_\phi(z|x)}\left[ \log \frac{p(x,z)}{q_\phi(z|x)} \right] = L(\theta,\phi;x)
            \end{align*}
            或者是
            \begin{align*}
            \log p(x) = KL(q_\phi(z|x)||p(z|x)) + L(\theta,\phi;x)
            \end{align*}
            \par
            将$L(\theta,\phi;x)$关于$\theta,\phi$求导，由于随机采样，导致导数不可求，我们采用确定性转化技术(reparameterization trick)：原本的采样过程如图(\ref{fig:IWVAE随机采样})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/IWVAE_random_sampling.jpg}
            \caption{IWVAE随机采样}
            \label{fig:IWVAE随机采样}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：IWVAE随机采样}\\
            \begin{align*}
            z_i^l \sim q_\phi(z_i|z_{i-1}) = N(z_i|\mu(z_{i-1}),\sigma^2(z_{i-1}))
            \end{align*}
            其中：$l=1,2,\dots,L$，$L$表示第$i$层$z_i$的采样数。经过确定性转化，采样过程如图(\ref{fig:IWVAE确定性采样})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/IWVAE_Deterministic_sampling.jpg}
            \caption{IWVAE确定性采样}
            \label{fig:IWVAE确定性采样}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：IWVAE确定性采样}\\
            \begin{align*}
            z_i = g_\phi(\epsilon_i,z_{i-1}) = \mu_i(z_{i-1}) + \sigma(z_{i-1})\epsilon_i\\
            z_i^l = g_\phi(\epsilon_i^l,z_{i-1}) = \mu_i(z_{i-1}) + \sigma(z_{i-1}) \odot\epsilon_i
            \end{align*}
            其中：$\epsilon_i^l \sim p(\epsilon_i),i=1,2,\dots,I$，$\epsilon = (\epsilon_1,\epsilon_2,\dots,\epsilon_I)$，每个随机层$z_i$都有一个辅助的随机量$\epsilon_i\sim p(\epsilon_i)$，并且在$\epsilon_i$上进行$L$次采样，$z_i^l = g_\phi(\epsilon_i^l,z_{i-1})$
            \par
            使用确定性转化技术后，$L(\theta,\phi;x)$关于$\phi$可导，有
            \begin{align*}
            \frac{\partial }{\partial \phi} & = \nabla_\phi \mathbb{E} _{q_\phi(z|x)} \left[ \log \frac{p(x,z)}{q_\phi(z|x)} \right]\\
            & = \nabla_\phi \mathbb{E} _{z\sim q_\phi(z|x)} \left[ \log\frac{p(x,z)}{q_\phi(z|x)} \right]\\
            & = \nabla_\phi \mathbb{E}_{\epsilon\sim N(0,I)} \left[ \log\frac{p(x,g_\phi(\epsilon,x))}{q_\phi(g_\phi(\epsilon,x)|x)} \right]\\
            & = \mathbb{E} _{\epsilon_1,\epsilon_2,\dots,\epsilon_I \sim N(0,I)} \nabla_\phi \log\frac {p}{q_\phi}
            \end{align*}
        \subsubsection{加权VAE}
        \par
        IWVAE和VAE有相同的网络结构，不同的是，IWVAE构建了一个加权的$\log p(x)$下界。VAE的变分下界为
        \begin{align*}
        \mathcal{L}(\theta,\phi;x) = \mathbb{E}_{z\sim q_\phi(z|x)} \left[ \log \frac{p(x,z)}{q_\phi(z|x)} \right]
        \end{align*}
        IWVAE的变分下界为
        \begin{align*}
        \mathcal{L}_L(\theta,\phi;x) =\mathbb{E}_{z^1,\dots,z^L \sim q_\phi(z|x)} \left[ \log \frac 1 L \sum_{l=1}^L \frac{p(x,z^l)}{q(z^l|x)} \right]
        \end{align*}
        其中：$z^1,z^2,\dots,z^L$是从识别模型中采取的相互独立的样本，$z^1,z^2,\dots,z^L\sim q_\phi(z|x)$。我们记
        \begin{align*}
        w_l = \frac{p(x,z^l)}{q_\phi(z^l|x)}
        \end{align*}
        于是下界$\mathcal{L}_L(\theta,\phi;x)$可以写为
        \begin{align*}
        \mathcal{L}_L = \mathbb{E} \left[\log \frac{1}{L} \sum_{l=1}^L w_l \right] \leqslant \log \mathbb{E}\left[ \frac{1}{L}\sum_{i=1}^Lw_l \right] = \log p(x)
        \end{align*}
        \par
        对上面的加权目标$\mathcal{L}_L$，我们有下面结论\cite{2016.Burda}(Approdix A)：
        \begin{align*}
        \log p(x) \geqslant \mathcal{L}_{L+1} \geqslant \mathcal{L}_L \quad \forall L>0
        \end{align*}
        此外，如果$\frac{p(z|x)}{q_\phi(z|x)}$是有界的，那么，当$L\rightarrow \infty$时，有$L_L \rightarrow \log p(x)$。这个下界$\mathcal{L}_L$可以用MC方法来近似。我们从识别模型中抽取$L$个样本，$z^l,l=1,2,\dots,L$，然后再平均它们的重要性权重。有人可能会担心这个估计量有较大的方差，关于方差的计算，可以参考\cite{2016.Burda}(Approdix B)。
        \par
        下面，我们来计算下界$\mathcal{L}_L$关于$\theta,\phi$的导数。像VAE中分析的那样，我们仍然采用确定性转化技术，有
        \begin{align*}
        \frac{\partial \mathcal{L}_L(\theta,\phi;x)}{\partial \theta} & = \nabla_\theta \mathbb{E}_{z^1,z^2,\dots,z^L\sim q_\phi(z|x)} \left[ \log \frac{1}{L}\sum_{l=1}^Lw_l \right]\\
        & =\nabla_\theta \mathbb{E}_{\epsilon^1,\epsilon^2,\dots,\epsilon^L\sim N(0,I)} \left[ \log\frac{1}{L}\sum_{l=1}^L w \left( x,g_\phi(\epsilon^l,x;\theta);\theta \right)  \right]\\
        & =\mathbb{E}_{\epsilon^1,\epsilon^2,\dots,\epsilon^L\sim N(0,I)}  \left[\nabla_\theta  \log\frac{1}{L}\sum_{l=1}^L w \left( x,g_\phi(\epsilon^l,x;\theta);\theta \right)  \right]\\
       &  =\mathbb{E}_{\epsilon^1,\epsilon^2,\dots,\epsilon^L\sim N(0,I)}  \left[ \sum_{l=1}^L \tilde{w}_L\nabla_\theta\log w \left( x,g_\phi(\epsilon^l,x;\theta);\theta \right)  \right]
        \end{align*}
        其中：$\epsilon^1,\epsilon^2,\dots,\epsilon^L$是去了$L$次样本；$\epsilon^l = (\epsilon_1^l,\epsilon_2^l,\dots,\epsilon_I^l)$表示共有$I$个特征层$z$。$w_L = w(x,g(x,\epsilon^l;\theta);\theta)$是权重函数；$\tilde{w}_l = \frac{w_l}{\sum_l w_l}$是归一化权重。特别的，当$L = 1$时，$\tilde{w}_1 =1$。
        \begin{align*}
        \nabla_\theta\log w \left( x,g_\phi(\epsilon^l,x;\theta);\theta \right) &= \nabla_\theta \log p(x,g_\phi(x,\epsilon^l;\theta);\theta) \\
        &\quad - \nabla_\theta \log q_\phi (g_\phi(x,\epsilon^l;\theta)|x;\theta)
        \end{align*}
        上式中等号右边第一项鼓励生成模型(decoder)分配高的概率给每一个$z_i$(在给定$z_{i+1}$后)，它同时也鼓励识别模型(encoder)调整随机层$q_\phi(z|x)$来做更好的预测。
        \par
        关于VAE的改进，还可以参考：Laddder VariationalAutoEncoder\cite{2016.Casper};2016.Rolfe\cite{2016.Rolfe}的Discrete Variational AutoEncoder;以及2016.Suwon\cite{2016.Suwon}。
    \subsection{随机生成网络GSN}
        \par
        Generative Stochastic Networks(GSN)是Bengio于2013年提出的一种生成网络，是去噪自动编码器DAE的推广。先回顾一下DAE：我们有样本数据$X=\{x^k\}_{k=1}^m$，$X\in R^{m\times n}/\{0,1\}^{m\times n}$，设AE网络有输入层、隐含层/特征层和输出层3层，要求$p(x)$，即样本的分布。这个问题本质是一个密度函数的估计(拟合)问题，如果对$p(x)$的分布形式进行假设，比如我们假设$p(x)$是多元高斯分布，那么，只要求多元高斯中的参数$\theta$即可。DAE在原样本中加入噪声$\varepsilon$，使原始样本数据$x$变为$\tilde{x} = x+\varepsilon$，然后用$\tilde{x}$进行训练。我们设含噪声的随机变量$\tilde{x}$的分布为$C(\tilde{x}|x)$，则$\tilde{x}\sim C(\tilde{x}|x)$，训练过程为
        \begin{align*}
        & h=f_{\theta_1}(\tilde{x})\\
        & \hat{x}= g_{\theta_2}(h)
        \end{align*}
        其中：$\theta \overset{\Delta}{= } (\theta_1,\theta_2)$，$h$为特征层/隐含层。一般的目标可以是离差平方和或者极大似然函数。
        \par
        原来的对$p(x)$的估计是一个无监督问题，而我们可以将DAE视为有监督问题，就像给定$\tilde{x}$求$x$一样。我们称$\tilde{x}$是坏样本(含噪声样本/损坏样本)，对于同一个样本$x^k$，可以对其添加不同的噪声，形成不同的坏样本。如果DAE网络训练结束后($\theta$求解结束)，对于一个已经损坏的样本$\tilde{x}^*$，我们就可以给出它的估计$\hat{x}^*$。具体的对于图像识别而言，给一张含糊不清的数字图片$\tilde{x}^*$，如图(\ref{fig:DAE做图像判别的示意图})
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/DAE_for_Image_discrimination.jpg}
            \caption{DAE做图像判别的示意图}
            \label{fig:DAE做图像判别的示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：DAE做图像判别的示意图}\\
        通过DAE我们就能给出$\hat{x}^* = 3$的概率。一定要注意$p_\theta(x|\tilde{x})$是一个识别问题，像回归一样$y|x\sim N$。上面遗留的问题是：在网络参数$\theta$训练完成后，如何识别坏样本，并且这个坏样本的估计量$\hat{x}^*$的统计性质如何？对于DAE，还有一个问题，我们说DAE网络中包含了样本$x$的信息，整个样本$x$的密度函数已经估计出来了，即$p(\hat{x}|\tilde{x)}$，那如何从这个分布中采样呢？
        \par
        在回答上面两个问题之前，先来介绍一个新的网络GSN。我们说GSN是DAE的推广，DAE是在$x$中添加了噪声，自然想能否在$h$中也添加噪声，形成$\tilde{h}$？GSN的网络结构图如图(\ref{fig:GSN的网络结构示意图})所示
                \begin{figure}[H]
                  \centering
                  \begin{varwidth}[t]{\textwidth}
                    \vspace{0pt}
                \includegraphics[height=4cm]{images/GSN_net_structure1.jpg}
                  \end{varwidth}
                  \qquad
                  \begin{varwidth}[t]{\textwidth}
                    \vspace{0pt}
                    \includegraphics[height=4cm]{images/GSN_net_structure2.jpg}
                  \end{varwidth}
            \caption{GSN的网络结构示意图}
            \label{fig:GSN的网络结构示意图}
                \end{figure}
        % \textcolor[rgb]{ 1 0 0}{todo:图片:GSN的网络结构示意图}\\
        在$x$部分增加噪声$\varepsilon$，在$h$部分增加噪声$\epsilon$。问题是：GSN的求导可以进行吗？可以看到，GSN就和VAE的确定性转换技术一样，所以GAN是可以直接求导的。
        \par
        下面，来处理上面遗留的两个问题：\ding{172}损坏样本的估计；\ding{173}如何采样。先来处理第二个问题，前面介绍了各种各样的自动编码器，自动编码器内存放着数据$x$的分布，现在要从这个分布中采样。可以尝试采用前面介绍的MCMC采样。Bengio(2013)给出了一个从参数分布$p_\theta(x)$中采样的方法：通过运行马尔科夫链交替增加噪声到近似的真实分布$p(x|\tilde{x})$当中。文中表明，如果一个学习后的参数分布$p_\theta(x|\tilde{x})$接近真实分布$p(x|\tilde{x})$，在一些优良的条件下，运行一段马氏链后，平稳分布$\pi(x)$会收敛到真实分布$p(x)$。假设我们已经训练好了AE网络，从当前样本$x$开始($x$可以是一个样本，也可以是一批样本)，则由AE形成的马氏链为
        \begin{enumerate}
        \item 从当前状态$x$开始，向$x$中注入噪声$\varepsilon$，有$\tilde{x}\sim C(\tilde{x}|x)$；
        \item 将$\tilde{x}$编码。$h = f(\tilde{x})$；
        \item 解码$h$。$\hat{x} = g(h)$，且$p(x|\hat{x} =g(h)) = p(x|\tilde{x})$；
        \item 从$p(x|\hat{x}) = p(x|\tilde{x})$中采样一个状态$x$。
        \end{enumerate}
        \par
        Bengio(2014)表明，如果自动编码器$p(\hat{x}|\tilde{x})$是真实分布$p(x|\tilde{x})$的一致估计量，则上述马尔科夫链平稳分布$\pi(x)$是$x$分布$p(x)$的一致估计量(虽然是隐含的)。
        \par
        形式上，用$p_{\theta_n}(\hat{x}|\tilde{x})$表示经过$n$次训练的DAE，他表示给定$\tilde{x}\sim C(\tilde{x}|x)$后，$x$的概率分布。这个估计量$p_{\theta_n}(\hat{x}|\tilde{x})$定义了一个马尔科夫链$T_n$：不断交替采样$\tilde{x}\in C(\tilde{x}|x)$，$x \sim p_\theta(\hat{x}|\tilde{x})$。我们设$\pi_n$是$T_n$的平稳分布，则有如下定理
        \begin{theorem}
        如果$p_{\theta_n}(\hat{x}|\tilde{x})$是真实分布$p(x|\tilde{x})$的一致估计量，并且$T_n$是一个马尔科夫链，则当$n\rightarrow \infty$时，平稳分布$\pi_n(x)$收敛到数据分布$p(x)$。
        \end{theorem}
        并且，为了使上述定理可行，要求$T_n$具有遍历性。DAE的采样示意图如图(\ref{fig:DAE采样示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/DAE_sampling.jpg}
            \caption{DAE采样示意图}
            \label{fig:DAE采样示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：DAE采样示意图}\\
        图(\ref{fig:DAE采样示意图})中：马尔科夫链的每个步骤与训练好的DAE相关联，每个步骤包括：(a)通过损坏过程$C$向状态$x$中注入噪声$\varepsilon$产生$\tilde{x}$；(b)用函数$f$进行编码，产生$h = f(\tilde{x})$；(c)用函数$g$进行解码，产生用于重构分布的参数$w\overset{\Delta}{=}g(h)$，在一般的平方重构误差下，$w = \hat{x} = g(h)$；(d)给定$w$，从重构分布$p(x|w)$采样新状态$x$。
        \par
        上面给出了DAE的马尔科夫链$x_t$，$\tilde{x}\sim C(\tilde{x}|x_t)$，$x_{t+1} \sim p_\theta (x|\tilde{x}_t)$。下面给出GSN的马尔科夫链。我们将GSN中的$x$和$h$都做为马尔科夫链的状态，有
        \begin{align*}
        & h_{t+1}\sim p_{\theta_1} (h|h_t,x_t) \\
        & x_{t+1}\sim p_{\theta_2} (x|h_{t+1})
        \end{align*}
        定义
        \begin{align*}
        h_{t+1} = f_{\theta_1}(x_t,\epsilon_t,h_t)
        \end{align*}
        其中：$\epsilon_t$是引入到隐含层的噪声。可以看出DAE是GSN的特殊情况。
        \begin{theorem}
        设训练样本$x\sim p(x)$，噪声$\epsilon\sim p(\epsilon)$，并且在隐含层$h$中添加噪声
        \begin{align*}
        h_t = f_{\theta_1}(x_{t-1},\epsilon_{t-1},h_{t-1})
        \end{align*}
        考虑模型$p_{\theta_2}(x|f_{\theta_1}(x,\epsilon_{t-1},h_{t-1}))$：对一个给定的$\theta_1$，$p_{\theta_2}(x|h)$是一个$p(x|h)$的估计量。设马尔科夫链的平稳分布$\pi_n(x,h)$的边缘分布为$\pi_n(x)$，当训练次数$n\rightarrow \infty$时，$\pi_n(x)\rightarrow p(x)$。
        \end{theorem}
        \par
        GSN的马尔科夫链如图(\ref{fig:GSN马尔科夫链示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/GSN_Markov_chain_diagram.jpg}
            \caption{GSN马尔科夫链示意图}
            \label{fig:GSN马尔科夫链示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：GSN马尔科夫链示意图}\\
        % \textcolor[rgb]{1 0 0}{引入2015.Alain.G Bengio 的Fig5的右图}
        \begin{theorem}
        设$(h_t,x_t)_{t=0}^\infty$是上图定义的马尔科夫链，假设这个马尔科夫链有平稳分布$\pi(x,h)$，并且对于每一个值$(x,h)$，如果
        \begin{enumerate}
        \item 所有的$p(x_t=x|h_t=h) = g(x|h)$有相同的密度，$t \geqslant 1$；
        \item 所有的$p(h_{t+1}=h|h_t=h',x_t=x) = f(h|h',x)$有相同的密度，$t \geqslant0 $；
        \item $p(h_0=h|x_0=x) = p(h_1=h|x_0=x)$；
        \item $p(x_1=x|h_1=h) = p(x_0=x|h_1=h)$
        \end{enumerate}
        那么，对于每个值$(x,h)$，我们会有
        \begin{enumerate}
        \item $p(x_0=x|h_0=h) = g(x|h)$；
        \item $p(x_0=x|h_t=t)=p(x_0=x,h_0=h$，$t \geqslant 0$；
        \item 平稳分布$\pi(x,h)$的边缘分布$\pi(x) = p(x_0 = x)$
        \end{enumerate}
        \end{theorem}
        上述结论表明：马尔科夫链的样本与$x_0$来自相同的分布。
    \subsection{beta - VAE}
        TODO: 待补充。。。
    \subsection{MATLAB应用实例}
        \subsubsection{MATLAB自带工具}
        \par
        MATLAB自带的自动编码器命令如表(\ref{tab:Autoencoders命令})所示
        \begin{table}[htbp]
          \caption{Autoencoders命令}
          \label{tab:Autoencoders命令}
          \centering
          \begin{tabular}{l|l}
          \toprule
          命令  & 说明 \\
          \midrule
          Autoencoder &  Autoencoder class\\
          trainAutoencoder & 训练自动编码器\\
          trainSoftmaxLayer &  Train a softmax layer for classification\\
          decode & Decode encoded data\\
          encode & Encode input data\\
          generateFunction & Generate a MATLAB function to run the autoencoder\\
          generateSimulink & Generate a Simulink model for the autoencoder\\
          network  & Convert(转变) Autoencoder object into network object\\
          plotWeights &  Plot a visualization of the weights for the encoder of an autoencoder\\
          predict &  Reconstruct(重建) the inputs using trained autoencoder\\
          stack &  Stack encoders from several autoencoders together\\
          view & View autoencoder\\
          \bottomrule
          \end{tabular}
        \end{table}
        \par
        % MATLAB构建AE的示例：
        % \begin{lstlisting}[language = Matlab]
        % %% 图像分类的Stacked Autoencoders(SAE)
        % % https://cn.mathworks.com/help/nnet/examples/training-a-deep-neural-network-for-digit-classification.html
        % %% 加载数据
        % % Load the training data into memory
        % [xTrainImages,tTrain] = digitTrainCellArrayData;
        % %% TRAIN
        % %展示一些训练图片
        % clf
        % for i = 1:20
        %     subplot(4,5,i);
        %     imshow(xTrainImages{i});
        % end
        % % Training the first autoencoder
        % rng('default')
        % hiddenSize1 = 100;
        % autoenc1 = trainAutoencoder(xTrainImages,hiddenSize1, ...
        %     'MaxEpochs',400, ...
        %     'L2WeightRegularization',0.004, ...
        %     'SparsityRegularization',4, ...
        %     'SparsityProportion',0.15, ...
        %     'ScaleData', false);
        % view(autoenc1)
        % figure()
        % plotWeights(autoenc1);
        % feat1 = encode(autoenc1,xTrainImages);
        % % Training the second autoencoder
        % hiddenSize2 = 50;
        % autoenc2 = trainAutoencoder(feat1,hiddenSize2, ...
        %     'MaxEpochs',100, ...
        %     'L2WeightRegularization',0.002, ...
        %     'SparsityRegularization',4, ...
        %     'SparsityProportion',0.1, ...
        %     'ScaleData', false);
        % view(autoenc2)
        % feat2 = encode(autoenc2,feat1);
        % % Training the final softmax layer
        % softnet = trainSoftmaxLayer(feat2,tTrain,'MaxEpochs',400);
        % view(softnet)
        % % Forming a stacked neural network
        % view(autoenc1)
        % view(autoenc2)
        % view(softnet)
        % deepnet = stack(autoenc1,autoenc2,softnet);
        % view(deepnet)
        % % Get the number of pixels in each image
        % imageWidth = 28;
        % imageHeight = 28;
        % inputSize = imageWidth*imageHeight;
        % %% TEST
        % % Load the test images
        % [xTestImages,tTest] = digitTestCellArrayData;
        % % Turn the test images into vectors and put them in a matrix
        % xTest = zeros(inputSize,numel(xTestImages));
        % for i = 1:numel(xTestImages)
        %     xTest(:,i) = xTestImages{i}(:);
        % end
        % y = deepnet(xTest);
        % plotconfusion(tTest,y);
        % %% Fine tuning the deep neural network
        % % Turn the training images into vectors and put them in a matrix
        % xTrain = zeros(inputSize,numel(xTrainImages));
        % for i = 1:numel(xTrainImages)
        %     xTrain(:,i) = xTrainImages{i}(:);
        % end
        % % Perform fine tuning
        % deepnet = train(deepnet,xTrain,tTrain);
        % y = deepnet(xTest);
        % plotconfusion(tTest,y);
        % \end{lstlisting}

\section{卷积神经网络CNN}
    \subsection{基础卷积神经网络CNN}
        \par
        回忆之前提到过的网络模型，无论是MLP、Hopfield、SMO、BM、DBM、AE、VAE和GSN等，这些网络模型的输入层都是向量输入，即$x^k = (x^k_1,x_2^k,\dots,x_n^k)$，即便是批量或者全批量，也是以向量为样本的。整个样本的数据结构如图(\ref{fig:向量样本的数据示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Vector_sample_of_the_data.jpg}
            \caption{向量样本的数据示意图}
            \label{fig:向量样本的数据示意图}
            \end{figure}
        % \textcolor[rgb]{1  0 0}{todo:图片：向量样本的数据示意图}\\
        也就是说，网络输入的样本$x^k$要是一个向量，比如，对于一个图像分类问题，要先将具体的图像样本(矩阵)变为向量，然后将向量输入到网络进行分类。自然会想，能不能把图像(矩阵)直接输入到网络中，因为对于图像处理而言，我们的样本就是一个个的图像矩阵。为此，要开发一个以矩阵为输入的神经网络(以及一些矩阵对矩阵的操作)。并且注意到如果图像是批量或者全批量样本，则是一个3维矩阵(张量)。
        \par
        幸运的是，我们已经有了这样的网络。下面要介绍的CNN网络就是一个以矩阵为样本的前馈网络(如果将CNN视为MLP的矩阵推广，那么Hopfield等网络能否推广到矩阵样本？)。如前面的神经网络一样，先来介绍CNN的网络结构，再介绍它的学习方法。
        \par
        1962年，Hubel和Wiesel通过对猫视觉皮层神经元的的研究，提出了感知野(receptive field)的概念；1980年，日本学者K.Fukushima提出了神经认知机，这也是第一代卷积神经网络；1989年，加拿大教授Yann LeCun提出了卷积神经网络(Convolution Neural Networks,CNN)；2012年，深度学习大牛，DBN、DBM的开发者Hinton教授带领2个学生，采用更深的CNN在Image Net问题上取得了当时最好的结果，虽然这一结果之后一直被刷新，但CNN带来的视觉革命是不容忽视的。
        \subsubsection{CNN网络结构}
            \par
            假设有一个带标签的图像集/样本集$S = \{x^k,y^k\}_{k=1}^m$，$x^k$是一个图像矩阵，$y^k$是图像$x^k$的分类标签值。为了简便，我们将$x^k$视为$n\times n$方阵，$x^k\in R^{n\times n}/\{0,1\}^{n\times n}$，假设分类任务共有$c$类，则$y^k\in \{1,2,\dots,c\}$。现在，我们来看对于一个图片$x^k$而言，CNN的处理方式(前向传播)，其处理流程如图(\ref{fig:CNN网络结构示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=5cm]{images/CNN_net_structure.jpg}
            \caption{CNN网络结构示意图}
            \label{fig:CNN网络结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：CNN网络结构示意图}
            \par
            这里给出的CNN网络结构(\ref{fig:CNN网络结构示意图})共有7个网络层。当然，我们可以继续加深网络，但是太深的CNN在反向传播过程中会出现误差消失/梯度消失的现象，具体而言，当我们从$F_1$层开始向$C_1$层传播，到了$C_1$层时，各$\theta$所分担的误差会非常小。在上面的7层CNN中，$C_1,S_2,C_3,S_4$都是为了从$x^k$中提取/获取特征，$F_5,F_6,F_7$是一个一般的BP神经网络(其它分类器亦可)。下面，我们来介绍每一步(每一层)的操作。\\
            $1\clubsuit$：对$C_1$层而言，输入为$32\times 32$大小的样本图片$x \overset{\Delta}{=}x^k$，输出为$6$个矩阵。并且，这6个矩阵的大小为$28\times 28$，与原矩阵$32\times 32$不一样，那么$1\clubsuit$是如何操作的才能产生这种结果呢？
            \par
            $1\clubsuit$过程是卷积过程(Colution)，主要是利用卷积核(权重矩阵$w$，待求)来进行操作的。为了方便，我们设被卷积的图像$a$的大小为$5\times 5$，卷积核$w$大小为$3\times 3$，输出矩阵为$c$，则$a$到$c$的卷积过程如图(\ref{fig:卷积过程示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Colution.jpg}
            \caption{卷积过程示意图}
            \label{fig:卷积过程示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：卷积过程示意图}\\
            用$w$从$a$的左上角开始，找到同样大小的$3\times 3$局部矩阵，2个矩阵($w$和$a$的局部矩阵)对应元素相乘相加(卷积操作)，得到36；之后，再把$w$一个点一个点的向右移动，卷积形成54和72；再将$w$向下移动，以形成其它的卷积值。可以计算，如果$a$是$m\times n$大小，$w$是$mx\times my$大小，则卷积后的$c$是$my\times ny$大小，其中：$my = m-mx+1,ny= n-nx+1$。你可能会有以下问题：
            \begin{enumerate}
            \item 是否要求输入图像$x$是01值？不限制；
            \item 是否要求输入图像$x$是方阵$n\times n$？不限制，但最好是；
            \item 为什么输入一张图片，结果卷积出来了6张图片？因为有6个卷积核$w_1,w_2,\dots,w_6$，并且注意：其实多个矩阵(map)可以公用一个卷积核，卷积之后结果相加，形成一个输出。
            \end{enumerate}
            $2\clubsuit$：$C_1$到$S_2$。对$S_2$而言，输入为6张图，输出为6张图，只不过大小从输入的$28\times 28$变为了$14\times 14$。那么，这6张图在$2\clubsuit$处都经历了什么？$S_2$层是一个池化过程/采样过程，从其名称“采样”可以看出，这是一个降维操作，以降低参数个数。该过程有2种常见的采样方法：一种是均值池化mean pooling；一种是最大池化max pooling。相对常用的是max pooling。我们用一个$28\times 28$的矩阵来演示池化过程，如图(\ref{fig:池化过程示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/pooling_process.png}
            \caption{池化过程示意图}
            \label{fig:池化过程示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：池化过程示意图}\\
            把原图像($28\times 28$)中的相邻4个(上下左右)数值之间取最大值，作为输出。这样就从$28\times 28$变为$14\times 14$。当然，对于 mean pooling而言，我们取相邻的4个数值的平均作为输出。我们可以设置池化池/采样矩阵(采样矩阵的大小，例如：$4\times 4$)的大小为$m_p\times n_p$，但是，有必要让$m_y/m_p,n_y/n_p$为整数。
            \par
            考虑：1.为什么要采样；2.采样的误差传播如何进行；3.能否间隔采样。如何设计其它的采样方法，并且一定注意采样的误差传播应该易于进行。\\
            $3\clubsuit$：$C_3$为卷积层，输入6个$14\times 14$的矩阵，输出$16$个$12\times 12$的矩阵($12=14-3+1$)，$S_2\to C_3$过程为卷积过程，但是，如果我们像$1\clubsuit$那样，对输入的6个矩阵的每一个矩阵都进行6次卷积操作，那么结果应该有$6$个或者$36$个输出矩阵。这$16$个输出矩阵式如何来的？我们应该清楚一点的是，输出矩阵的多少应该由卷积核的个数控制，比如：要形成16个输出矩阵，就设置16个卷积核，对于每个卷积核而言，无论有多少个输入图像与它进行卷积，都将其得到的结果相加，以形成1个输出。所以为了有16个输出就设置16个卷积核。现在的问题是：每个卷积核都应该和那几个输入图片(共6个)进行卷积呢？当然，可以进行全连接，即每个卷积核都要卷积6个输入。但是这样做会使计算量变得很大，为此，我们采用LeNet5的非全连接策略，其连接方式如表(\ref{tab:LeNet5的连接表})所示
            \begin{table}[htbp]
              \caption{LeNet5的连接表}
              \label{tab:LeNet5的连接表}
              \centering
              \begin{tabular}{c|llllllllllllllll}
              \toprule
              $S2\to C_3$&1  &2 &3  &4  &5  &6  &7  &8  &9  &10 &11 &12 &13 &14 &15 &16 \\
              \midrule
              1          &$@$ &  &   &   &$@$ &$@$ &$@$ &   &   &$@$ &$@$ &$@$ &$@$ &   &$@$ &$@$\\
              2          &$@$ &$@$&   &   &   &$@$ &$@$ &$@$ &   &   &$@$ &$@$ &$@$ &$@$ &   &$@$\\
              3          &$@$ &$@$&$@$ &   &   &   &$@$ &$@$ &$@$ &   &   &$@$ &   &$@$ &$@$ &$@$\\
              4          &   &$@$&$@$ &$@$ &   &   &$@$ &$@$ &$@$ &$@$ &   &   &$@$ &   &$@$ &$@$\\
              5          &   &  &$@$ &$@$ &$@$ &   &   &$@$ &$@$ &$@$ &$@$ &   &$@$ &$@$ &   &$@$\\
              6          &   &  &   &$@$ &$@$ &$@$ &   &   &$@$ &$@$ &$@$ &$@$ &   &$@$ &$@$ &$@$\\
              \bottomrule
              \end{tabular}
            \end{table}
            表(\ref{tab:LeNet5的连接表})中画$@$的表示对应的神经元(矩阵)连接，否则不连接。例如：$C_3$的第一个矩阵为
            \begin{align*}
            C_3^1 = f(S_2^1 w_1 + S_2^2 w_1 + S_2^3 w_1 + b)
            \end{align*}
            当然，这里还可以采取其他的非全连接方式。\\
            $4\clubsuit$：$S_4$为采样层(down sample)。如前，输入16个$12\times 12$矩阵，输出16个$6\times 6$矩阵。\\
            $5\clubsuit$：$F_5$为展开的特征层。该层的操作只是将$S_4$层得到的16个$6\times 6$矩阵展开合并为1个向量，以便输入到后面的神经网络等基本分类器当中。其实，$F_5$不仅可以在采样层$S_4$后对其展开，也可以在卷积层后对卷积层展开。\\
            $6/7\clubsuit$：是一个简单的分类器，比如BP和Softmax等。
            \par
            通过上面的分析，已经基本了解了CNN的网络结构与基本的操作(卷积和池化)。注：能否设置一个动态网络，随着训练的不断进行，网络结构也在发生变化？上面只是简单的描述了一下CNN的前向传播过程，下面，来建立数学模型，并求解网络参数(反向传播)。
        \subsubsection{CNN训练方式}
            \par
            先将CNN网络描述成神经元的形式，如图(\ref{fig:CNN网络的神经元形式})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/CNN_neural_form_of_the_network.jpg}
            \caption{CNN网络的神经元形式}
            \label{fig:CNN网络的神经元形式}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：CNN网络的神经元形式}\\
            图(\ref{fig:CNN网络的神经元形式})中的每一个神经元表示一个矩阵(map)。更一般的，设样本集为$S = \{x^k,y^k\}_{k=1}^N $，共有$c$类，$y^k \in \{1,2,\dots,c\}$。设CNN网络共有$L$层(输入$x$不算一层)，各层神经元个数为$n_l(l=1,2,\dots,L)$，记第$l$层神经元为$x^l$，$x^l = (x_1^l,x_2^l,\dots,x_{n_l}^l)$，$x_i^l$是矩阵(除了后面的BP分类器中的神经元外)。第$i$个神经元与第$j$个神经元连接的权重为$w_{ij}$(当然，许多神经元共用一个卷积核$w$)，一般的，有几个输出图像就有几个卷积核。$b_j^l$为$l$层神经元$j$的偏置。
            \paragraph{CNN前向传播}(1)对卷积层而言，其输入输出可以表示为
            \begin{align*}
            x_j^l = f \left( \sum_{i=1}^{n_{l-1}}x_i^{l-1}\oplus w_{ij}^l + b_j^l \right)
            \end{align*}
            其中：$f$为普通可导函数，$\oplus$表示卷积等操作，并且是$l-1$层所有的神经元与$l$层的$j$神经元连接，且连接的各卷积核$w_{ij}$是不同的，这是一般的表述方式。我们记
            \begin{align*}
            u_j^l = \sum_{i=1}^{n_{l-1}}x_i^{l-1}\oplus w_{ij}^l + b_j^l
            \end{align*}
            为第$l$层第$j$神经元的输入，则$x_j^l$为其输出。
            \par
            (2)对池化层而言(采样层)，其输入输出的表达式为
            \begin{align*}
            x_j^l = f \left( \beta_j^l \mathrm{down} \left( x_j^{l-1} \right)  + b_j^l \right)
            \end{align*}
            其中：$\mathrm{down}(x)$是对矩阵$x$进行下采样操作(均值池化、最大值池化)，$\beta_j^l,b_j^l$为偏置。令
            \begin{align*}
            u_j^l = \beta_j^l \mathrm{down} \left( x_j^{l-1} \right)  + b_j^l
            \end{align*}
            为第$l$层第$j$个神经元的输入，$x_j^l$为其输出。
            \par
            (3)对小分类器而言
            \begin{align*}
            x^l = f(w^lx^{l-1}+b^l)\\
            \end{align*}
            或者写为
            \begin{align*}
            x_j^l = f \left( w_{\cdot j}^l x^{l-1} + b_j^l \right) = f \left(  \sum_{i=1}^{n_{l-1}}x^{l-1}+b_j^l \right)
            \end{align*}
            我们仍然令
            \begin{align*}
            u^l = w^lx^{l-1}+b^l
            \end{align*}
            为第$l$层的输入，$x^l$为输出。
            \paragraph{CNN反向传播}先来表示网络输出值$t$和样本真实值的误差，以便构建“离差平方和目标”。
            对于$N$个样本$S=\{x^k,y^k\}_{k=1}^N$，$c$个类别，其误差平方可以表示为
            \begin{align*}
            E = \frac{1}{2}\sum_{n=1}^N\sum_{k=1}^c (t_k^n-y_k^n)^2
            \end{align*}
            其中：$t^n$表示第$n$个样本的网络输出值/估计值。记$e^n\in R^c/\{0,1\}^c$为第$n$个样本的误差，$E^n$为第$n$个样本的误差平方，有
            \begin{align*}
            & E = \sum_{n=1}^N E^n\\
            & E^n = \frac{1}{2}\sum_{k=1}^c (t_k^n - y_k^n)^2 = \frac{1}{2}||t^n - y^n||^2
            \end{align*}
            令$\theta \overset{\Delta}{=} (w,b)$。$E$关于$\theta$求导，有
            \begin{align*}
            \frac{\partial E}{\partial \theta} = \sum_{n=1}^N \frac{\partial E^n}{\partial \theta}
            \end{align*}
            下面，来求解$ \frac{\partial E^n}{\partial \theta}$。
            \par
            (1)对小分类器而言，和前面介绍的BP是一样的，这里我们再写一次。
            \begin{align*}
            E^2 = \frac{1}{2}||f(u^L) - t^n||^2 = \frac{1}{2}||f(w^Lx^{l-1}+b^L) - t^n||^2 = \frac{1}{2} ||y^n - t^n||^2
            \end{align*}
            对所有的$l$(小分类器的层)，$E^n$关于$b$求导有
            \begin{align*}
            \frac{\partial E^n}{\partial b^L} = \frac{\partial E^n}{\partial u^L} \frac{\partial u^L}{\partial b^L}
            \end{align*}
            而$\frac{\partial u^L}{\partial b^L} = 1$，所以我们要求$\frac{\partial E^n}{\partial u^l}$。定义$\delta^L = \frac{\partial E^n}{\partial u^l}$，有
            \begin{align*}
            & \delta^L = \frac{\partial E^n}{\partial u^L} = \frac{\partial }{\partial u^L}\frac{1}{2}||f(u^L) - t^n||^2 = (f(u^L )-t^n) f'(u^L) = e^n f'(u^L)\\
            & \delta ^l = \frac{\partial E^n}{\partial u^l} (w^{l+1})^\mathrm{T}\delta^{l+1}f'(u^l)\quad l=L-1,L-2,\dots,
            \end{align*}
            同理，$E^n$关于$w$求导，有
            \begin{align*}
            \frac{\partial E^n}{\partial w^l} = \frac{\partial E^n}{\partial u^l}\frac{\partial u^l}{\partial w^l} = x^{l-1}(\delta^l)^\mathrm{T}
            \end{align*}
            \par
            (2)对卷积层而言。卷积层的反向传播示意图如图(\ref{fig:卷积层的反向传播示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/The_reverse_propagation_of_the_convolution_layer.jpg}
            \caption{卷积层的反向传播示意图}
            \label{fig:卷积层的反向传播示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：卷积层的反向传播示意图}
            \begin{align*}
            \delta_j^l = \beta_j^{l+1} \left( f'(u_j^l)\cdot \mathrm{up}(\delta_j^{l+1}) \right)
            \end{align*}
            其中：$\mathrm{up}(\cdot)$是上采样操作，与$\mathrm{down}(\cdot)$相反。如果下采样的池化池/采样矩阵的大小为$n\times n$，则$\mathrm{up}(x)$写为
            \begin{align*}
            \mathrm{up}(x) = x \otimes I_{n\times n}
            \end{align*}
            这里的$\otimes $表示Kronecker乘积。比如，在$S$层中第一个神经元的误差矩阵为
            \begin{align*}
            e=
            \begin{pmatrix}
            1 & 2\\
            3 & 4
            \end{pmatrix}
            \end{align*}
            而$S$的第一个神经元是$C$的第一个神经元经过最大下采样缩小2倍($n=2$)得到的，那么
            \begin{align*}
            \mathrm{up}(e) =
            \begin{pmatrix}
            1 & 1 & 2 & 2\\
            1 & 1 & 2 & 2\\
            3 & 3 & 4 & 4\\
            3 & 3 & 4 & 4\\
            \end{pmatrix}
            \end{align*}
            \par
            现在，得到了$l$层神经元$j$的误差$\delta_j^l$，接下来，要把误差下分到权重$w_j^l$和$b_j^l$上
            \begin{align*}
            & \frac{\partial E^n}{\partial b_j} = \sum_{u,v} \left( \delta_j^l \right)_{uv} \\
            & \frac{\partial E^n}{\partial w_{ij}^l} = \sum_{u,v} \left( \delta_j^l \right)_{uv} \left( p_i^{l-1} \right)_{uv}
            \end{align*}
            其中：$ \sum_{u,v} \left( \delta_j^l \right)_{uv}$表示将$\delta_j^l$逐元素相加，$(p_i^{l-1})_{uv}$是$x_i^{l-1}$在卷积时候，与$w_{ij}^l$逐元素相乘的pitch，输出卷积层某个图像的$uv$位置是由上一层$uv$位置的pitch与卷积核$w_{ij}^l$逐元素相乘的结果。在MATLAB中可以通过下面的命令实现
            \begin{align*}
            \frac{\partial E^n}{\partial w_{ij}^l} = \mathrm{rot}180 (\mathrm{conv2}(x_i^{l-1},\mathrm{rot180}(\delta_j^l),'valid'))
            \end{align*}
            示例：卷积层的误差传递如图(\ref{fig:卷积层误差传递示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Convolution_layer_error_transfer_diagram.jpg}
            \caption{卷积层误差传递示意图}
            \label{fig:卷积层误差传递示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：卷积层误差传递示意图}\\
            假设$l+1$层的pool层大小为$2\times 2$，并且此时pool后的$\delta_j^{l+1}$是
            \begin{math}
            \left(
            \begin{smallmatrix}
            1 & 3\\
            2 & 4
            \end{smallmatrix}
            \right)
            \end{math}
            \ding{172}如果将$l$层(卷积层)mean pool到$l+1$层，则$l$层$\delta_j^l$应为$4\times 4$，为
            \begin{align*}
            \mathrm{up}(\delta_j^{l+1}) =
            \begin{pmatrix}
            1 & 1 & 3 & 3\\
            1 & 1 & 3 & 3\\
            2 & 2 & 4 & 4\\
            2 & 2 & 4 & 4\\
            \end{pmatrix}
            \end{align*}
            又因为是均值采样且反向传播时，误差总和不变，所以卷积层$l$要对每个值平摊，于是误差变为
            \begin{align*}
            \begin{pmatrix}
            0.25 & 0.25 & 0.75 & 0.75\\
            0.25 & 0.25 & 0.75 & 0.75\\
            0.5  & 0.5  & 1    & 1   \\
            0.5  & 0.5  & 1    & 1   \\
            \end{pmatrix}
            \end{align*}
            $\mathrm{up}(x)$可以通过MATLAB中的kron函数实现。\ding{173}如果是将$l$层max pool到$l+1$层，则需要在前向传播中记录pool区域中的最大值的位置，以便把误差分给相应位置。假如我们在
            \begin{math}
            \left(
            \begin{smallmatrix}
             & & &*\\
             &*& & \\
            *& & & \\
             & &*& \\
            \end{smallmatrix}
            \right)
            \end{math}
            位置取得最大值，则
            \begin{align*}
            \delta_j^l =
            \begin{pmatrix}
            0 & 0 & 0 & 3\\
            0 & 1 & 0 & 0\\
            2 & 0 & 0 & 0\\
            0 & 0 & 4 & 0\\
            \end{pmatrix}
            \end{align*}
            \par
            上面给出了$\delta_j^l$的求法，现在给出$\frac{\partial E^n}{\partial b_j^l},\frac{\partial E^n}{\partial w_{ij}^l}$的求法。这里不考虑非线性函数$f$和$\beta_j^l$，因此，pool层前面是没有权值的，也就没有所谓的权值的导数了。假设现在要求
            \begin{align*}
            & \frac{\partial E^n}{\partial b_j} = \sum_{u,v} \left( \delta_j^l \right)_{uv} \\
            & \frac{\partial E^n}{\partial w_{ij}^l} = x_i^{l-1}\odot \delta_j^l
            \end{align*}
            其中：$\odot$表示矩阵相关操作(反卷积)，可以用conv2函数实现，但是要将$\delta_j^l$旋转$180^\circ$，即
            \begin{align*}
            \mathrm{conv2}(x_i^{l-1},\mathrm{rot180}(\delta_j^l),'valid')
            \end{align*}
            设第$l-1$层的第$i$个图像(矩阵)$x_i^{l-1}$大小为$4\times 4$的
            \begin{math}
            \left(
            \begin{smallmatrix}
            16 & 2  & 3  & 13\\
            5  & 11 & 10 & 8 \\
            9  & 7  & 6  & 12\\
            4  & 14 & 15 & 1 \\
            \end{smallmatrix}
            \right)
            \end{math}
            ，第$l$层的第$j$个神经元的误差$\delta_j^l$为$3\times 3$的
            \begin{math}
            \left(
            \begin{smallmatrix}
            0.8  & 0.1 &  0.6\\
            0.3  & 0.5 &  0.7\\
            -0.4 & 0   & -0.2\\
            \end{smallmatrix}
            \right)
            \end{math}
            ，这时的$w_{ij}^l$的导数矩阵的大小为$2\times 2$且其结果为
            \begin{align*}
            \begin{pmatrix}
            16 & 2  & 3  & 13\\
            5  & 11 & 10 & 8 \\
            9  & 7  & 6  & 12\\
            4  & 14 & 15 & 1 \\
            \end{pmatrix}
            \odot
            \begin{pmatrix}
            0.8  & 0.1 &  0.6\\
            0.3  & 0.5 &  0.7\\
            -0.4 & 0   & -0.2\\
            \end{pmatrix}
            =
            \begin{pmatrix}
            20.4 & 2.8\\
            4.9 & 12.7\\
            \end{pmatrix}
            \end{align*}
            此时偏置$b_j^l$的导数为1.2，即将$\delta_j^l$的元素相加即可$0.8+0.1-0.6+0.3+0.5+0.7-0.4-0.2=1.2$。
            \par
            (3)对池化层而言。这里最困难的是计算$\delta_j^l$，一旦得到了它，我们只要更新偏置参数$\beta,b$就可以了。如果池化层$l$与下一层卷积层$l+1$是全连接，那么就可以通过BP来计算采样层$\delta_j^l$了。要计算卷积核的梯度，所以必须要找到输入矩阵中哪部分(patch)对应输出矩阵的哪一个像素。这里，要找到当前层(pool)的$\delta_j^l$矩阵的哪一patch对应下一层(卷积层)的$\delta^{l+1}$的给定像素，然后用反向传播传递回来
            \begin{align*}
            \delta_j^l = f'(u_j^l)\cdot \mathrm{conv2} \left( \delta_j^{l+1},\mathrm{rot180}(k_j^{l+1}),'full' \right)
            \end{align*}
            \par
            下面，就可以把误差/灵敏度$\delta_j^l$传递给$\beta,b$了
            \begin{align*}
            \frac{E^n}{\partial b_j^l} =  \sum_{u,v}(\delta_j^l)w
            \end{align*}
            而对于乘性偏置$\beta$，因为涉及到了前向传播中下采样的计算，所以，最好在前向传播中保存好这些矩阵，这样，在反向传播中就不用重新计算了。令
            \begin{align*}
            d_j^l = \mathrm{down}(x_j^{l-1})
            \end{align*}
            则
            \begin{align*}
            \frac{\partial E^n}{\partial \beta_j} = \sum_{u,v} \left( \delta_j^l d_j^l \right) _{uv}
            \end{align*}
            示例：池化层的反向传播示意图如图(\ref{fig:池化层的反向传播示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/The_reverse_propagation_of_the_pool_layer.jpg}
            \caption{池化层的反向传播示意图}
            \label{fig:池化层的反向传播示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片:池化层的反向传播示意图}\\
            假设$l$层的某个矩阵$x_j^l$的大小为$3\times 3$，第$l+1$层有2个卷积核$w_1^l,w_2^l$，卷积核的大小为$2\times 2$，则在前向传播时，第$l+1$层会有2个$2\times 2$的输出矩阵$x^{l+1}$。设2个卷积核为
            \begin{math}
            \left(
            \begin{smallmatrix}
            0.1 & 0.2 \\
            0.2 & 0.4\\
            \end{smallmatrix}
            \right)
            \end{math}
            和
            \begin{math}
            \left(
            \begin{smallmatrix}
            -0.3 & 0.1 \\
            0.1 & 0.2\\
            \end{smallmatrix}
            \right)
            \end{math}
            。反向传播时，假设已经知道第$l+1$层2个输出图的误差$\delta_1^{l+1}$和$\delta_2^{l+2}$为
            \begin{math}
            \left(
            \begin{smallmatrix}
            1& 3 \\
            2& 2\\
            \end{smallmatrix}
            \right)
            \end{math}
            和
            \begin{math}
            \left(
            \begin{smallmatrix}
            2& 1 \\
            1& 1\\
            \end{smallmatrix}
            \right)
            \end{math}
            。注：1.矩阵大小为多大，误差$\delta$就为多大，每个矩阵元素都有误差/灵敏度；2.假设pool到conv是全连接。
            \par
            那么，我们就将$w_j^{l+1}$和$\delta_j^{l+1}$实现conv2操作
            \begin{align*}
            \mathrm{conv2}(\delta_j^{l+1},\mathrm{rot180}(w_j^{l+1}),'full')
            \end{align*}
            其中，conv2将$\delta_j^{l+1}$填充'full'为
            \begin{math}
            \left(
            \begin{smallmatrix}
            0 & 0 & 0 & 0\\
            0 & 1 & 3 & 0\\
            0 & 2 & 2 & 0\\
            0 & 0 & 0 & 0\\
            \end{smallmatrix}
            \right)
            \end{math}
            和
            \begin{math}
            \left(
            \begin{smallmatrix}
            0 & 0 & 0 & 0\\
            0 & 2 & 1 & 0\\
            0 & 1 & 1 & 0\\
            0 & 0 & 0 & 0\\
            \end{smallmatrix}
            \right)
            \end{math}
            然后再和旋转$180^\circ$的$w_j^{l+1}$进行卷积操作，有
            \begin{align*}
            &
            \begin{pmatrix}
            0 & 0 & 0 & 0\\
            0 & 1 & 3 & 0\\
            0 & 2 & 2 & 0\\
            0 & 0 & 0 & 0\\
            \end{pmatrix}
            \odot
            \begin{pmatrix}
            0.1 & 0.2 \\
            0.2 & 0.4 \\
            \end{pmatrix}
            =
            \begin{pmatrix}
            0.1 & 0.5 & 0.6\\
            0.4 & 1.6 & 1.6\\
            0.4 & 1.2 & 0.8\\
            \end{pmatrix}\\
            &
            \begin{pmatrix}
            0 & 0 & 0 & 0\\
            0 & 2 & 1 & 0\\
            0 & 1 & 1 & 0\\
            0 & 0 & 0 & 0\\
            \end{pmatrix}
            \odot
            \begin{pmatrix}
            -0.3 & 0.1 \\
            0.1 & 0.2 \\
            \end{pmatrix}
            =
            \begin{pmatrix}
            -0.6 & -0.1 & 0.1\\
            -0.1 & 0.3 & 0.3\\
            0.1 & 0.3 & 0.2\\
            \end{pmatrix}
            \end{align*}
            则$l$层$j$矩阵的灵敏度$\delta_j^l$为$3\times 3$，是上述2个矩阵的和
            \begin{align*}
            \delta_j^l =
            \begin{pmatrix}
            0.1 & 0.5 & 0.6\\
            0.4 & 1.6 & 1.6\\
            0.4 & 1.2 & 0.8\\
            \end{pmatrix}
            +
            \begin{pmatrix}
            -0.6 & -0.1 & 0.1\\
            -0.1 & 0.3 & 0.3\\
            0.1 & 0.3 & 0.2\\
            \end{pmatrix}
            =
             \begin{pmatrix}
            -0.5 & 0.4 & 0.9\\
            0.3 & 1.9 & 1.9\\
            0.5 & 1.5 & 1\\
            \end{pmatrix}
            \end{align*}
            \par
            (4)学习特征矩阵的组合。大部分时候，通过卷积多个输入矩阵(maps)，然后再对这些卷积值求和得到一个输出map，这样做的效果往往较好。在一些文献中，如LeNet中，一般是选择哪些输入maps组合在一起进行输入。现在，我们让CNN在训练过程中自己学习这些组合，即让网络自己挑选哪些输入maps进行组合。我们用$\alpha_{ij}$表示第$j$个输出的map中的$i$个输入map的权重或贡献。这样，第$j$个输出map就可以表示为
            \begin{align*}
            x_j^l =f \left( \sum_{i=1}^{n_l-1} \alpha_{ij}(x_i^{l-1}\oplus w_i^l) + b_j^l \right)
            \end{align*}
            要求$\alpha_{ij}$要满足
            \begin{align*}
            &\sum_i \alpha_{ij} = 1\\
            &0 \leqslant \alpha_{ij} \leqslant 1
            \end{align*}
            上述约束可以通过将变量$\alpha_{ij}$表示为一组无约束的隐含权值$c_{ij}$的softmax函数来加强(因为softmax的因变量是自变量的指数函数，它们的变化率会不同)
            \begin{align*}
            \alpha_{ij} = \frac{e^{c_{ij}}}{\sum_ke^{c_{kj}}}
            \end{align*}
            \par
            因为对于一个固定的$j$而言，每组权值$c_{ij}$都是和其它组的权值独立的，所以为了方便描述，我们把下标$j$去掉，只考虑一个map的更新，其他map的更新情况是一样的，只是索引$j$不同而已。softmax函数的导数表示为
            \begin{align*}
            \frac{\partial \alpha_k}{\partial c_i} = \delta_{ki}\alpha_i - \alpha_i\alpha_k
            \end{align*}
            这里的$\delta$是Kronecker delta。误差$E^n$对第$l$层变量$\alpha_i$的导数为
            \begin{align*}
            \frac{\partial E^n }{\partial \alpha_i} = \frac{\partial E^n}{\partial u^l} \frac{\partial u^l}{\partial \alpha_i} = \sum_{uv} \left( \delta ^l\odot(x_i^{l-1}\oplus w_i^l)  \right)
            \end{align*}
            其中：$\odot$表示元素操作，$\oplus$表示卷积操作。最后，$E^n$对$c_i$求导，有
            \begin{align*}
            \frac{\partial E^n}{\partial c_i} &= \sum_k \frac{\partial E^n}{\partial \alpha_k}\frac{\partial \alpha_k}{\partial c_i}\\
            &=\alpha_i \left( \frac{\partial E^n}{\partial \alpha_i} - \sum_{k}\frac{\partial E^n}{\partial \alpha_k}\alpha_k \right)
            \end{align*}
            \par
            (5)强加稀疏性组合。为了限制$\alpha_i$是稀疏的，也就是限制一个输出map与某些而非全部输入maps链接，我们在整体代价函数中增加稀疏约束项$\Omega(\alpha)$。对单一样本而言，重写代价函数为
            \begin{align*}
            \tilde{E}^n = E^n + \lambda \sum_{i,j} |(\alpha)_{ij}| = E^n + \Omega(\alpha)
            \end{align*}
            我们仍将$\tilde{E}^n$关于参数求导，这里主要是$\Omega(\alpha)$对权值$c_i$求导。先求$\Omega(\alpha)$关于$\alpha_i$的导数，再求对$c_i$的导数，有
            \begin{align*}
            & \frac{\partial \Omega}{\partial \alpha_i} = \alpha \mathrm{sign}(\alpha_i)\\
            \end{align*}
            所以权重$c_i$的梯度为
            \begin{align*}
            \frac{\partial \tilde{E}}{\partial c_i} = \frac{\partial E}{\partial c_i} + \frac{\partial \Omega }{\partial c_i}
            \end{align*}
        \subsubsection{CNN的问题}
            \par
            % \textcolor[rgb]{1 0 0}{(1)自带
            % (2)DeepLearnToolbox
            % }
            \begin{enumerate}
            \item 梯度消失。无论是ANN(MLP)、CNN还是后面要介绍的RNN，如果网络层数过多，就会出现梯度消失/爆炸现象。比如：$\frac{\partial E}{\partial w^l}$，当$L$很大而$l =1$时，$\frac{\partial E}{\partial w^1} = (10^{-10})_{n\times n}$。这时权重$w$的更新非常小，几乎不动。解决方法：1.减少层数$L$；2.增大学习率$\eta$；3.使用ReLu作为传递函数。
            \item 随机梯度下降的参数选取。如何选取批量样本大小以及学习率$\eta$。
            \item 参数$\theta \overset{\Delta }{=}(w,b)$的初始化。
            \item 样本归一化。
            \end{enumerate}

    \subsection{AlexNet}
        \par
        2012年，Hinton教授及其2个学生Alex kvizhevsky和Ilya Sutskever提出一种改进的深层CNN网络 - AlexNet，并将其运用到Image Net的ILSVRC2012中，取得了当时最好的成绩：在top-1和top-5上的误差率为$37.5\%$和$17.0\%$。
        \par
        ImageNet(http://www.image-net.org)是李菲菲组的图像库。ImageNet设想为全世界的教育工作者、研究工作者提供图片资源。ImageNet不拥有图片的版权，只提供图片的缩略图和url。从某种程度上讲，它可以视为图像搜索引擎。ILSVRC使用ImageNet的一个子集，共1000个类别，每个类别大约包含1000张图片，训练集为12万张，验证集为5万张，测试集为1万张。输入图像的大小为$256\times 256 \times 3$。在AlexNet网络中，随机提取$224\times 224$个像素点，然后crop\footnote{注：crop为将图片进行4个边界crop和中心crop。}。crop后实际输入到AlexNet网络的图像大小为$227\times 227\times 3$(RGB图像)。
        \par
        AlexNet是一种经典的DeepCNN，它由5层convolution layer、2层fully connected layer和1个label layer(1000类)组成，是一个8层的CNN网络，但是这里的Convolution layer和CNN中的不同，它是许多网络层的组合，比如：convolution layer1是由1个卷积层、1个maxpool和1个LRN共同构成。AlexNet的网络结构如图(\ref{fig:AlexNet网络结构图1})所示
            \begin{figure}[H]
            \centering
            \includegraphics[width=8cm]{images/AlexNet1.jpg}
            \caption{AlexNet网络结构图1}
            \label{fig:AlexNet网络结构图1}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：AlexNet网络结构图1}
        \par
        从上面的网络示意图(\ref{fig:AlexNet网络结构图1})中，我们可以看到，与传统的CNN相比，AlexNet除了网络层数更深之外，还多了Relu和LRN层。这个大的网络包含了6千万个参数和65万个神经元，并利用了Rleu、dropout、data augmentation等技术来防止过拟合。下面，我们来介绍AlexNet中的这些技术。
        \par
        (1)Relu。在前面的神经网络章节中，介绍传递函数时，我们已经介绍了Relu传递函数。我们用Relu来代替传统的sigmoid函数，其好处有3，\ding{172}在采用sigmoid传递时，计算需要指数运算，此运算相对而言计算量大，并且，在反向传播求梯度时，求导涉及到除法，除法的计算量仍然大；\ding{173}在sigmoid传递时，当网络深度很大时，容易出现梯度消失现象，因为在sigmoid接近饱和区域时，变化太缓慢，梯度趋于0，造成信息损失；\ding{174}Relu使一部分神经元的输出为0，使网络具有稀疏性，并减少了参数的相互依赖关系。
        \par
        (2)Local Response Normalization, LRN(局部归一化)。Relu传递函数本身其实是不对输入做归一化的，从而避免出现饱和现象。如果训练样本经过卷积网络产生正响应输入到Relu的，则就可以对该神经元的参数进行相应的学习，不过AlexNet发现，在Relu后面加上一个局部归一化部分，则会使网络达到更好的泛化效果
        \begin{align*}
        b_{xy}^i = a_{xy}^i\Bigg/ \left( k+\alpha\sum_{j=\max(0,i-n/2)}^{\min (N-1,i+n/2)} (a_{xy}^i)^2\right)^\beta
        \end{align*}
        其中：$a_{xy}^i$表示输入maps的$(x,y)$位置做第$i$次卷积并通过Relu单元的结果，而$b_{xy}^i$是相应归一化的结果，$n$是指相同位置的第$i$次前后附近的卷积核的数目，而$N$是总的卷积次数。选取邻近的$n$个特征图(maps)，在maps的空间位置$(x,y)$一次平方，然后求和，乘以$\alpha$，加上$k$。Alex在原文中是$k=1$，$n=5$，$\alpha=10^{-4}$，$\beta = 0.75$，并且与不做局部归一化进行比较，在top-1和top-5上分别提到了$1.4\%$和$1.2\%$，并且在CIFAR10中的结果也有提高。
        \par
        (3)重叠pooling层。普通的采样层(如前面CNN的池化层那样)，采样窗口大小为$2\times 2$。我们可以以步长$s$进行划分，如果是普通采样，$s=z(=2)$，即采样窗口不重叠，我们利用$z\times z$大小的采样窗口，隔$s$步($s$个像素点)蹦一下，进行采样。而重叠pool就像它的名字一样，前后2个采样窗口$(z\times z)$是有重叠的，即$s<z$。无重叠pool如图(\ref{fig:有无重叠的pool示意图})(a)所示，有重叠pool如图(\ref{fig:有无重叠的pool示意图})(b)所示
            \begin{figure}[H]
              \centering
              \begin{varwidth}[t]{\textwidth}
                \vspace{0pt}
                \includegraphics[height=4cm]{images/yes_or_no_overlapping_pool1.jpg}
              \end{varwidth}
              \qquad\qquad
              \begin{varwidth}[t]{\textwidth}
                \vspace{0pt}
                \includegraphics[height=4cm]{images/yes_or_no_overlapping_pool2.jpg}
              \end{varwidth}
                \caption{有无重叠的pool示意图}
                \label{fig:有无重叠的pool示意图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：有无重叠的pool示意图}\\
        当然，如果采用有重叠的pool方式\footnote{注：有学者认为，在训练一个良好的生成模型时，弃用pool层也是很重要的，如VAE和GAN。}，可能使采样结果重复(对maxpool而言)。另外，实验表明，maxpool优于meanpool。Alex实验表明，使用$s=2,z=3$的有重叠pool比使用$s=z=2$的无重叠pool效果要好，在top-1和top-5上提高$0.4\%$和$0.3\%$。
        \par
        (4)过拟合。AlexNet网络有6千万个参数，而训练样本的类别只有1000类，这不足以让我们来学习这么大的网络，因此我们要考虑网络的过拟合。文中提到了2个防止过拟合的策略，一个是Data Augmantation(这个我们不介绍)，一个是dropout。组合预测是一种非常成功的减小预测误差的手段，但它训练要花费好几天的时间，对大型网络而言，更是困难。然而，最近推出的dropout技术是一种非常有效的模型组合方法，它的训练只花费2倍的单模型的时间。dropout是Hinton在Improving neural networks by preventing co-adaption中提出的，以0.5概率随机将隐含层中的各神经元输出置为0。以这种方式丢弃的神经元既不参与前向传播，也不参与反向传播，所以对每个输入样本而言，该神经网络都是一个随机得到不确定的网络。但是，所有这些结构之间共享权重，即权重的更新照旧。这样得到的参数能够适应不同情况下的网络结构，提高了系统的鲁棒性。AlexNet的前2个full connected(FC)层使用了dropout方法，所以在测试时，应该注意，对每个被dropout的神经元的输出乘上一个0.5，以合理的逼近预测输出分布的几何均值。
        \par
        (5)学习过程。下面介绍的内容在本书的其它部分皆有详细的介绍。AlexNet网络的目标函数可以设置为1.log-loss；2.softmax log-loss；3.p-distance loss。对于AlexNet训练参数的设置，AlexNet训练时使用批量梯度下降算法SGD，批量大小(batch size)为128。参数更新使用动量(momentum)更新方法，weight deccy设置为0.0005，更新公式为
        \begin{align*}
        & v_{i+1} = 0.9v_i-0.0005\cdot\epsilon\cdot w_i - \epsilon\cdot\Big<\frac{\partial L}{\partial w}\Big |_{w_i}\Big>_{D_i}\\
        & w_{i+1} = w_i+v_{i+1}
        \end{align*}
        其中：$i$为第$i$个批量样本(每个批量更新一次参数)，$v$为动量，$\epsilon$为学习率，$\Big<\frac{\partial L}{\partial w}\Big |_{w_i}\Big>_{D_i}$是第$i$个批量$D_i$的目标$L$关于$w$的方向导数在$w_i$的值。
        \par
        网络的初始权重为$w_0\sim N(0,0.01)$，而2、4、5卷积层的偏置b及全连接层FC的偏置初始化都为1，剩下的偏置初始化为0。对于学习率$\epsilon$，每次对当前的学习率除以10，直到交叉验证CV的error rale不再更新为止。Alex的学习率初始值为0.01，验证3次就终止。AlexNet在ImageNet的1.2百万张图片上，大概90次停止，在NVIDIA GTX 580 GPU上跑了5到6天。
        \par
        (6)网络框架。进入CNN，我们也基本上正式进入了深度学习搭建、调参之旅，说实话，旅途坑很多。这里插入2张图片(\ref{fig:AlexNet网络框架图})，上图是AlexNet的网络数字流程图，下图是AlexNet的双GPU图。
        \begin{figure}[H]
          \centering
          \begin{varwidth}[t]{\textwidth}
            \vspace{0pt}
            \includegraphics[height=4cm]{images/AlexNet_net_digital_flow_chart.jpg}
          \end{varwidth}
          \qquad
          \begin{varwidth}[t]{\textwidth}
            \vspace{0pt}
            \includegraphics[height=4cm]{images/AlexNet_double_GPU.jpg}
          \end{varwidth}
          \caption{AlexNet网络框架图}
          \label{fig:AlexNet网络框架图}
        \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：AlexNet的网络数字流程图}\\
        % \textcolor[rgb]{1 0 0}{todo:图片：AlexNet的双GPU图}\\

    \subsection{NiN}
        \par
        2014年Min Lin的Network in Network(NiN)\cite{2014.MinLin}是当时少有的对CNN卷积层进行改进的文章。文章就CNN框架提出了2种改进方案：1、mloconv替代conv；2、平均池(average pooling)替代CNN的全连接。
        \subsubsection{mloconv替代conv}
            \par
            NiN使用mlpconv来替代原来的conv层，mlpconv实际上是在conv层上加上mlp。因为conv是线性的，而mlp是非线性的，后者能够得到更高的抽象层，泛化能力更强。在跨通道的情况下(cross channel,cross feature map)，mlpconv等价于卷积层加上$1\times 1$卷积层，所以mlpconv也称为cccp层。借助这个机会，我们再来看一下conv。其实CNN和MLP有很深的渊源，我们可以将CNN展成向量来观察二者之间的相似性，这里我们就不做了。
            \par
            (1)conv。传统的conv是给定一张图片(map)$x$，我们用一个卷积核$w$扫描这张图片，以实现卷积，如图(\ref{fig:传统的conv})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/traditional_conv.jpg}
            \caption{传统的conv}
            \label{fig:传统的conv}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：传统的conv}\\
            这其实是权重共享技术，因为原输入$x$共享了一个卷积核/权重$w$。比如，我们将$x$展开成向量，将卷积核$w$展开成向量，如图(\ref{fig:卷积核展开示意图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Convolution_core_unfold.jpg}
            \caption{卷积核展开示意图}
            \label{fig:卷积核展开示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：卷积核展开示意图}\\
            权值共享为$w_1=w_2=\dots,w_n:=w$。就输入$x$的某一部分(patch)来看，令$patch = x_1$，如图(\ref{fig:输入的部分卷积图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/input_the_partial_convolution_graph.jpg}
            \caption{输入的部分卷积图}
            \label{fig:输入的部分卷积图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：输入的部分卷积图}\\
            % \textcolor[rgb]{1 0 0}{todo:加上原文中的fig1}\\
            我们将其展开，如图(\ref{fig:输入的部分卷积展开图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/input_the_partial_convolution_unfold_graph.jpg}
            \caption{输入的部分卷积展开图}
            \label{fig:输入的部分卷积展开图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：输入的部分卷积展开图}\\
            图(\ref{fig:输入的部分卷积展开图})中有
            \begin{align*}
            y_1 = f(w^\mathrm{T}x_1)
            \end{align*}
            即输出图像的某一个像素点$y_1$就是原输入图像的部分$x_1$和卷积核$w$卷积而来(忽略$b$，不考虑多输入)。这是一个2层的MLP，我们考虑能否将这个2层的MLP加深？
            \par
            (2)mlpconv。malpconv的示意图如图(\ref{fig:mlpconv示意图})所示
            \begin{figure}[H]
                \centering
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\textwidth]{images/mlpconv1.jpg}
                    \caption{}
                    \label{fig:mlpconv示意图1}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\textwidth]{images/mlpconv2.jpg}
                    \caption{}
                    \label{fig:mlpconv示意图2}
                \end{subfigure}
                \caption{mlpconv示意图}\label{fig:mlpconv示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：mlpconv示意图(a)(b)}\\
            图(\ref{fig:mlpconv示意图1})中，令$w = (w_1,w_2,w_3)$我们有
            \begin{align*}
            & h_1 = f(w_1x_1)\\
            & h_2 = f(w_2x_1)\\
            & h_3=f(w_3x_1)\\
            & y=f_2(vh) = f_2(vf(w^\mathrm{T}x_1))
            \end{align*}
            前面只是用了一个卷积$w$，这里使用了3个卷积$w_1,w_2,w_3$就有3个输出，然后将它们汇聚在一起，就变成了一个3层的MLP。当然，可以继续加深网络。
            \par
            就整个输入矩阵$x$而言，我们设置了3个卷积核$w_1,w_2,w_3$，用这3个卷积核分别扫描$x$就有了3个输出，然后将其汇聚在一处，如图(\ref{fig:3个卷积核的mlpconv示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/3convolution_mlpconv.jpg}
            \caption{3个卷积核的mlpconv示意图}
            \label{fig:3个卷积核的mlpconv示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：3个卷积核的mlpconv示意图}\\
            这里，也可以将$v$视为一个卷积核。有一个问题是：哪一层算作MLP的输入？为了将conv和mlp分开，将上面的$h_1,h_2,h_3$即卷积后面的输出作为mlp的输入。这样，上面的过程是一个1卷积conv加上2层mlp。将后面的mlp层加深，如图(\ref{fig:conv和3层mlp})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/conv_and_3mlp.jpg}
            \caption{conv和3层mlp}
            \label{fig:conv和3层mlp}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：conv和3层mlp}
            \par
            当然，上面两种理解都可以：$x$展开后直接mlp；$x$先卷积再mlp。二者本质上是一样的，并且注意，我们并不要mlp层数太多。
            \par
            (3)mlp = conv + $1\times 1$ conv。上面的分析只是对一个输入$x$而言，且$x$是一个矩阵(而RGB图像是一个张量)。对于单个输入$x$和单个卷积核$w$而言，$1\times 1$conv($1\times 1$卷积核)是易于理解的，卷积核的大小就是$1\times 1$。但实际上，CNN的卷积大多是多个maps和多个卷积核之间的操作。输入多个map和一组卷积核进行卷积操作，然后求和，得到一个输出map。如果此时使用$1\times 1$卷积核，其实就是\uline{多个feature map的线性组合}。
            \par
            文中提出了mlpconv其实等价于传统卷积核后接cccp层，从而实现多个feature map的线性组合，而cccp层与$1\times 1$卷积核是等价的。多输入的mlpconv(cccp层)如图(\ref{fig:cccp层示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/cccp_layer.jpg}
            \caption{cccp层示意图}
            \label{fig:cccp层示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：cccp层示意图}  \\
            如果要使MLP的输入有$n$个神经元，就需要$n$个卷积核$w_1,w_2,\dots,w_n$，从而实现上面的2个MLP。在caffe上的实现是：mlpconv = convenience + $1\times 1$conv + $1\times 1$conv。
        \subsubsection{Average Pooling}
            \par
            NiN\cite{2014.MinLin}中对CNN的第2处改进是使用全局平均pool来替代CNN中小分类器与卷积(池化)完全展开的接口。回忆一下CNN中的$S_4$到$F_5$层，是将$S_4$层的矩阵展开，然后拼接成$F_5$，如图(\ref{fig:CNN全展开层示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/CNN_full_expanded_layer_diagram.jpg}
            \caption{CNN全展开层示意图}
            \label{fig:CNN全展开层示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：CNN全展开层示意图}\\
            然后，再将$F_5$层作为小分类器的输入层进行运行。但是，这样展开拼接有一个问题，就是展开之后的神经元输入太多了，导致小分类器的权重$w$矩阵是非常大的，不易求解。现在，我们将$S_4$的每个输出矩阵(feature map)求平均，然后再将平均值合并作为$F_5$层(小分类器的输入)，如图(\ref{fig:average pooling示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/average_pooling.jpg}
            \caption{average pooling示意图}
            \label{fig:average pooling示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：average pooling示意图}\\
            这样，$S_4$层有几个矩阵，小分类器就有几个输入神经元。注：$S_4$到$F_5$的形式可以改进。
            \par
            称原本$S_4$到$F_5$为全连接；称改进后的$S_4$到$F_5$为Average pooling。
        \subsubsection{NiN的网络结构示意图}
            \par
            NiN网络结构示意图如图(\ref{fig:NiN网络结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/NiN_networks.jpg}
            \caption{NiN网络结构示意图}
            \label{fig:NiN网络结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：NiN网络结构示意图}
            \par
            基于TensorFlow实现的NiN网络如下\footnote{程序来自微信公众号：DLdigest 深度学习每日摘要(2017-05-09 )}
            \begin{lstlisting}[language = Python]
            import tensorflow as tfdef nin_cell(input):
                conv1_filter = tf.get_variable('conv1_filter', shape=[5, 5, 3, 192])
                conv1 = tf.nn.relu(tf.nn.conv2d(input, conv1_filter))
                mlpconv1_filter = tf.get_variable('mlpconv1_filter', shape=[1, 1, 192, 160])
                mlpconv1 = tf.nn.relu(tf.nn.conv2d(conv1, mlpconv1_filter))
                mlpconv2_filter = tf.get_variable('mlpconv2_filter', shape=[1, 1, 160, 96])
                mlpconv2 = tf.nn.relu(tf.nn.conv2d(mlpconv1, mlpconv2_filter))
                max_pool1 = tf.nn.max_pool(mlpconv2, ksize = [1,3,3,1], strides=[1,2,2,1])
                conv2_filter = tf.get_variable('conv2_filter', shape=[5, 5, 96, 192])
                conv2 = tf.nn.relu(tf.nn.conv2d(max_pool1, conv2_filter))
                mlpconv3_filter = tf.get_variable('mlpconv3_filter', shape=[1, 1, 192, 192])
                mlpconv3 = tf.nn.relu(tf.nn.conv2d(conv2, mlpconv3_filter))
                mlpconv4_filter = tf.get_variable('mlpconv4_filter', shape=[1, 1, 192, 192])
                mlpconv4 = tf.nn.relu(tf.nn.conv2d(mlpconv3, mlpconv4_filter))
                max_pool2 = tf.nn.max_pool(mlpconv4, ksize = [1,3,3,1], strides=[1,2,2,1])
                conv3_filter = tf.get_variable('conv3_filter', shape=[3, 3, 192, 192])
                conv3 = tf.nn.relu(tf.nn.conv2d(max_pool2, conv3_filter))
                mlpconv4_filter = tf.get_variable('mlpconv4_filter', shape=[1, 1, 192, 192])
                mlpconv4 = tf.nn.relu(tf.nn.conv2d(conv3, mlpconv4_filter))
                mlpconv5_filter = tf.get_variable('mlpconv5_filter', shape=[1, 1, 192, 10])
                mlpconv5 = tf.nn.relu(tf.nn.conv2d(mlpconv4, mlpconv5_filter))
                global_avg_pool = tf.nn.avg_pool(mlpconv5, ksize=[1,8,8,1])
                return global_avg_pool
            \end{lstlisting}
        \subsubsection{NiN的实验结果}
             \begin{figure}[H]
            \centering
            \includegraphics[width=10cm]{images/the_experimental_result_of_NiN_comparewith_other_networks_on_CIFAR-10_dataset.jpg}
            \caption{NiN与其它网络在CIFAR-10数据集上对比的实验结果
            }
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：NiN与其他网络在CIFAR-10数据集上对比的实验结果}


    \subsection{GoogLeNet}
        \subsubsection{GoogLeNet介绍}
            \par
            Szegedy等设计的GoogLeNet\cite{2014.Christian}在2014年的ILSVRC中获胜。它主要的贡献就是实现了一个奠基模块。它能够显著的减少网络中参数的数量，AlexNet中有6千万个，而它只有4万个。此外，GoogLeNet网络中没有使用卷积神经网络顶部的全连接层，而是使用了average pooling方法。ILSVRC2014年时采用的GoogLeNet有22层，参数比AlexNet少了12倍，但准确度更高(这说明AlexNet中还有许多不重要的参数，AlexNet还有很大的改进空间)。下面，我们来介绍GoogLeNet的2种重要的策略。
            \par
            (1)Motvation and High Level Considerations。直接提升深度卷积神经网络的方法是从深度和宽度两方面增加尺寸的，但是大的尺寸会使网络中有许多参数，容易出现过拟合现象，特别是当训练数据集不够大时。直接增加尺寸的另一个弊端是需要大量的计算资源。根本解决方法是将全连接层变为系数层。早些时候，为了打破网络的对称性和提高网络学习能力，传统网络使用了随机稀疏连接的方法。但是，非均匀系数网络的计算效率较低，我们可以将多个稀疏矩阵合并成相关的稠密子矩阵的方法来解决。
            \par
            (2)Incepion结构。Inception的主要思想是：怎样用密集成分来近似局部稀疏结构。GoogLeNet\cite{2014.Christian}中设计的Inception结构如图(\ref{fig:Inception结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Inception_structure.jpg}
            \caption{Inception结构示意图}
            \label{fig:Inception结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：Inception结构示意图}
            \par
            我们采用大小不同的卷积对上一层的特征矩阵(例如：128个$100\times 100$的矩阵)进行卷积操作，提取不同维度的特征。这里卷积大小(1,3,5)不是必要的，可改。在卷积之后，将3个得到的卷积后的特征图/矩阵(maps)拼接起来(合并)。并且，为了使卷积后的maps的大小相同，在给定卷积步长$s=1$后，只要改变$pad=0,1,2$即可。由于pool层在许多实验中表现良好，所以也将其计算。但是$5\times 5$卷积核带来的计算量仍然是非常巨大的。为此，我们借鉴NiN的思路，用$1\times 1$卷积来降维，如图(\ref{fig:Inception结构cccp降维示意图})所示\\
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Inception_structure_cccpDimensionality_reduction.jpg}
            \caption{Inception结构cccp降维示意图}
            \label{fig:Inception结构cccp降维示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：Inception结构cccp降维示意图}
            \par
            在$3\times 3$和$5\times 5$卷积前使用$1\times 1$卷积进行降维(将输入图片降维，例如：$256\to 64$)。这一层一般称为“瓶颈层”(bottleneck layer)，\underline{它减小了每一层的特征map的数量}，并由此减少了计算量。例如：假设我们输入层有256个特征图片，有256个输出，并且假定Inception层只进行$3\times 3$卷积操作，那么，它需要$256\times 256\times 3\times 3$(60万次)次卷积操作。如果用一个$1\times 1$的卷积核先将256卷积到64，然后再对64个特征图片进行$3\times 3$卷积操作，则有$64\times 64\times 3\times 3$卷积操作，然后，将64个输出maps再用$1\times 1$卷积返回，那么，这个操作为
            \begin{align*}
            256\times 1\times 1\times 64 + 64\times 64 \times 3\times 3 + 64\times 1\times 1\times 256 \approx 7\text{万}
            \end{align*}
            7万和60万相比，少了近10倍。鉴于GoogLeNet在图片问题上有良好的表现，下面来介绍4个改进版本。

        \subsubsection{GoogLeNet - V1}
            \par
            GoogLeNet\cite{2014.Christian}网络的核心就是Inception，其网络深度达到了27层。如此深的网络，它在BP反向传播过程中如何克服梯度消失问题呢？GoogLeNet用了一个先验信息：层数较小的网络也可能取得不错的分类效果。那么，深度网络中间层的特征对于分类来说，也是有很好的判别作用(即用中间特征做判别)，所以，在中间的某些部分设置小的分类器来进行训练。训练阶段，总损失为总分类器和中间小分类器损失的和；在测试阶段，小分类器被弃用。GoogLeNet的网络结构如图(\ref{fig:GoogLeNet网络结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[width=11cm]{images/GoogLeNet_steucture.jpg}
            \caption{GoogLeNet网络结构示意图}
            \label{fig:GoogLeNet网络结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：GoogLeNet网络结构示意图}\\
            GoogLeNet采用了模块组装的方式来搭建网络，这便于网络的添加和修改。并且，在网络的最后采用了average pooling来替代CNN的全连接。GoogLeNet中仍然采用了dropout策略，并在网络的中间层加了2个小分类器softmax，以避免梯度消失。小分类器的结构如图(\ref{fig:GoogLeNet小分类器的结构图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/The_structure_of_GoogLeNet_small_classifier.jpg}
            \caption{GoogLeNet小分类器的结构图}
            \label{fig:GoogLeNet小分类器的结构图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：GoogLeNet小分类器的结构图}\\
            average pooling部分的卷积核大小为$5\times 5$，步长$s >3$。
            % (4a)的输出为$4\times 4\times 512$，(4d)的输出为$4\times 4\times 518$，
            $1\times 1$的卷积核包含降维的$128$个卷积核和Relu，全连接层FC有1024个单元和修正线性激活，dropout层的dropped的输出比率为$20\%$，将softmax作为1000类的分类器的损失。
            \par
            GoogLeNet - V1最终top-5错误率在验证集和测试集上都是$6\%$，获得2014年的第一。GoogLeNet和其它网络的对比结果如图(\ref{fig:GoogLeNet在Top-5上的结果})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/The_result_of_GoogLeNet_in_top5.jpg}
            \caption{GoogLeNet在Top-5上的结果}
            \label{fig:GoogLeNet在Top-5上的结果}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：GoogLeNet在Top-5上的结果}

        \subsubsection{GoogLeNet - V2}
            \par
            2015.Sergey\cite{2015.Sergey}引入Batch-normalized Inception被视为Inception第二代。Batch-normalized 在一层的输出上计算所有特征映射的均值和方差，并用这些值规定它们的响应，这相当于数据增向(whiteniy)，因此，使得所有神经图(nurmal maps)在同一范围有响应，而且是零均值，在下一层不需要从输入数据中学习offset时，这有助于训练。相关实现可以参考下面的网址\footnote{https://github.com/nutszebra/googlenet\_v2/blob/master/googlenet\_v2.py}。

        \subsubsection{GoogLeNet - V3}
            \par
            2015年12月，该团队发布了Inception-V3版本\cite{2015.Szegedy}。在Inception-V1时期，能与GoogLeNet能一较高下的只有VGG(这个下面介绍)，但相比之下，GoogLeNet的计算效率要明显高于VGG。GoogLeNet表现虽然良好，但是，要想通过简单放大(大的卷积核)Inception结构来构建更大的网络则会立即增加消耗。
            \par
            大的卷积核可以带来更大的感知范围，但这也意味着我们将要训练更多的参数，比如$5\times 5$与$3\times 3$，二者的参数量为$25/9\approx 3$。为此，Sergey loffe等提出用2个连续的$3\times 3$卷积($s=1$)组成小网络来替代$5\times 5$。然而，这样有2个问题：\ding{172}这种替代会造成表达能力下降吗？即提取的特征会减少吗；\ding{173}$3\times 3$卷积之后，还要再激活吗？从大量的实验来看，表达能力不会下降，并且，增加非线性激活会提高性能，即$5\times 5$可以用2个$3\times 3$代替。那么，我们是否可以考虑更小的卷积核呢？比如$n\times 1$。
            \par
            于是，任意的$n\times n$卷积核都可以通过$1\times n$结合$n\times 1$来替代。作者发现，在网络前期使用这种替代效果并不好，如果在中等大小的feature map上使用效果要好一些(作者建议map大小在12到20之间)。于是，原GoogLeNet的inception变为图(\ref{fig:inception-v3示意图})(b)
            \begin{figure}[H]
              \centering
              \begin{varwidth}[t]{\textwidth}
                \vspace{0pt}
                \includegraphics[height=4cm]{images/inception_v3(a).jpg}
              \end{varwidth}
              \qquad\qquad
              \begin{varwidth}[t]{\textwidth}
                \vspace{0pt}
                \includegraphics[height=4cm]{images/inception_v3(b).jpg}
              \end{varwidth}
                        \caption{inception-v3示意图}
                        \label{fig:inception-v3示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：inception-v3示意图}\\
            图(\ref{fig:inception-v3示意图})(a)中用2个$3\times 3$来替代一个$5\times 5$，图(\ref{fig:inception-v3示意图})(b)中用$n\times 1$来替代$5\times 5$和$3\times 3$。当然，还可以将Inception设计为图(\ref{fig:inception-v3-2示意图})的形式。GoogLeNet - V3的实现可以参考\footnote{https://github.com/nutszebra/googlenet\_v3}
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/inception_v3_2.jpg}
            \caption{inception-v3-2示意图}
            \label{fig:inception-v3-2示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo；图片：inception-v3-2示意图}



        \subsubsection{GoogLeNet - V4}
            \par
            2016年8月，该团队再次更新了Inception的版本\cite{2016.Szegedy} ：Inception-V4。Inception-V4中吸收了在2015ILSVRC中获胜的ResNet的特点，构建了Inception-ResNet模块。同时，文\cite{2016.Szegedy}中还发现，ResNet的结构可以极大的加速训练，同时性能也有提升，得到了一个Inception-ResNet-V2网络。此外，该团队还设计了一个更深更优化的Inception-V4模型，能够达到和Inception-ResNet-V2相似的性能。值得一提的是Inception-V4中没有Resdual操作。
            \par
            先来简单记一下Resdual操作，关于ResNet后面介绍。Resdual的经典结构如图(\ref{fig:Resdual结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Resdual_structure.jpg}
            \caption{Resdual结构示意图}
            \label{fig:Resdual结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：Resdual结构示意图}\\
            我们将Inception和Resdual相结合，得到Inception-ResNet的经典模块如图(\ref{fig:Inception-ResNet-V1结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/Inception-ResNet-V1_structure.jpg}
            \caption{Inception-ResNet-V1结构示意图}
            \label{fig:Inception-ResNet-V1结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：Inception-ResNet-V1结构示意图}\\
            其余图片参考原文。网址\footnote{https://github.com/mtmd/GoogleNet\_MATLAB}给出了GoogleNet的MATLAB实现。

    \subsection{VGG Net}
        \par
        VGG是ILSVRC2014年比赛的第二名，仅次于GoogLeNet，由Karen Simanyan和Androw Izsserman 实现\cite{2014.KarenSzegedy}。它的主要贡献是展示出网络的深度是算法优良的关键。他们设计的最好的VGG网络包含16层，并且网络结构非常一致，统一使用$3\times 3$卷积层和$2\times 2$pooling层。但是VGG的计算量是非常大的，大量的参数导致它会占用很大的内存(140M)，其中绝大多数参数都是来自于一个全连接层FC。后面，可以尝试将这个FC层去掉，以减少参数量。
        \par
        VGG同样是一种卷积神经网络，通常有16到19层，其网络结构如图(\ref{fig:VGG网络结构图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=2cm]{images/VGG_Net_structure.jpg}
            \caption{VGG网络结构图}
            \label{fig:VGG网络结构图}
            \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：VGG网络结构图}
        \par
        注意，就像前面所说的那样，图(\ref{fig:VGG网络结构图})中的conv都是$3\times 3$大小，maxpool都是$2\times 2$大小。VGG正是试图通过多个$3\times 3$卷积来替代更大的卷积核(比如$5\times 5$ 和$7\times 7$)，这也是前面Inception的策略。并且VGG-E第45块：$256\times 256$和$512\times 512$个$3\times 3$是卷积核依次使用多次，以提取到更多的特征maps以及这些maps的组合。其效果就等于是一个带有3个卷积层的大型$512\times 512$的大分类器，这意味着要有大量的参数。
        \par
        VGG实现细节：dropout只在前面2个FC中使用，在第3个FC中不用。使用批量为256的批量梯度算法SGD，同样采用动量权重更新，动量参数为0.9。VGG在目标中使用了L2正则项(惩罚项)，罚权重为$5\time 10^{-4}$，dropout率为0.5，学习率初始值为$0.01$，并在validation error达到瓶颈之前以10倍下降，直到validation error不再变化。在实验中，学习率共降过3次，迭代次数有370千次，共74次对全部数据进行扫描。权重初始值使用Pre-traing(预训练)的方法：先预训练一小部分网络，当网络稳定后再向前训练。每次初始化权重时，使用$N(0,0.01)$，偏置$b$的初始值为0，传递函数使用Relu。

    \subsection{ResNet}
        \subsubsection{ResNet简介}
            \par
            ResNet\cite{2015.HeKaiming}是ILSVRC2015年的获胜者，由微软亚洲研究院的何凯明等研发，在图像分类、目标检测等任务中，ResNet的性能大幅度超越前一年的网络。残差网络的明显特征是有着相当深的网络深度，从32层到152层，深度远超之前的网络。并且，更有甚者设计了1001层的网络结构，其网络深度是令人吃惊的。残差网络使用了特殊的跳跃式连接，大量使用批量归一化(batch normalization)，并且网络的最后也没有使用FC层。
            \par
            从前面介绍的CNN及其改进来看，似乎越深的网络表达能力越强。我们能不能将一个简单的网络加深，使它变得更优呢(不改变结构的情况下)？何凯明等人通过实验证明：在时间复杂度相同的情况下，深度较深的网络性能会更优一下，但是一般的堆积网络块并不能使网络更好。堆积的深层网络除了使计算量变大之外，另一大难题则是梯度消失(infernation)，进而导致网络收敛缓慢。2013年，多伦多大学Lei jimny Ba和微软的RichCarnana发表了《Do Deepnets really need to be deep?》一文，文中用一个浅层网络去模拟一个深层网络，结果得到2个只有1层的浅层网络，但这个网络却能与深层网络相媲美。因此，作者提出，对浅层网络而言，可能还有许多更好的网络结构和更好的学习算法等待我们开发(这是重点)。同样，何凯明等在ResNet的原文\cite{2015.HeKaiming}中也做过实验，将网络的深度由20增加到56，发现随着网络深度的加深，错误率却不降反增，如图(\ref{fig:20vs56层(简单堆积加深)的结果图})所示
            \begin{figure}[H]
              \centering
              % \begin{varwidth}[t]{\textwidth}
              %   \vspace{0pt}
              %   \includegraphics[height=4cm]{images/20vs56layer_simple_stack1.jpg}
              % \end{varwidth}
              % \qquad
              % \begin{varwidth}[t]{\textwidth}
              %   \vspace{0pt}
                \includegraphics[height=4cm]{images/20vs56layer_simple_stack2.jpg}
              % \end{varwidth}
                \caption{20vs56层(简单堆积加深)的结果}
                \label{fig:20vs56层(简单堆积加深)的结果图}
            \end{figure}

% \begin{figure}[H]
%     \centering
%     \begin{subfigure}[b]{0.4\textwidth}
%         \includegraphics[width=\textwidth]{images/20vs56layer_simple_stack1.jpg}
%         \caption{}
%         \label{fig:20vs56层(简单堆积加深)的结果图1}
%     \end{subfigure}
%     \begin{subfigure}[b]{0.4\textwidth}
%         \includegraphics[width=\textwidth]{images/20vs56layer_simple_stack2.jpg}
%         \caption{}
%         \label{fig:20vs56层(简单堆积加深)的结果图2}
%     \end{subfigure}
%     \caption{20vs56层(简单堆积加深)的结果}
%     \label{fig:20vs56层(简单堆积加深)的结果图}
% \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：20vs56层(简单堆积加深)的结果图(a)(b)}
            从图(\ref{fig:20vs56层(简单堆积加深)的结果图})中可以看出，简单增加网络深度不仅仅使测试集错误率提高，而且在训练集中错误率也提高，这就排除了深度网络过拟合的可能(如果仅在测试集中错误率提高，则是网络过拟合)。模型中也使用了Relu和BN等防止梯度消失的策略，但最终结果表明：普通增加深度是有问题的，至于问题出在哪里，这个还有待研究。
        \subsubsection{高速公路网络HighWay Network}
            \par
            ResNet可以视为Highway network的特例。Highway Network\cite{2015.Rupesh}是瑞士3位学者于2015年提出的一种超深度的网络，为什么说是超深呢？原文\cite{2015.Rupesh}指出，他们能够训练900层的神经网络。虽然只是层数加深，没有性能的提高，但是能训练就已经很不错了。他们还在文中给出了最深达100层的Highway Net的收敛情况，如图(\ref{fig:HighWayNetwork的收敛情况})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=5cm]{images/HighWayNetwork_convergence.jpg}
            \caption{HighWayNetwork的收敛情况}
            \label{fig:HighWayNetwork的收敛情况}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo；图片：HighWayNetwork的收敛情况}
            \par
            Highway Net的工作受到了LSTM(这个我们在RNN中介绍)中gate的启发：既然梯度在某些地方被阻碍了，那就让它直接通过这些阻碍层好了，不求导或者令导数为1。HighwayNet的思想正源于此，并且，这也是Highway名称的由来。在Highway网络中，我们设网络层数为$L$，$W_{H_l}(l=1,2,\dots,L)$表示第$l$层的权重，$H$为第$l$层的非线性函数，$x_1$是第1层的输入，$w_{H_1}$是第1层的权重，$y_1$是第1层的输出，忽略偏置$b$，并省略层$l$的标记，可以将输入输出写为
            \begin{align*}
            y = H(x,W_H)
            \end{align*}
            这里：$H$是一个仿射变换，但是，它还可以有更一般的形式，在Highway中，我们添加2个新的非线性转换$T(x,W_T),C(x,W_c)$，$y$为
            \begin{align*}
            y = H(x,W_H)T(x,W_T)+xC(x,W_c)
            \end{align*}
            我们定义$T$为转换门(transform gate)，$C$是传递门(carry gate)。为了简单，令$C = 1-T$，于是有
            \begin{align*}
            y = H(x,W_H)T(x,W_T)+x[(1-T)(x,W_T)]
            \end{align*}
            由于是gate，所以$T$的取值为0或1。我们可以看到
            \begin{align*}
            y =
            \left\{
            \begin{aligned}
            x \qquad T = 0, \ \text{关闭}\\
            H(x,W_H)\qquad T = 1,\ \text{打开}
            \end{aligned}
            \right.
            \end{align*}
            这种思路是非常巧妙地，将上面的$y$关于$x$求导，有
            \begin{align*}
            \frac{\partial y}{\partial x} =
            \left\{
            \begin{aligned}
            I \quad T=0\\
            H'(x,W_H) \quad T=1
            \end{aligned}
            \right.
            \end{align*}
            其中：$I$是全1向量。上面的$y = x$代表着什么，想必也是了然的，这就是Highway。并且$\frac{\partial y}{\partial x} = I$也使梯度得以直接通过(很“变态”的一种方法)。使用TensorFlow实现HighwayNet如下\footnote{微信公众号：DLdigest深度学习每日摘要(2017-05-07)}
            \begin{lstlisting}[language = Python]
            def highwayUnit(input_layer, unit_id, is_training=True):
                with tf.variable_scope('HighwayUnit_'+str(unit_id), initializer=tf.random_normal_initializer()):
                    T = tf.layers.conv2d(input_layer, 32, (3,3), padding='same')
                    bn_layer1 = tf.contrib.layers.batch_norm(input_layer, is_training=is_training)
                    relu_layer1 = tf.nn.relu(bn_layer1)
                    conv_layer1 = tf.layers.conv2d(relu_layer1, 32, (3,3), padding='same')
                    bn_layer2 = tf.contrib.layers.batch_norm(conv_layer1, is_training=is_training)
                    relu_layer2 = tf.nn.relu(bn_layer2)
                    conv_layer2 = tf.layers.conv2d(relu_layer2, 32, (3,3), padding='same')
                return (1.0-T)*input_layer+T*conv_layer2
            \end{lstlisting}

        \subsubsection{ResNet理论}
            \par
            下面正式进入到ResNet中。像Highway那样，ResNet也使用了“直通”的方法，不过ResNet还采用了一些其他的技巧，从而使ResNet完全避免了梯度消失问题。
            \par
            我们知道，在一个浅层网络上累加/堆积一些$x_{l+1} = y = x_l$是不改变网络的结果的，它只是单纯的增加了网络的深度而已。但是，这样的“深”并非我们的初衷，我们希望加深网络来提高网络的性能。先来看一下一般的网络结构，如图(\ref{fig:一般的网络结构示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=3cm]{images/normal_Network.jpg}
            \caption{一般的网络结构示意图}
            \label{fig:一般的网络结构示意图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：一般的网络结构示意图}\\
            要求经过两个权重层/卷积层后，输入的$x_{l+1} = x_l$。如果拟合/逼近一个恒等式$x_{l+1} = H(x_l)$不容易，可以转而拟合其误差，让其误差趋于0。并且由于要求$x_{l+1} = x_l$，所以二者的大小应该是一样的。拟合误差的网络如图(\ref{fig:误差块网络示意图})所示
             \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/Error_block_network_diagram.jpg}
            \caption{误差块网络示意图}
            \label{fig:误差块网络示意图}
            \end{figure}
            % \textcolor[rgb]{ 1 0 0}{todo:图片：误差块网络示意图}\\
            图(\ref{fig:误差块网络示意图})中，$F(x_l)$表示$x_{l+1}-x_l$。当$f(x) = x$时，为了方便，忽略层$l$的下标，有
            \begin{align*}
            & F(x) = W_2\sigma (W_1x)\\
            & y = x+F(x)\\
            & H(x_l) = f(y)
            \end{align*}
            \par
            我们写出更一般的残差块的公式，要求$x_l$到$x_{l+1}$为$h(x_l)$，有
            \begin{align*}
            & F(x) = W_2+\sigma(W_1x)\\
            & y = h(x)+F(x)\\
            & x_{l+1} = H(x_l) = f(y)
            \end{align*}
            其中：$x_l$是第$l$残差单元/残差块(residual unit)的输入特征maps(input feature maps)；$W_l=\{W_{l,k|1 \leqslant k \leqslant K}\}$是第$l$层/残差块的权重，$W_l = (W_{l1},W_{l2})$。$K$是第$l$层的权重数量，或者说是第$l$个残差块的卷积层数；$F$是残差函数；$f$是传递函数，例如$f = Relu$；$h(x_l)$是$x_l$的一个变换，一般为恒等式$h(x_l) = x_l$。
            \par
            如果传递函数$f$也是一个恒等式，我们可以写出
            \begin{align*}
            x_{l+1} = x_l+F(x_l,W_l)
            \end{align*}
            将$L$个残差块堆积起来，则有
            \begin{align*}
            x_{l+2} = x_{l+1} + F(x_{l+1}, W_{l+1}) = x_l + F(x_l,W_l)+F(x_{l+1},W_{l+1})
            \end{align*}
            更一般的，有
            \begin{align*}
            x_L =x_l + \sum_{i=l}^{L-1}F(x_i,W_i)
            \end{align*}
            这里，为了便于理解，可以将$F(x_i,W_i)$视为0。对任何深度的$L$和任意的层/块$l$，上式有一些非常好的性质：
            \begin{enumerate}
            \item $\forall L$，特征$x_L$可以表示成$x_l(\forall l)$和$\sum\limits_{i=l}^{L-1}F(x_i,W_i)$的和；
            \item $\forall L$，$x_L =x_0 + \sum\limits_{i=0}^{L-1}F(x_i,W_i)$，即$x_L$是所有残差$F(x_i,W_i)$求和后加上$x_0$；
            \end{enumerate}
            \par
            记ResNet网络的最终误差为$E$，$E$关于$x_l$求导，有
            \begin{align*}
            \frac{\partial E}{\partial x_l} = \frac{\partial E}{\partial x_L} \frac{\partial x_L}{\partial x_l} = \frac{\partial E}{\partial x_L} \left( 1+\frac{\partial }{\partial x_l}\sum_{i=l}^{L-1}F(x_i,W_i) \right)
            \end{align*}
            上式表明，梯度$\frac{\partial E}{\partial x_l}$能够分解为2部分：$\frac{\partial E}{\partial x_L}$和$\frac{\partial E}{\partial x_L}\frac{\partial }{\partial x_l}\sum\limits_{i=l}^{L-1}F$。后面这部分$\frac{\partial E}{\partial x_L}$确保了信息/梯度可以传递到任何层$l$，并且保证了$\frac{\partial E}{\partial x_l}$不会消失。因为$\frac{\partial }{\partial x_l}\sum\limits_{i=l}^{L-1}F$对$x_l$不会总是$-1$，这里的梯度已经不再是一般的连乘$\frac{\partial }{\partial}\dots\frac{\partial }{\partial}$的形式了，所以不会消失。
            \par
            但是，要注意的是，前面假设了$h(x_l) = x_l$，并且假设$x_{l+1} =y_l$，这是两个非常强的约束，一旦打破，上述关系式即不成立。
            \par
            (1)对于第一个假设。关于$h(x_l) = x_l$是我们一直默认的，而且实验表明这种方法是较好的。现在，将其改为$h(x_l) = \lambda_l x_l$，并且仍然假设$x_{l+1} = y_l$(即传递函数$f$是恒等传递)，有
            \begin{align*}
            x_{l+1} = \lambda_l x_l + F(x_l W_l)
            \end{align*}
            递归堆积，有
            \begin{align*}
            x_L = \prod_{i=l}^{L-1} \lambda_i x_l + \sum_{i=l}^{L-1}\prod_{j=i+1}^{L-1}\lambda_jF(x_i,W_i)
            \end{align*}
            或者简单记为
            \begin{align*}
            x_L = \prod_{i=l}^{L-1} \lambda_i x_l + \sum_{i=l}^{L-1}\hat{F}(x_i,W_i)
            \end{align*}
            其中：$\hat{F} = \prod\limits_{j=i+1}^{L-1}\lambda_jF(x_i,W_i)$。
            \par
            我们仍然记误差为$E$，$E$关于$x_l$求导，有
            \begin{align*}
            \frac{\partial E}{\partial x_l} = \frac{\partial E}{\partial x_L} \left( \prod_{i=l}^{L-1}\lambda_i + \frac{\partial }{\partial x_l} \sum_{i=l}^{L-1}\hat{F}(x_i,W_i) \right)
            \end{align*}
            第一项$\prod\limits_{i=l}^{L-1}\lambda_i $是非常危险的，如果对于所有的$i$，$\lambda_i >1$，那么这一项会按指数方式增长；如果对于所有的$i$，有$\lambda_i < 1$，那么这一项会减小甚至消失。因此，梯度很依赖$\lambda_i$而$\lambda_i$又不定，所以网络不稳定。
            \par
            (2)对于第二个假设。$x_{l+1} = f(y_l) = y_l$，将$f$放宽，不要求其为恒等变换，但是仍然要将$x_l$直接传递给$x_{l+1}$。为此，将$f$移到旁边的残差分支上来，至于$f\triangleq Relu$安放在哪里，可以参考何凯明文献\cite{2016.Kaiming}中的Fig4和Tab2，Fig4如图(\ref{fig:传递函数的6种不同的位置比较})所示，Tab2如图(\ref{fig:传递函数Tab2})所示
            \begin{figure}[H]
            \centering
            \includegraphics[width=12cm]{images/Transfer_func_of_six_different_location_compare.jpg}
            \caption{传递函数的6种不同的位置比较}
            \label{fig:传递函数的6种不同的位置比较}
            \end{figure}
            \begin{figure}[H]
            \centering
            \includegraphics[width=12cm]{images/Transfer_functab2.jpg}
            \caption{传递函数Tab2}
            \label{fig:传递函数Tab2}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：传递函数的6种不同的位置}\\
            % \textcolor[rgb]{1 0 0}{todo：图片：传递函数Tab2}\\
            Fig4和Tab2中的比较表明：将$f=Relu$移到残差分支中，不仅可以满足之前的假设，而且是这几种移动中最优的移动。接下来使用TensorFlow来实现上图(\ref{fig:传递函数的6种不同的位置比较})所示的ResUnit
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            def resUnit(input_layer, unit_id, is_training=True):
                with tf.variable_scope('ResUnit_'+str(unit_id), initializer=tf.random_normal_initializer()):
                    bn_layer1 = tf.contrib.layers.batch_norm(input_layer, is_training=is_training)
                    relu_layer1 = tf.nn.relu(bn_layer1)
                    conv_layer1 = tf.layers.conv2d(relu_layer1, 32, (3,3), padding='same')
                    bn_layer2 = tf.contrib.layers.batch_norm(conv_layer1, is_training=is_training)
                    relu_layer2 = tf.nn.relu(bn_layer2)
                    conv_layer2 = tf.layers.conv2d(relu_layer2, 32, (3,3), padding='same')
                return input_layer+conv_layer2

            if __name__ == '__main__':
                with tf.Session() as sess:
                    input_layer = tf.get_variable('input', shape=[4,10,10,32], dtype=tf.float32)
                    out = resUnit(input_layer, 1)
                    sess.run(tf.global_variables_initializer())
                    print sess.run(out)
            \end{lstlisting}

            \par
            下面将残差块堆积起来，形成DeepResNet，如图(\ref{fig:DeepResNet网络结构图})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=12cm,angle=90]{images/DeepResNet_sructure.jpg}
            \caption{DeepResNet网络结构图}
            \label{fig:DeepResNet网络结构图}
            \end{figure}
            % \textcolor[rgb]{ 1 0 0}{todo:图片：DeepResNet网络结构图}
            \par
            ResNet层数逐步加深的训练误差如图(\ref{fig:ResNet层数逐步加深的训练误差})所示
            \begin{figure}[H]
            \centering
            \includegraphics[height=4cm]{images/trainingerror_of_The_number_of_ResNetlayers_gradually_deepen.jpg}
            \caption{ResNet层数逐步加深的训练误差}
            \label{fig:ResNet层数逐步加深的训练误差}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：ResNet层数逐步加深的训练误差}
            从图(\ref{fig:ResNet层数逐步加深的训练误差})中可以看到，随着ResNet网络的加深，训练误差逐渐下降，没有出现普通堆积的误差增加的情况。
            \par
            下面，我们简记一下ResNet的结果。
            1. 2015年ResNet原文\cite{2015.HeKaiming}的Fig4和Tab2，在ImageNet数据集上进行了平整网络plain network和残差网络的收敛性对比；
            2. 2015年ResNet原文\cite{2015.HeKaiming}的Tab4，在ImageNet数据集上进行和ResNet与其它网络的的单一模型top-1和top-5的对比实验；
            3. 2015年ResNet原文\cite{2015.HeKaiming}的Tab5，在ImageNet数据集上进行和ResNet与其它网络的的集成模型top-5的对比实验；
            4. 2016年1001层残差网络的原文\cite{2016.Kaiming}的Fig3和Fig6，展示了1001层网络在CIFAR-10数据上的训练收敛图；
            5. 2016.Andreas在文\cite{2016.Andreas}中指出，ResNet其实质上并非一个非常深的网络，而是由指数个非常前的网络叠加而成。该论文同时指出，查看网络除了要看网络的深度和宽度(特征提取的多少)之外，还应该查看网络的multiplicity。重要观点查看原文Fig1即可。
            6. 2016.Zhang\cite{2016.Zhang}提出多级残差网络。网络结构参考原文\cite{2016.Zhang}的Fig1的RoR、Fig2的RoR-3和Fig3的Pre-RoR-3或RoR-3-WRN。
            7. 2016.Abdi\cite{2016.Abdi}同样提出多级残差网络。
            8. 2016.Zagoruyko\cite{2016.Zagoruyko}提出WResNet(WRN)，将ResNet网络性能改善。
            9. 2016.Brian\cite{2016.Brian}对ResNet网络内部的特征进行了可视化。
            10. 2016.Gao\cite{2016.Gao}提出随机丢弃路径的网络。整个网络结构是随机的，并将该网络在CIFAR-10数据集上进行测试。
            11. 2016.Gustav\cite{2016.Gustav}提出了分形网络(fractal network)的概念，并在此基础上采用dropout方法进行训练。
    \subsection{MATLAB应用实例}
        \subsubsection{MATLAB自带CNN工具}
        \par
        MATLAB自带的卷积神经网络CNN命令如表(\ref{tab:CNN命令})所示
        \begin{table}[H]
          \caption{CNN命令}
          \label{tab:CNN命令}
          \centering
          \newcolumntype{Y}{>{\centering\arraybackslash}X}% 定义自适应列的居中格式 Y, 用 X 为左对齐(自适应列)
          \begin{tabularx}{\textwidth}{l|l}% 需要引入 tabularx 宏包；表格总宽度一定要设置
          \toprule
          命令  & 说明 \\
          \midrule
          trainingOptions &  Options for training neural network\\
          trainNetwork & Train a convolutional network\\
          imageInputLayer  & Image input layer\\
          convolution2dLayer & Convolutional layer\\
          reluLayer &  Rectified(改正) Linear Unit (ReLU) layer\\
          crossChannelNormalizationLayer&  Channel-wise local response normalization layer\\
          averagePooling2dLayer &  Average pooling layer object\\
          maxPooling2dLayer & Max pooling layer\\
          fullyConnectedLayer  & Fully connected layer\\
          dropoutLayer & Dropout layer\\
          softmaxLayer & Softmax layer for convolutional neural networks\\
          classificationLayer &  Create a classification output layer\\
          regressionLayer &  Create a regression output layer\\
          activations &  Compute convolutional neural network layer activations\\
          predict &  Predict responses using a trained convolutional neural network\\
          classify & Classify data using a trained convolutional neural network\\
          deepDreamImage&  Visualize(形象) network features using deep dream\\
          alexnet &  Pretrained AlexNet convolutional neural network\\
          vgg16  & Pretrained VGG-16 convolutional neural network\\
          vgg19 &  Pretrained VGG-19 convolutional neural network\\
          importCaffeLayers &  Import convolutional neural network layers from Caffe\\
          importCaffeNetwork & Import pretrained convolutional neural network models from Caffe\\
          SeriesNetwork &  Series network class\\
          TrainingOptionsSGDM &  Training options for stochastic gradient descent with momentum\\
          Layer&   Network layer\\
          ImageInputLayer&  Image input layer\\
          Convolution2DLayer & Convolutional layer\\
          ReLULayer &  Rectified(改正) Linear Unit (ReLU) layer\\
          CrossChannelNormalizationLayer&  Channel-wise local response normalization layer\\
          AveragePooling2DLayer &  Average pooling layer object\\
          MaxPooling2DLayer &  Max pooling layer\\
          FullyConnectedLayer &  Fully connected layer\\
          DropoutLayer & Dropout layer\\
          SoftmaxLayer & Softmax layer for convolutional neural networks\\
          ClassificationOutputLayer &  Classification output layer\\
          RegressionOutputLayer &  Regression output layer\\
          \bottomrule
          \end{tabularx}
        \end{table}

        \subsubsection{MatConvNet}
            \par
            MatConvNet是一个少有的基于MATLAB语言的深度学习工具箱，主要用于卷积神经网络(恰好就是我们这章所讲的内容)。MatConvNet包含了上面介绍的各大网络，并且由于上面的网络都比较大，MatConvNet在mat数据格式里已经提供了网络的基本结构，只需要将样本数据带入训练即可。
            MatConvNet基本模型示例：
            \begin{lstlisting}[language = Matlab]
            %% MatConvNet
            %1、 安装编译 MatConvNet (needed once).
            cnnMatFile = fullfile(matlabroot,'work','DL_song', 'MatConvNet');
            if ~exist(cnnMatFile, 'file') % download only once
                disp('Untar pre-trained CNN model...');
                MatConvNetPath = 'D:\Program Files\MATLAB\R2016a\work\深度学习\深度学习工具箱/matconvnet-1.0-beta23.tar.gz';
                untar(MatConvNetPath,cnnMatFile) ;
            end
            cnnMatFile = fullfile(cnnMatFile,'matconvnet-1.0-beta23');
            cd(cnnMatFile)
            % addpath matlab
            %编译
            run matlab/vl_compilenn ;%CPU编译
            %GPU编译
            vl_compilenn('enableGpu', true)
            %检测
            vl_testnn
            vl_testnn('gpu', true)
            %% VGG-face(人脸识别模型)
            % 下载已经训练好的模型 (needed once).注意：下载可能需要时间
            urlwrite(...
              'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-f.mat', ...
              'imagenet-vgg-f.mat') ;
            % Setup MatConvNet.
            run matlab/vl_setupnn ;
            % Load a model and upgrade it to MatConvNet current version.
            net = load('imagenet-vgg-f.mat') ;
            net = vl_simplenn_tidy(net) ;
            % Obtain and preprocess an image.
            im = imread('peppers.png') ;
            im_ = single(im) ; % note: 255 range
            im_ = imresize(im_, net.meta.normalization.imageSize(1:2)) ;
            im_ = im_ - net.meta.normalization.averageImage ;
            % Run the CNN.
            res = vl_simplenn(net, im_) ;
            % Show the classification result.
            scores = squeeze(gather(res(end).x)) ;
            [bestScore, best] = max(scores) ;
            figure(1) ; clf ; imagesc(im) ;
            title(sprintf('%s (%d), score %.3f',...
               net.meta.classes.description{best}, best, bestScore)) ;
            %% DAG模型
            % setup MatConvNet
            run  matlab/vl_setupnn
            % 下载已经训练好的模型 (needed once)
            urlwrite(...
              'http://www.vlfeat.org/matconvnet/models/imagenet-googlenet-dag.mat', ...
              'imagenet-googlenet-dag.mat') ;
            % load the pre-trained CNN
            net = dagnn.DagNN.loadobj(load('imagenet-googlenet-dag.mat')) ;
            net.mode = 'test' ;
            % load and preprocess an image
            im = imread('peppers.png') ;
            im_ = single(im) ; % note: 0-255 range
            im_ = imresize(im_, net.meta.normalization.imageSize(1:2)) ;
            im_ = bsxfun(@minus, im_, net.meta.normalization.averageImage) ;
            % run the CNN
            net.eval({'data', im_}) ;
            % obtain the CNN otuput
            scores = net.vars(net.getVarIndex('prob')).value ;
            scores = squeeze(gather(scores)) ;
            % show the classification results
            [bestScore, best] = max(scores) ;
            figure(1) ; clf ; imagesc(im) ;
            title(sprintf('%s (%d), score %.3f',...
            net.meta.classes.description{best}, best, bestScore)) ;
            \end{lstlisting}
            \par
            我们还可以用MATLAB结合MatConvNet来建立网络，下面给出一个示例：
            \begin{lstlisting}[language = Matlab]
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            %% 这个例子展示深度学习模型CNN在图像识别中的应用
            %Note: 这个例子需要下面工具箱的支持：
            % Computer Vision System Toolbox?,
            % Image Processing Toolbox?,
            % Neural Network Toolbox?,
            % Parallel Computing Toolbox?,
            % Statistics and Machine Learning Toolbox?,
            % a CUDA-capable NVIDIA? GPU with compute capability 3.0 or higher.
            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
            %% 1、系统检验：为了检验你的计算机有一个CUDA-capable NVIDIA? GPU with compute capability 3.0 or higher.
            % 获得GPU设备的信息(GPU要求是NVIDIA的)
            deviceInfo = gpuDevice;
            % 检查GPU计算能力
            computeCapability = str2double(deviceInfo.ComputeCapability);
            assert(computeCapability > 3.0, ...
                'This example requires a GPU device with compute capability 3.0 or higher.')
            %% 2、下载图像数据
            % 从下面的网址下载压缩的数据
            url = 'http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz';
            % 将结果储存在一个临时文件夹
            outputFolder = fullfile(tempdir, 'caltech101'); %设置下载路径(图像数据下载在哪里)
            if ~exist(outputFolder, 'dir') %如果文件夹不存在，则下载并保存到该文件夹路径
                disp('Downloading 126MB Caltech101 data set...');
                untar(url, outputFolder);
            end
            %% 3、加载图像数据
            rootFolder = fullfile(outputFolder, '101_ObjectCategories');
            categories = {'airplanes', 'ferry', 'laptop'};%类别标签
            % 创建一个ImageDatastore来帮助您管理数据。因为ImageDatastore作用于图像文件位置,图像不加载到内存中,直到读,使其有效使用大型图像集合。
            imds = imageDatastore(fullfile(rootFolder, categories), 'LabelSource', 'foldernames');
            % imd变量现在包含图片和每个图像的分类标签。自动分配的标签图像文件的文件夹的名称。
            tbl = countEachLabel(imds)% 使用countEachLabel总结每个类别的图片数量。
            % 将3个类别中的图片数量取相同---67
            minSetCount = min(tbl{:,2}); %确定最小的类别数
            % 用splitEachLabel来随机选取图片，并使每个类别的图片大小为67
            imds = splitEachLabel(imds, minSetCount, 'randomize');%imds包含图片和类别
            % 再次展示个类别的数量
            countEachLabel(imds)
            % 找到每个类别的第一个图片
            airplanes = find(imds.Labels == 'airplanes', 1);
            ferry = find(imds.Labels == 'ferry', 1);
            laptop = find(imds.Labels == 'laptop', 1);
            % 将图片展示出来
            figure
            subplot(1,3,1);
            imshow(imds.Files{airplanes})
            subplot(1,3,2);
            imshow(imds.Files{ferry})
            subplot(1,3,3);
            imshow(imds.Files{laptop})
            %% 下载CNN模型(MatConvNet)
            % Location of pre-trained "AlexNet"
            cnnURL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-caffe-alex.mat';
            % Store CNN model in a temporary folder
            cnnMatFile = fullfile(tempdir, 'imagenet-caffe-alex.mat');
            if ~exist(cnnMatFile, 'file') % download only once
                disp('Downloading pre-trained CNN model...');
                websave(cnnMatFile, cnnURL);
            end
            %% 加载CNN模型
            % Load MatConvNet network into a SeriesNetwork
            convnet = helperImportMatConvNet(cnnMatFile)
            % 查看CNN结构
            convnet.Layers
            % 查看第一层网络
            convnet.Layers(1)
            % 查看最后一层网络
            convnet.Layers(end)
            % ImageNet分类任务类名称的数量
            numel(convnet.Layers(end).ClassNames)
            %% Pre-process Images For CNN
            % 如上所述，ConvNet的输入只能是RGB图像227-by-227。
            % Set the ImageDatastore ReadFcn
            imds.ReadFcn = @(filename)readAndPreprocessImage(filename);
            %% 设置训练集和测试集
            % 将集分为训练和验证数据。选择图像从每组训练数据的30%,其余70%,验证数据。
            % 随机分割来避免结果的偏差。训练集和测试集将由CNN模型处理。
            [trainingSet, testSet] = splitEachLabel(imds, 0.3, 'randomize');
            %% 观察中间层提取的特征
            % 得到第二卷积层的网络权重
            w1 = convnet.Layers(2).Weights;
            % Scale and resize the weights for visualization
            w1 = mat2gray(w1);
            w1 = imresize(w1,5);
            % Display a 混合图 of network weights. There are 96 个体 sets of
            % weights in the first layer.
            figure
            montage(w1)
            title('First convolutional layer weights')
            % 注意网络的第一层已经学会过滤器捕捉blob和边缘特征。
            % 这些“原始”功能被更深的网络层处理,并结合早期功能形成更高层次的图像特征。
            % 这些更高层次特性更适合识别任务,因为他们将所有的原始功能合并到更丰富的图像表示
            % You can easily extract features from one of the deeper layers using the activations method.
            % Selecting which of the deep layers to choose is a design choice,
            % but typically starting with the layer right before the classification layer is a good place to start.
            % In convnet, the this layer is named 'fc7'.
            Let's extract training features using that layer.
            featureLayer = 'fc7';
            trainingFeatures = activations(convnet, trainingSet, featureLayer, ...
                'MiniBatchSize', 32, 'OutputAs', 'columns');
            % 注意,激活计算GPU和“MiniBatchSize”设置32确保CNN和图像数据适合GPU内存。
            % 你可能需要降低“MiniBatchSize”如果你的GPU耗尽内存。
            % 此外,激活输出安排列。这有助于加速多级线性支持向量机训练。
            %% Train A Multiclass SVM Classifier Using CNN Features
            % Get training labels from the trainingSet
            trainingLabels = trainingSet.Labels;
            % Train multiclass SVM classifier using a fast linear solver, and set
            % 'ObservationsIn' to 'columns' to match the arrangement used for training
            % features.
            classifier = fitcecoc(trainingFeatures, trainingLabels, ...
                'Learners', 'Linear', 'Coding', 'onevsall', 'ObservationsIn', 'columns');
            %% 评估分类器
            % Extract test features using the CNN
            testFeatures = activations(convnet, testSet, featureLayer, 'MiniBatchSize',32);
            % Pass CNN image features to trained classifier
            predictedLabels = predict(classifier, testFeatures);
            % Get the known labels
            testLabels = testSet.Labels;
            % Tabulate the results using a confusion matrix.
            confMat = confusionmat(testLabels, predictedLabels);
            % Convert confusion matrix into percentage form
            confMat = bsxfun(@rdivide,confMat,sum(confMat,2))
            % Display the mean accuracy
            mean(diag(confMat))
            %% 对新图像进行分类
            newImage = fullfile(rootFolder, 'airplanes', 'image_0690.jpg');
            % Pre-process the images as required for the CNN
            img = readAndPreprocessImage(newImage);
            % Extract image features using the CNN
            imageFeatures = activations(convnet, img, featureLayer);
            % Make a prediction using the classifier
            label = predict(classifier, imageFeatures)
            \end{lstlisting}

\section{循环神经网络RNN}

% \bibliography{part-MLDL-chap-DeepLearn}%bib文件名称

    todo:这是很有必要补充的一章！！！\footnote{稿子已经有了，我们正在想要不要添加进来。。。}


\section{对抗生成网络GAN}
    \subsection{引言}
        \par
        对于生成模型而言，我们的任务是拟合(估计)样本分布，并从分布中生成/采样样本。假设你已经有了GAN的思想：用生成器G生成假样本，将假样本和真样本送进判别器D中进行真假判别。判别器D的目标是使假样本被判别为真的概率尽可能小，真样本被判别为真的概率尽可能大；生成器G的目标是使假样本为真的概率尽可能大。判别器D和生成器G交替进行训练，每训练1步G要训练$k$步D。
        \par
        现在，我们来考虑这样的生成器G(generator)：
        \begin{enumerate}
        \item 是否需要训练判别器？我们可以将判别器的判别水平提前固定，只有生成器生成的图片/样本能骗过判别器即可。就像一个学生和一个美术老师一样，老师要求学生画一个狮子，而学生从未见过狮子，于是他随便画了个，交给老师，老师说这个不是，狮子尾巴有个球，哪哪哪要改(学生见过其它动物，未见过狮子，并且老师也有一定的知识，老师可以说狮子和……很像)，于是学生回去改，再交再改直到老师/判别器满意为止。
        \item 判别器和生成器时训练。我们先将判别器训练到一定的水平，然后再开始生成样本，判别器的目标是使生成样本属于已有样本的概率最小(即在生成器固定的情况下，使概率最小)，生成器的目标是使概率最大。老师会通过学生提交的作品提高自己的要求/判别率(无论生成器给出一个什么样的样本，我都要给它判成假的，如果判别效果不好，我就去修改判别器。生成器要让最好的判别效果最差)。
        \item 多个判别器。我们设定多个判别器作为老师(判别器判别率固定也可，渐渐提高也可)，然后让生成器去生成样本，要让多个导师都认可才可以。这是一个什么问题？生成器是样本分布的拟和吗？
        \end{enumerate}
        \par
        设有生成器G产生的样本分布函数为$P_g$，密度函数为$p_g$，假样本为$x\sim P_g$；真实样本分布函数为$P_r$，密度函数为$p_r$，真样本为$x\sim P_r$。我们现在是从$P_g$中采样一个$x$，并于真实样本进行判别，即将$P_g$产生的$x$和$P_r$产生的$x$输入到判别器中进行判别。如果判别器D不能辨识真伪，我们就说在D下，$P_g$是$P_r$的估计。
        \par
        我们知道，一般的生成器G是一个生成网络，或者说$P_g$是没有显示表达式的，比如$P_g = N(\mu,\sigma^2)$。回忆一下概率中的采样过程：$x = F^{-1}(z),z\sim U[0,1]$，其中，$F$为$x$的分布函数，$F^{-1}$是$F$的逆，$z$是均匀分布$U$的样本。这就是从分布$F$采样$x$的过程，注意到这种方法要求$F$可逆(当然还有许多其它的采样方法，这里不做详细说明)。如果事先不知道$F$的具体形式，我们该怎么办呢？简单，毕竟我们的生成器G用的神经网络嘛，我们不用神经网络来求$F$，而是直接表示$F^{-1}$。用神经网络(生成器G)表示$F^{-1}$，于是有
        \begin{align*}
        x = G(z)\quad z\sim U[0,1]
        \end{align*}
        这里的$x$即是生成器G带来的样本$x\sim P_g$。如果说G是什么，G是$P_g^{-1}$，即G是估计分布$P_g$的逆。至此，已经有了真实样本$x$、真实分布$P_r$($P_r$可以用样本来估计)以及生成器G产生的假样本$x$和估计分布$P_g$($P_g$还可以用假样本估计)。
        \par
        现在考虑能用这两个样本数据$x\sim P_g,x\sim P_r$来做什么。最终目标是通过二者来说明生成器(生成网络)G的好坏，以及如何指导我们构建好的生成器。一个直观的想法是通过$P_g$与$P_r$的距离/散度来评价G的好坏。
        \subsubsection{不考虑判别器D}
            \par
            先不考虑GAN中的判别器D(GAN中用D来辨识真假样本$(x,x)$，以此得到更好的G)，设$x$是来自$P_r$的样本数据，$x= \{x_1,x_2,\dots,x_n\}$共$n$个样本；$x\sim P_g$是生成器G带来的假样本(假设假样本有许多个)。\ding{172}如果$x\sim P_r$是一个随机变量，我们会问来自$P_g$的一个假样本$x\sim P_g$是否在真实样本分布$P_r$内？\ding{173}如果$x\sim P_r$是一随机向量，我们会问来自$P_g$的一个假样本$x\sim P_g$是否在真实样本分布$P_r$内？\ding{174}如果$x\sim P_r$是一随机矩阵(图片)，我们会问来自$P_g$的一个假样本$x\sim P_g$是否在真实样本分布$P_r$内？
            \par
            明显的一个问题是：我们不能问单一的假样本$x\sim P_g$是否在$P_r$内，只能看到$x\sim P_g$在$P_r$内的概率值。我们希望假样本$x$在$P_g$的概率和在$P_r$的概率值相等或者差不多，即$P_g$和$P_r$相似。这又回到了$P_r,P_g$相似程度的度量，如图(\ref{fig:单一样本在2个分布中的概率值比较图})(a)(b)所示
            \begin{figure}[H]
            \centering
            \includegraphics[width=4.5cm]{single_salmplein_2_equiv1}
            \qquad
            \includegraphics[width=4cm]{single_salmplein_2_equiv2}
            \caption{单一样本在2个分布中的概率值比较图}
            \label{fig:单一样本在2个分布中的概率值比较图}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：单一样本在2个分布中的概率值比较图}\\
            当然，如果从单一样本的角度来看，从$P_g$中按概率抽取一个样本$x^*$，希望$x^*$和$\mathbb{E}_{x\sim P_r}(x)$接近，或者更近一步的说，我们希望两个总体$P_r,P_g$的均值相等。这变成了两总体均值相等检验问题，其示意图如图(\ref{fig:2总体均值是否相等示意图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=4cm]{images/2_equiv.jpg}
                \caption{总体均值是否相等示意图}
                \label{fig:2总体均值是否相等示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：2总体均值是否相等示意图}\\
            \subsubsection{考虑固定的判别器D}
            \par
            现在，对于真假样本$x\sim P_r,x\sim P_g$，考虑一个判别器Ditector。并且，这里的判别器D是固定的，即D已经训练好了，在训练过程中D不再训练。而GAN中的D是需要训练的。我们从$P_g$中生成了$n$个样本$\{x_i\}_{i=1}^n$，从$P_r$中产生$n$个样本$\{x_i\}_{i=1}^n$，将二者混合在一起，输入到D中，对于每一个样本$x$，D都会给出$x$被判别为真的概率，记这个判别概率为$D(x)$($D(x)$是样本$x$被判为来自$P_r$的概率)。自然希望求G，使G带来的样本$x\sim P_g$被判为$P_r$的概率$D(x\sim P_g)$尽可能高(其实，没有必要将$x\sim P_r$输入到判别器D中)，即
            \begin{align*}
            & \max _G\ \sum_{i=1}^n D(x_i)\\
            & s.t. \quad x_i\sim P_g,\quad i=1,2,\dots,n
            \end{align*}
            D中含有$P_r$的特征，当G能够欺骗D时，说明$P_g$也有了$P_r$的特征，进一步$x\sim P_g$可以充当$P_r$的样本。我们将上面的表达式写成平均值的形式，有
            \begin{align*}
            \max _G \ \frac{1}{n}\sum_{i=1}^n D(x_i) ,\quad x_i \sim P_g
            \end{align*}
            上式等价于
            \begin{align*}
            \max_G\ \mathbb{E}_{x\sim P_g} D(x)
            \end{align*}
            等价于
            \begin{align*}
            \min _G \ \mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align*}
            \par
            当然，我们可以将$D(x)$的形式进行变换，比如$\log D(x)$或者$\log (1-D(x))$。求解上面的优化问题，最终会得到一个G，我们称G是在D下的生成器，$P_g$是在D下的$P_r$的估计。
            \par
            在这一部分中，是在D的判别下让$x$使$P_r$的概率最大。回到前一部分，对于一个给定的$x\sim P_g$，我们也会有$x$在$P_r$中的概率，即假样本$x$在真分布$P_r$中的概率，如图(\ref{fig:假样本在真分布的概率示意图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=5cm]{images/fault_sample_in_real_distribution.jpg}
                \caption{假样本在真分布的概率示意图}
                \label{fig:假样本在真分布的概率示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0 }{todo:图片：假样本在真分布的概率示意图}\\
            于是也可以设定目标
            \begin{align*}
            \max_G\ \mathbb{E}_{x\sim p_g}P_r(x)
            \end{align*}
            其中：$P_r(x)$表示样本$x\sim P_g$在$P_r$的概率。这里的$P_r$就充当了判别器D，而判别器D充当了极大似然估计中的似然函数(样本$x\sim P_g$在$P_r$或者D下出现的概率最大)。所以，在这一部分中，还可以对G设置联合概率最大的目标，如下
            \begin{align*}
            &\max_G\ D(x)_{x\sim P_g} = D(x_1)D(x_2)\cdots D(x_n)\\
            &\max_G\ P_r(x)_{x_1,\dots,x_n\overset{iid}{\sim }P_g} = P_r(x_1)P_r(x_2)\cdots P_r(x_n)
            \end{align*}
            注意到，生成器G的好坏与D的判别率有直接关系。
        \subsubsection{可变动的判别器D}
            \par
            在上一部分，我们设定判别器D是固定的，现在，假设在对真假样本$(x,x)$进行判别时，D也在不断的学习。
            \par
            在每次对G进行训练/迭代之前，我们都训练一下D。直观的说：第$t$次迭代时，从$P_g$中产生了$n$个样本，通过D判别后，找到了G的修正方案(梯度)，然后G更新为G。在$t+1$次迭代时，从$P_g$中再次产生$n$个新样本，问题是：还用那个老旧的D来做判别吗？不！我们用一个新的D来做判别(可以再找其它的判别模型进行判别，还可以联合判别，这个之后再讨论)，这里不打算换用其它类型的判别器，仍然在D上做，但要求$t+1$时刻的D更准确。我们需要训练D，要训练D则需要用于训练的样本数据，这里有两种方案：1种是样本不变，1种是将$x\sim P_g$加入到D的训练当中。采用第二种方案，将$x\sim P_g$的标签值设置为$-1$或$0$，表示“假”，然后训练D即可。
            \par
            当然，在GAN中，作者给D的训练设置了目标：要求D使$x\sim P_r$被判为真样本的概率$D(x\sim P_r)$尽可能大，$x\sim P_g$被判为真样本的概率$D(x\sim P_g)$尽可能小，即
            \begin{align*}
            \max \ \sum_{i=1}^n D(x_i)_{x_1,\dots,x_n\sim P_r}\\
            \min \ \sum_{i=1}^n D(x_i)_{x_1,\dots,x_n\sim P_g}
            \end{align*}
            将上式改为均值形式，有
            \begin{align*}
            \max_D\ \mathbb{E}_{x\sim P_r} D(x)\\
            \min_D\ \mathbb{E}_{x\sim P_g} D(x)
            \end{align*}
            其中，第二个目标等价于
            \begin{align*}
            \max_D\ \mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align*}
            将上述两个目标合并，有
            \begin{align*}
            \max _D\ \mathbb{E}_{x\sim P_r}[D(x)] + \mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align*}
            \par
            捋一下：当前时刻$t$更新完G之后$G_t$，在$t+1$时刻，要先训练一会儿D(得到$D_{t+1}$)，然后再用新的$D_{t+1}$来进行判别，求G的更新方向$G_{t+1} = G_t+\Delta G_t$。对于G，我们的目标是
            \begin{align*}
            \min_G\ \mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align*}
            对于D，目标是
            \begin{align*}
            \max_D\ \mathbb{E}_{x\sim P_r}[D(x)]+\mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align*}
            \par
            将上述两个目标合并，形成二层规划或者最小最大规划，有
            \begin{align}
            \label{GAN模型1}
            \min_G\ \max_D\ \mathbb{E}_{x\sim P_r}[D(x)]+\mathbb{E}_{x\sim P_g}[1-D(x)]
            \end{align}

    \subsection{Vanilla GAN}
        \subsubsection{原始GAN模型}
            \par
            在GAN原文\cite{2014.Goodfellow}中，作者将上述目标(\ref{GAN模型1})的判别概率$D(x)$变为了$\log D(x)$，有
            \begin{align*}
            \min_G\ \max_D\ V(D,G) =  \mathbb{E}_{x\sim P_r}[\log D(x)]+\mathbb{E}_{x\sim P_g}[\log(1-D(x))]
            \end{align*}
            再将$x\sim P_g$改写为$x = G(z),z\sim U[0,1]$，将$U[0,1]$扩展为$P_z$，有
            \begin{align}
            \label{GAN原始目标}
            \min_G\ \max_D\ V(D,G) =  \mathbb{E}_{x\sim P_r}[\log D(x)]+\mathbb{E}_{z\sim P_z}[\log(1-D(G(z)))]
            \end{align}
            \par
            下面来分析一下GAN的优化模型(\ref{GAN原始目标})。对于$\min_G\max_D$，\ding{172}先固定G来看$\max_D$：
            \begin{theorem}[最优判别器D]
            在G固定的条件下，最优判别器D\footnote{注意，这里是密度函数$p_g,p_r$。}为
            \begin{align*}
            D_G^*(x) = \frac{p_r(x)}{p_r(x)+p_g(x)}
            \end{align*}
            \end{theorem}
            \begin{Proof}
            给定G，训练D就是求解
            \begin{align*}
            \max_D \ V(G,D) = \mathbb{E}_{x\sim P_r}[\log D(x)]+\mathbb{E}_{z\sim P_z}[\log(1-D(G(z)))]
            \end{align*}
            而
            \begin{align*}
            V(G,D) &= \int_x p_r(x) \log D(x)\mathrm{d}x + \int_z p_z(z)\log(1-D(G(z)))\mathrm{d}z\\
            &=\int_x p_r(x)\log D(x)+ p_g(x)\log(1-D(x))\mathrm{d}x
            \end{align*}
            对于函数$a\log(y)+b\log(1-y)$，$\forall (a,b)\in R^2/\{0,0\}$在$[0,1]$处取得最大值$\frac{a}{a+b}$。
            \end{Proof}
            \par
            \ding{173}在得到最优判别器$D^*$的情况下，来求$\min_G\ V(G,D^*)$。我们先将$D^*$带入到$V(G,D)$，有
            \begin{align*}
            V(G,D^*) &= \mathbb{E}_{x\sim P_r}[\log D^*(x)] + \mathbb{E}_{z\sim P_z}[\log (1-D^*(G(z)))]\\
            &=\mathbb{E}_{x\sim P_r}[\log D^*(x)]+\mathbb{E}_{x\sim P_g}[\log (1-D^*(x))]\\
            &=\mathbb{E}_{x\sim P_r} \left[ \log \frac{p_r(x)}{p_r(x)+p_g(x)} \right] + \mathbb{E}_{x\sim P_g} \left[\log \frac{p_g(x)}{p_r(x)+p_g(x)}   \right]
            \end{align*}
            令$C(G) = V(G,D^*)$，则要求$\min_G\ C(G)$。
            \begin{theorem}
            当且仅当$p_r = p_g$时，$C(G)$有全局极小点，且$C(G)$在此点处的值为$-\log 4$。
            \end{theorem}
            \begin{Proof}
            考虑$p_g = p_r$，则$D^*(x) = \frac{1}{2}$，于是
            \begin{align*}
            C(G) & = \log \frac{1}{2}+\log \frac{1}{2} = -\log 4\\
            & = \mathbb{E}_{x\sim P_r}(-\log 2)+\mathbb{E}_{x\sim P_g}(-\log 2)
            \end{align*}
            为了表明$p_g = p_r$是最小点，$-\log 4$是最小值，我们将$C(G)$减去$-\log 4$。如果$C(G)+\log 4 \geqslant 0$，则表明$C(G)$的最小值为$-\log 4$。
            \begin{align*}
            C(G) & = -\log 4 + KL \left( P_r\Big|\Big| \frac{P_r+P_g}{2} \right) + KL \left( P_g\Big|\Big| \frac{P_r+P_g}{2} \right) \\
            & = -\log 4+ 2JSD(P_r||P_g)
            \end{align*}
            由JSD散度(Jensen Shannon Dirergence)\footnote{
                For distributions $P$ and $Q$ of a continuous random variable, the Kullback–Leibler divergence is defined to be the integral
                \begin{align*}
                    KL(P||Q) = \int_{-\infty}^\infty p(x) \log \frac{p(x)}{q(x)}\mathrm{d}x
                \end{align*}
                where$ p $and$ q $denote the densities of$ P $and$ Q$.
             }
            可知，当且仅当$p_r = p_g$时JSD = 0，否则JSD$>0$。于是$C(G) \geqslant 0$，当且仅当$p_r = p_g$时，等号成立。
            \end{Proof}
            \par
            回看上面的证明，我们会发现，在D给定后，求G就是求$\min _G C(G)$。而$C(G)$去掉他的极小值后，就是一个$P_r,P_g$的JSD散度，所以，我们求G的本质是求
            \begin{align*}
            \min _G\ JSD(P_r||P_g) = KL \left( P_r\Big|\Big| \frac{P_r+P_g}{2} \right) + KL \left( P_G\Big|\Big| \frac{P_r+P_g}{2} \right)
            \end{align*}
            自然会考虑能否为G设置其他的散度或距离(D的目标基本不变)
            % \footnote{https:\/\/en.wikipedia.org\/wiki\/Kullback\\\%E2\\\%80\\\%93Leibler\\\\_divergence\}
            ，这将在后面的$f$-GAN中进行详细说明。下面，给出GAN的程序。
        \subsubsection{GAN算法与程序}
            \par
            GAN的伪代码如(\ref{code:Vanilla GAN})所示
            \begin{algorithm}[htbp]
                \caption{Minibatch stochastic gradient descent training of GAN}\label{code:Vanilla GAN}
                \begin{algorithmic}[1]
                    \State 初始化：$P_r$的真实样本$\{x_i\}_{i=1}^n$(即原有的样本数据)，迭代步$t$，$t_max$，生成器G判别器D，设G和D的参数为$\theta_g,\theta_d$，每迭代步$t$下，判别器训练次数$k$(即在一次更新G下，要更新$k$次D)，批量大小$m$。
                    \For {$t=1,2,\dots,t_{max}$}
                        \State $//$更新D
                        \For {$k$ steps}
                            \State sample minibatch of m noise sample $\{z^{(1)},z^{(2)},\dots,z^{(m)}\}$ from $P_z$；生成$m$个假样本$x^{(1)} = G(z^{(1)}),x^{(2)} = G(z^{(2)}),\dots,x^{(m)} = G(z^{(m)})$。
                            \State sample minibatch of m example $\{x^{(1)},x^{(2)},\dots,x^{(m)}\}$ from $P_r$。即从原始数据$\{x_i\}_{i=1}^n$中挑出$m$个。
                            \State 将$2m$个真假样本$x^{(i)}$输入到判别器D，得到各样本属于真实分布的概率$D(x^{(i)})$
                            \begin{align*}
                            \max_D\ V(D,G) = \mathbb{E}_{x\sim P_r}[\log D(x)]+\mathbb{E}_{z\sim P_z}[\log (1-D(G(z)))]
                            \end{align*}
                            \State 求D的梯度
                            \begin{align*}
                            &\nabla _{\theta_d} \frac{1}{m} \sum_{i=1}^m [\log D_t(x^{(i)})]+\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^m [\log (1-D_t(G_t(z^{(i)})))]\\
                            ={}&\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^m [\log D_t(x^{(i)})+\log (1-D_t(G_t(z^{(i)})))]
                            \end{align*}
                            \State 求$D_{t+1} = D_t+\nabla_{\theta_d}$；
                        \EndFor
                        \State $//$ 更新G
                        \State sample minibatch of m noise sample $\{z^{(1)},z^{(2)},\dots,z^{(m)}\}$ from $P_z$；
                        \State 计算梯度
                        \begin{align*}
                        \nabla _{\theta_g}\frac{1}{m}\sum_{i=1}^m \log (1-D_{t+1}(G(z^{(i)})))
                        \end{align*}
                        \State 更新$G$
                        \begin{align*}
                        G_{t+1} = G_t + \nabla_{\theta_g}
                        \end{align*}
                    \EndFor
                \end{algorithmic}
            \end{algorithm}
            \par
            GAN模型的TensorFlow\footnote{http://www.tensorfly.cn/}\footnote{https://www.tensorflow.org/}程序如下，更详细的可以参考\footnote{https://github.com/wiseodd/generative-models/tree/master/GAN}
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, 784])
            D_W1 = tf.Variable(xavier_init([784, 128]))
            D_b1 = tf.Variable(tf.zeros(shape=[128]))
            D_W2 = tf.Variable(xavier_init([128, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            Z = tf.placeholder(tf.float32, shape=[None, 100])
            G_W1 = tf.Variable(xavier_init([100, 128]))
            G_b1 = tf.Variable(tf.zeros(shape=[128]))
            G_W2 = tf.Variable(xavier_init([128, 784]))
            G_b2 = tf.Variable(tf.zeros(shape=[784]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            def sample_Z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def generator(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                D_logit = tf.matmul(D_h1, D_W2) + D_b2
                D_prob = tf.nn.sigmoid(D_logit)
                return D_prob, D_logit
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            G_sample = generator(Z)
            D_real, D_logit_real = discriminator(X)
            D_fake, D_logit_fake = discriminator(G_sample)
            # D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_fake))
            # G_loss = -tf.reduce_mean(tf.log(D_fake))
            # Alternative losses:
            # -------------------
            D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))
            D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))
            D_loss = D_loss_real + D_loss_fake
            G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))
            D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)
            G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)
            mb_size = 128
            Z_dim = 100
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                if it % 1000 == 0:
                    samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})

                    fig = plot(samples)
                    plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
                    plt.close(fig)
                X_mb, _ = mnist.train.next_batch(mb_size)
                _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})
                _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})
                if it % 1000 == 0:
                    print('Iter: {}'.format(it))
                    print('D loss: {:.4}'. format(D_loss_curr))
                    print('G_loss: {:.4}'.format(G_loss_curr))
            print()
            \end{lstlisting}

    \subsection{f-GAN}
        \par
        文献\cite{2016.Sebastian}中介绍了一些“可行”的divergence和distance(注意：距离和散度不是同一概念，距离是对称的而散度不是)，并且Sebastian等也从变分角度给出了设置判别器D的原因。
        \subsubsection{f-散度族}
            \par
            KL距离可能是最为常用的散度了，它用于衡量2个概率分布$P_r,P_g$的不同程度。现在，我们来介绍一大类散度：$f$-散度族。令$x$为随机变量，$\mathcal{X}$是其取值域(domain)，$f$-散度定义为
            \begin{align*}
            D_f(P_r||P_g) = \int_\mathcal{X}p_g(x)f \left( \frac{p_r(x)}{p_g(x)} \right) \mathrm{d}x
            \end{align*}
            其中：$f:R^+\to R$是一个凸的单调函数，满足$f(1) = 0$。$f$不同，最终的距离/散度$D_f(P_r||P_g)$就不同。常见的$f$以及由其形成的$D_f(P_r||P_g)$如图(\ref{fig:f散度族})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=15cm]{images/fsandu1.jpg}
                \caption{f散度族}
                \label{fig:f散度族}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:表格：f散度族}\\
            其中：$u$是$f$的自变量，$dom_f$表示$f$的自变量域，即$u$的域。下面，我们来看$f$散度的变分估计。
        \subsubsection{Veriational Estimation of f-divergence}
            \par
            在GAN中求解G时，使用上面介绍的$f$散度，目标变为求G使$D_f(P_r||P_g)$最小，有
            \begin{align*}
            \min_G\ D_f(P_r||P_g) = \int_\mathcal{X}p_g(x)f \left( \frac{p_r(x)}{p_g(x)} \right) \mathrm{d}x
            \end{align*}
            此时的G中还不具有参数，因此上述问题是一个关于$P_g$的变分问题。Nguyen讨论了在只有$P_g,P_r$(无$f$)时，$f$-divergence的一个一般化的变分估计方法。下面，我们将会用变分估计方法来求解G (将$P_g$参数化后求参数$\theta_g$)。为了完整，我们给出Nguyan散度估计的一个self-containde：
            \par
            对于任意一个凸的单调函数$f$，有一个凸共轭(conjugate)函数$f^*$，也被称为fenchel共轭。定义为
            \begin{align*}
            f^*(t) = \sup_{u\in dom_f}\{ut - f(u)\}
            \end{align*}
            并且，$f^*$也是凸的单调的。对于这对函数$(f,f^*)$，有$f^{**} = f$。因此，可以将$f$表示为
            \begin{align*}
            f(u) = \sup_{t\in dom_{f^*}} \{tu - f^*(t)\}
            \end{align*}
            将$f(u)$带入到$D_f(P_r||P_g)$中，有(这里的$u$是$\frac{p_r(x)}{p_g(x)}$)
            \begin{align*}
            D_f(P_r||P_g) & = \int_\mathcal{X} p_g(x )f \left( \frac{p_r(x)}{p_g(x)} \right)\mathrm{d}x\\
            & =\int _\mathcal{X} p_g(x) \sup_{t\in dom_{f^*}} \left\{t\frac{p_r(x)}{p_g(x)} - f^*(t)\right\} \mathrm{d}x \\
            &\geqslant \sup_{t\in dom_{f^*}}\int_\mathcal{X} p_g(x) t\frac{p_r(x)}{p_g(x)} - p_g(x)f^*(t)\mathrm{d}x \quad \text{Jensen不等式}\\
            &\geqslant \sup _{T\in \Gamma} \left( \int_\mathcal{X}p_r(x)T(x)\mathrm{d}x - \int_\mathcal{X} p_g(x)f^*(T(x))\mathrm{d}x \right)\\
            & = \sup _{T\in \Gamma} \left( \mathbb{E}_{x\sim  P_r}[T(x)] - \mathbb{E}_{x\sim  P_g}[f^*(T(x))] \right)
            \end{align*}
            其中：$T(x):\mathcal{X}\to R$是$\mathcal{X}$上的函数，$\Gamma$是$T$的任意一个函数集，且是无穷维函数空间(T的所有可能)的一个小部分(subset)，因此有第二个不等号。
            \par
            可以发现，这里的$T$就相当于GAN中的分类器D。计算上式得变分下界，我们发现，在可能的函数集$\Gamma$中，the bound is tight for
            \begin{align*}
            T^*(x) = f' \left( \frac{p_r(x)}{p_g(x)} \right)
            \end{align*}
            其中：$f'$是$f$的一阶导。这个情况可以用于指导我们如何选择$f$以及设计函数集$\Gamma$。例如：KL散度相当于$f(u) = -\log (u)$，其下界为$T^*(x) = -\frac{p_g(x)}{p_r(x)}$，图(\ref{fig:f散度族})中给出了一些$f$散度，图(\ref{fig:f散度的共轭})给出了共轭$f^*$以及$f^*$的域$dom_{f^*}$。
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/fsandu.jpg}
                \caption{f散度的共轭}
                \label{fig:f散度的共轭}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：f散度的共轭}
            \par
            上述问题仍然是一个泛函(变分)问题
            \begin{align*}
            \min_{P_g} \ \sup_{T}\ V(P_r,T) = \mathbb{E}_{x\sim P_r}[T(x)] - \mathbb{E}_{x\sim P_g}[f^*(T(x))]
            \end{align*}
            下面来处理这个泛函问题。像一般的泛函问题那样，将函数问题参数化，将求函数问题变为求参数问题。将两个函数$P_g \triangleq G $和$T\triangleq D$参数化，设其参数为$\theta_g,\theta_d$，于是有
            \begin{align*}
            \min_{\theta_g} \ \max_{\theta_d}\ F(\theta_g,\theta_d) = \mathbb{E}_{x\sim P_r}[T_{\theta_d}(x)] - \mathbb{E}_{x\sim P_{\theta_g}}[f^*(T_{\theta_d}(x))]
            \end{align*}
            \par
            为了书写方便，令$(\theta_g,\theta_d) \triangleq (\theta,w)$，$T_w(x)  = g_f(V_w(x))$，于是上述目标变为
            \begin{align*}
            \min_\theta \ \max_w \ F(\theta,w) = \mathbb{E}_{x\sim P_r}[g_f(V_w(x))] + \mathbb{E}_{x\sim P_g}[-f^*(g_fV_w(x))]
            \end{align*}
            其中：$V_w:\mathcal{X}\to R$的输出$R$不存在任何限制，$g_f:R\to dom_{f^*}$是一个输出激活函数。
        \subsubsection{f-GAN的程序}
            \par
            f-GAN的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 64
            h_dim = 128
            lr = 1e-3
            d_steps = 3
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def generator(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                out = tf.matmul(D_h1, D_W2) + D_b2
                return out
            G_sample = generator(z)
            D_real = discriminator(X)
            D_fake = discriminator(G_sample)
            # Uncomment D_loss and its respective G_loss of your choice
            # ---------------------------------------------------------
            """ Total Variation """
            # D_loss = -(tf.reduce_mean(0.5 * tf.nn.tanh(D_real)) -
            #            tf.reduce_mean(0.5 * tf.nn.tanh(D_fake)))
            # G_loss = -tf.reduce_mean(0.5 * tf.nn.tanh(D_fake))
            """ Forward KL """
            # D_loss = -(tf.reduce_mean(D_real) - tf.reduce_mean(tf.exp(D_fake - 1)))
            # G_loss = -tf.reduce_mean(tf.exp(D_fake - 1))
            """ Reverse KL """
            # D_loss = -(tf.reduce_mean(-tf.exp(D_real)) - tf.reduce_mean(-1 - D_fake))
            # G_loss = -tf.reduce_mean(-1 - D_fake)
            """ Pearson Chi-squared """
            D_loss = -(tf.reduce_mean(D_real) - tf.reduce_mean(0.25*D_fake**2 + D_fake))
            G_loss = -tf.reduce_mean(0.25*D_fake**2 + D_fake)
            """ Squared Hellinger """
            # D_loss = -(tf.reduce_mean(1 - tf.exp(D_real)) -
            #            tf.reduce_mean((1 - tf.exp(D_fake)) / (tf.exp(D_fake))))
            # G_loss = -tf.reduce_mean((1 - tf.exp(D_fake)) / (tf.exp(D_fake)))

            D_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(D_loss, var_list=theta_D))
            G_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(G_loss, var_list=theta_G))
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                X_mb, _ = mnist.train.next_batch(mb_size)
                z_mb = sample_z(mb_size, z_dim)
                _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, z: z_mb})
                _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={z: z_mb})
                if it % 1000 == 0:
                    print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}

    \subsection{Conditional GAN}
        \par
        回顾前面的GAN，在生成假样本$x\sim P_g$时，用$x = G(z),z\sim U[0,1]$，即生成器G的网络输入仅是随机值$z$。现在，考虑能否将其它信息作为G的输入来生成假样本$x$，即生成网络的输入$z$变为其它形式(还可以考虑G在生成$x$的同时还生成其它信息，这个后面讨论)。可以尝试用$z\sim N$来替代原本的$z\sim U$，这是行的通的，并且也可以解释的通(下面解释)。但是，即便是$z\sim f$，GAN仍然是一个无指导性的生成：训练后的GAN只能生成room图片，而不能根据要求生成相应的图片(比如要求GAN生成狗的图片，再生成猫的图片)。
        \par
        现在，考虑这样一种生成问题：用同一个GAN，生成数字1、数字2$\cdots$，即我们来指导GAN生成哪些事物，称这些指导为指导信息。我们将指导信息作为输入来生成假样本$x$。
        \par
        在介绍CGAN之前，先来考虑一般的图像回归/分类问题$X\to Y$，构建回归器
        \begin{align*}
        & y = w \phi(x)+z\\
        & z\sim N(0,\sigma^2)
        \end{align*}
        更一般的，记为$y = \varphi(x)+z$。既然可以从$X\to Y$，我们同样可以用神经网络来构建$Y\to X$的映射，有
        \begin{align*}
        x = G(y)+z
        \end{align*}
        这里的$y$即为图像的标签信息。在图像分类任务中，我们将图片$x$作为输入，标签值$y$作为输出，构建$X\to Y$的映射，现在反过来，以$y$为输入，$x$为输出，构建$Y\to X$的映射以生成图像(一个很普通的问题是：当$y$和$z$的维度很低时，要生成高维$x$是不易的)。
        \par
        要从$x = G(y)+z$中采样($y = \varphi(x)+z$中采样是一样的)，我们都只需要取一个$y$形成$G(y)$，再生成多个随机值$z$，将$G(y)$和多个随机值$z$相加，求平均即可，即$x_i = \sum_{j}G(y_i)+z_{ij} $。
        \begin{align*}
        p_g(x) & = \int _z p(x,z)\mathrm{d}z\\
        & =\int_z p(x|z)p(z)\mathrm{d}z\\
        & =\sum_zp(x|z)p(z)
        \end{align*}
        更一般的\cite{2014.Mirza}，在输入层中加入噪声$z$，如图(\ref{fig:CGAN生成网络示意图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=5cm]{images/CGAN_product_network.jpg}
                \caption{CGAN生成网络示意图}
                \label{fig:CGAN生成网络示意图}
                \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：CGAN生成网络示意图}\\
        $x = G(z,y)$。注意，这里和前面DAE中添加噪声的方法有所不同，DAE是在$x$中添加噪声，形成$\tilde{x} = x+z$，而这里是将$z$作为输入的一部分。
        \par
        在判别器D中，将$y$作为输入，$x$作为输入来进行判别，$D(x|y)$表示$y$给定后，输入样本$x$为真的概率。这里有一个问题：判别器D的输入和输出是什么？\ding{172}输入为标签值$y$，输出为$p(x|y)$，表示输入$y$输出为$x$的条件概率。\ding{173}输入是$(y,x)$，输出是$D(x|y)$，表示输入$y,x$为真的概率。如果是第一种方法，则G和D作的任务是一样的。采用第二种方法，CGAN的网络结构图如图(\ref{fig:CGAN网络结构图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/CGAN_network.jpg}
                \caption{CGAN网络结构图}
                \label{fig:CGAN网络结构图}
                \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：CGAN网络结构图}\\
        可以构建如下条件GAN(CGAN)的目标
        \begin{align*}
        \min_G\ \max_D\ V(D,G) & = \mathbb{E}_{x\sim P_r}[\log D(x|y)] + \mathbb{E}_{z\sim P_z}[\log (1-D(x|y))]\\
        & = \mathbb{E}_{x\sim P_r}[\log D(x|y)] + \mathbb{E}_{z\sim P_z}[\log (1-D(G(z,y)|y))]
        \end{align*}
        值得一提的是，CGAN中的$z$可以是任意的噪声，不局限于均匀噪声$z\sim U[0,1]$。CGAN的TensorFolw程序如下
        \begin{lstlisting}[language = Python]
        import tensorflow as tf
        from tensorflow.examples.tutorials.mnist import input_data
        import numpy as np
        import matplotlib.pyplot as plt
        import matplotlib.gridspec as gridspec
        import os
        mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
        mb_size = 64
        Z_dim = 100
        X_dim = mnist.train.images.shape[1]
        y_dim = mnist.train.labels.shape[1]
        h_dim = 128
        def xavier_init(size):
            in_dim = size[0]
            xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
            return tf.random_normal(shape=size, stddev=xavier_stddev)
        """ Discriminator Net model """
        X = tf.placeholder(tf.float32, shape=[None, 784])
        y = tf.placeholder(tf.float32, shape=[None, y_dim])
        D_W1 = tf.Variable(xavier_init([X_dim + y_dim, h_dim]))
        D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
        D_W2 = tf.Variable(xavier_init([h_dim, 1]))
        D_b2 = tf.Variable(tf.zeros(shape=[1]))
        theta_D = [D_W1, D_W2, D_b1, D_b2]
        def discriminator(x, y):
            inputs = tf.concat(axis=1, values=[x, y])
            D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)
            D_logit = tf.matmul(D_h1, D_W2) + D_b2
            D_prob = tf.nn.sigmoid(D_logit)
            return D_prob, D_logit
        """ Generator Net model """
        Z = tf.placeholder(tf.float32, shape=[None, Z_dim])
        G_W1 = tf.Variable(xavier_init([Z_dim + y_dim, h_dim]))
        G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
        G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
        G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
        theta_G = [G_W1, G_W2, G_b1, G_b2]
        def generator(z, y):
            inputs = tf.concat(axis=1, values=[z, y])
            G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)
            G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
            G_prob = tf.nn.sigmoid(G_log_prob)
            return G_prob
        def sample_Z(m, n):
            return np.random.uniform(-1., 1., size=[m, n])
        def plot(samples):
            fig = plt.figure(figsize=(4, 4))
            gs = gridspec.GridSpec(4, 4)
            gs.update(wspace=0.05, hspace=0.05)
            for i, sample in enumerate(samples):
                ax = plt.subplot(gs[i])
                plt.axis('off')
                ax.set_xticklabels([])
                ax.set_yticklabels([])
                ax.set_aspect('equal')
                plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
            return fig
        G_sample = generator(Z, y)
        D_real, D_logit_real = discriminator(X, y)
        D_fake, D_logit_fake = discriminator(G_sample, y)
        D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))
        D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))
        D_loss = D_loss_real + D_loss_fake
        G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))
        D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)
        G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)
        sess = tf.Session()
        sess.run(tf.global_variables_initializer())
        if not os.path.exists('out/'):
            os.makedirs('out/')
        i = 0
        for it in range(1000000):
            if it % 1000 == 0:
                n_sample = 16
                Z_sample = sample_Z(n_sample, Z_dim)
                y_sample = np.zeros(shape=[n_sample, y_dim])
                y_sample[:, 7] = 1
                samples = sess.run(G_sample, feed_dict={Z: Z_sample, y:y_sample})
                fig = plot(samples)
                plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')
                i += 1
                plt.close(fig)
            X_mb, y_mb = mnist.train.next_batch(mb_size)
            Z_sample = sample_Z(mb_size, Z_dim)
            _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: Z_sample, y:y_mb})
            _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: Z_sample, y:y_mb})
            if it % 1000 == 0:
                print('Iter: {}'.format(it))
                print('D loss: {:.4}'. format(D_loss_curr))
                print('G_loss: {:.4}'.format(G_loss_curr))
        print()
        \end{lstlisting}
        \par
        实验：在MINIST数据集上，以类别标签为条件$y$(one - hot编码)，给定$z$后，生成0-9数字图像，然后将$(y,x|y)\sim P_g$，$(y,x|y)\sim P_r$作为训练集输入到D中进行判断。最终生成的0-9数字图像如图(\ref{fig:CGAN数字生成图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/CGAN_number.jpg}
                \caption{CGAN数字生成图}
                \label{fig:CGAN数字生成图}
                \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：CGAN数字生成图}

    \subsection{InfoGAN}
        \subsubsection{InfoGAN模型建立}
            \par
            前面GAN生成器为$x = G(z)$，CGAN的生成器为$x = G(z,y)$，这里的$y$为指导信息。现在，考虑在生成器G的输入层加入一些$x$自身的信息，比如$x$的主成分。构建如下生成器
            \begin{align*}
            x = G(z,x')
            \end{align*}
            其中：$x'$为图像$x$的部分特征信息，例如，要生成$n\times n$大小的图像，可以用$m\times m(m <n)$的部分图像作为$x'$。进一步考虑条件GAN，有
            \begin{align*}
            x = G(z,x',y)
            \end{align*}
            其中：$x'$为$x$的部分特征，$y$为指导信息，$z$为噪声。其实，可以将$y$视为$x$的部分特征$x'$的一部分。
            \par
            现在，来看InfoGAN\cite{2017.Chen}的思路：InfoGAN将输入改为$z$和$c$。$z$仍为噪声，$c$设定为潜变量($c$可以对应于笔画粗细、图像光照、字体倾斜度等，我们称之为latent code)。设共有$L$个潜变量$c_1,c_2,\dots,c_L$(用$c$表示)，于是生成器G为
            \begin{align*}
            x = G(z,c)
            \end{align*}
            并且假设$c_1,c_2,\dots,c_L$之间相互独立，即$P(c_1,c_2,\dots,c_L) = \prod_{i=1}^LP(c_i)$。生成器G构建完成之后，要考虑判别器D，D的设置仍然和前面一样。下面就要考虑如何构建目标，以及$c\sim P_c$是什么，如果$c$是$x'$或者$c$是$x$的主成分那还好说，但如果$c$是潜在的变量，那么$P_c$如何，以及如何采样$c\sim P_c$？
            \par
            如果将$x'$作为部分的输入，我们自然希望$G(z,x')$和$x'$尽可能靠近，如果把$c$视为$x'$，这里我们希望$c$和$x = G(c,z)$尽可能靠近。用互信息$I(c;x)$来衡量二者的相关性，当$c,x$相互独立时，$I(c;x) = 0$。
            \begin{align*}
            I(c;x) = I(c;G(z,c)) = H(c) - H(x|c) = H(x) -H(c|x)
            \end{align*}
            其中：$H$为熵
            \begin{align*}
            H(x) & = -\int p(x)\log p(x)\mathrm{d}x\\
            & =-\sum_{i=1}^n p_i \log p_i\\
            & =\mathbb{E}[-\log p_i]
            \end{align*}
            并且，对于互信息$I(c;x)$，我们有
            \begin{align*}
            I(c;x) &= H(c) - H(c|x)\\
            &=H(c)+H(x) - H(c,x)\\
            &=\sum_c p(c) \log \frac{1}{p(c)} + \sum _x p(x)\log \frac{1}{p(x)} - \sum_{x,c}p(c,x)\log \frac{1}{p(c,x)}\\
            &=\sum_{c,x}p(c,x) \log \frac{p(c,x)}{p(c)p(x)}
            \end{align*}
            \par
            在设置生成器G时，应该使$c$和$x = G(c,z)$的互信息$I$尽可能大，于是有InfoGAN的目标
            \begin{align*}
            \min_G\ \max_D\ V_I(D,G) = V(D,G)-\Lambda I(c;G(z,c))
            \end{align*}
            其中：$V(D,G)$是GAN的原始目标。我们来看$I(c;x)$
            \begin{align*}
            I(c;x) =&  H(c) - H(c|x)\\
            =& H(c) - \int p(c|x)\log \frac{1}{p(c|x)}\mathrm{d}x
            \end{align*}
            这样，在计算$I(c;x)$时，就需要计算后验$p(c|x)$，这是相当麻烦的。幸运的是，我们可以用$p(c|x)$的一个近似$q(c|x)$来得到$I(c;x)$的一个下界
            \begin{align*}
            I(c;x) &= H(c) - H(c|x)\\
            &=\mathbb{E}_{x\sim G(z,c)} \left [ \mathbb{E}_{c'\sim p(c|x)}[\log p(c';x)]\right] + H(c)\\
            &=\mathbb{E}_{x\sim G(z,c)}\left[ KL(P(\cdot|x)||Q(\cdot|x))+\mathbb{E}_{c'\sim p(c|x)}[\log q(c'|x)] \right]+H(c)\\
            &\geqslant\mathbb{E}_{x\sim G(z,c)} \left[\mathbb{E}_{c'\sim p(c|x)}[\log q(c'|x)]  \right]+H(c)
            \end{align*}
            \par
            上述求互信息$I$的下界的方法称为最大变分互信息(variational Information Maximization)。$H(c)$是易于计算的，在下面的分析中，我们将其视为一个常数(熵不变)。
            \par
            So far we habe by passed the problem of having to computer the posterior $p(c|x)$. explicithy wia this hower bound but we still need to be able to sample from the posterior in the inner expection.
            \begin{lemma}[lemma 5.1]
            设$X,Y$为随机变量，$f(x,y)$为二元函数，则有
            \begin{align*}
            \mathbb{E}_{x\sim X,y\sim Y|x}[f(x,y)] = \mathbb{E}_{x\sim X,y\sim Y|x,x'\sim X|y}[f(x',y)]
            \end{align*}
            \end{lemma}
            \begin{Proof}
            \begin{align*}
            \mathbb{E}_{x\sim X,y\sim Y|x}[f(x,y)] &=\int_xp(x)\int_yp(y|x)f(x,y)\mathrm{d}y\mathrm{d}x\\
            &=\iint_{x,y}p(x,y)f(x,y)\mathrm{d}y\mathrm{d}x\\
            &=\iint_{x,y}p(x,y)f(x,y)\int_{x'}p(x'|y)\mathrm{d}x'\mathrm{d}y\mathrm{d}x\\
            &=\int_x p(x)\int_y p(y|x)\int_{x'}p(x'|y)f(x',y)\mathrm{d}x'\mathrm{d}y\mathrm{d}x\\
            &=\mathbb{E}_{x\sim X,y\sim Y|x,x'\sim X|y}[f(x',y)]
            \end{align*}
            \end{Proof}
            \par
            应用上面的引理，我们可以得到互信息$I(c;x)$的一个下界
            \begin{align*}
            I(c;x) &= \mathbb{E}_{x\sim G(z,c)} \left[ \mathbb{E}_{c'\sim p(c|x)}[\log q(c'|x)] \right]+H(c)\\
            &=\mathbb{E}_{c\sim p(c),x\sim G(z,c)}[\log q(c|x)]+H(c)\\
            &\triangleq L_1(G,q)
            \end{align*}
            \par
            $L_1(G,q)$是可以用MC方法来近似(模拟)的。现在，我们将目标$L_1(G,q)$添加到GAN的目标中，求G使$L_1(G,q)$尽可能大，有
            \begin{align*}
            \min_{G,q} \ \max_D\ V_{infoGAN}(G,G,q) = V(D,G) - \lambda L_1(G,q)
            \end{align*}
        \subsubsection{InfoGAN程序}
            \par
            InfoGAN的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, 784])
            D_W1 = tf.Variable(xavier_init([784, 128]))
            D_b1 = tf.Variable(tf.zeros(shape=[128]))
            D_W2 = tf.Variable(xavier_init([128, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            Z = tf.placeholder(tf.float32, shape=[None, 16])
            c = tf.placeholder(tf.float32, shape=[None, 10])
            G_W1 = tf.Variable(xavier_init([26, 256]))
            G_b1 = tf.Variable(tf.zeros(shape=[256]))
            G_W2 = tf.Variable(xavier_init([256, 784]))
            G_b2 = tf.Variable(tf.zeros(shape=[784]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            Q_W1 = tf.Variable(xavier_init([784, 128]))
            Q_b1 = tf.Variable(tf.zeros(shape=[128]))
            Q_W2 = tf.Variable(xavier_init([128, 10]))
            Q_b2 = tf.Variable(tf.zeros(shape=[10]))
            theta_Q = [Q_W1, Q_W2, Q_b1, Q_b2]
            def sample_Z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def sample_c(m):
                return np.random.multinomial(1, 10*[0.1], size=m)
            def generator(z, c):
                inputs = tf.concat(axis=1, values=[z, c])
                G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                D_logit = tf.matmul(D_h1, D_W2) + D_b2
                D_prob = tf.nn.sigmoid(D_logit)
                return D_prob
            def Q(x):
                Q_h1 = tf.nn.relu(tf.matmul(x, Q_W1) + Q_b1)
                Q_prob = tf.nn.softmax(tf.matmul(Q_h1, Q_W2) + Q_b2)
                return Q_prob
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            G_sample = generator(Z, c)
            D_real = discriminator(X)
            D_fake = discriminator(G_sample)
            Q_c_given_x = Q(G_sample)
            D_loss = -tf.reduce_mean(tf.log(D_real + 1e-8) + tf.log(1 - D_fake + 1e-8))
            G_loss = -tf.reduce_mean(tf.log(D_fake + 1e-8))
            cross_ent = tf.reduce_mean(-tf.reduce_sum(tf.log(Q_c_given_x + 1e-8) * c, 1))
            ent = tf.reduce_mean(-tf.reduce_sum(tf.log(c + 1e-8) * c, 1))
            Q_loss = cross_ent + ent
            D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)
            G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)
            Q_solver = tf.train.AdamOptimizer().minimize(Q_loss, var_list=theta_G + theta_Q)
            mb_size = 32
            Z_dim = 16
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                if it % 1000 == 0:
                    Z_noise = sample_Z(16, Z_dim)
                    idx = np.random.randint(0, 10)
                    c_noise = np.zeros([16, 10])
                    c_noise[range(16), idx] = 1
                    samples = sess.run(G_sample, feed_dict={Z: Z_noise, c: c_noise})
                    fig = plot(samples)
                    plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
                    plt.close(fig)
                X_mb, _ = mnist.train.next_batch(mb_size)
                Z_noise = sample_Z(mb_size, Z_dim)
                c_noise = sample_c(mb_size)
                _, D_loss_curr = sess.run([D_solver, D_loss],
                                          feed_dict={X: X_mb, Z: Z_noise, c: c_noise})
                _, G_loss_curr = sess.run([G_solver, G_loss],
                                          feed_dict={Z: Z_noise, c: c_noise})
                sess.run([Q_solver], feed_dict={Z: Z_noise, c: c_noise})
                if it % 1000 == 0:
                    print('Iter: {}'.format(it))
                    print('D loss: {:.4}'. format(D_loss_curr))
                    print('G_loss: {:.4}'.format(G_loss_curr))
            print()
            \end{lstlisting}
            \par
            在实验中，作者通过只改变latent code c中的某一个维度，来观察生成数据的变化。其实验确实证明：latent code确实学到了一些维度，如图像的角度或光照等因素，也即说明InfoGAN确实学习到了数据中的disentangled的可解释部分的表示。其效果如下三张图(\ref{fig:infoGAN实验结果})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=7cm]{images/InfoGAN1}
                \qquad
                \includegraphics[width=7cm]{images/InfoGAN2}
                \qquad
                \includegraphics[width=10cm]{images/InfoGAN3}
                \caption{infoGAN实验结果}
                \label{fig:infoGAN实验结果}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：InfoGAN效果图}

    \subsection{Mali GAN}
        \subsubsection{Mali GAN模型建立}
            \par
            尽管生成对抗网络(GAN)在获取连续分布上已经取得了成功，但其在离散背景(比如自然语言任务)上的应用却相当有限。主要的原因是通过离散变量的反向传播很困难，而且 GAN 训练目标还具有固有的不稳定性。为了解决这些问题，文献\cite{2017.Tong}提出了最大似然增强的离散生成对抗网络(Maximum-Likelihood Augmented Discrete Generative Adversarial Networks)。Mali GAN没有直接优化该 GAN 目标，而是使用遵循对数似然的推导提出了一种全新的且低方差的目标。在多种离散数据集上的实验结果表明了这方法的有效性。
            \par
            在GAN的分析中，我们知道在G给定的情况下，最优判别器D为
            \begin{align*}
            D^* = \frac{p_r}{p_r+p_g}
            \end{align*}
            给定$D^*$，真实分布密度$p_r$可以写为
            \begin{align*}
            p_r(x) = \frac{D^*}{1-D^*}p_g(x)
            \end{align*}
            即真实样本的概率可以用$p_g$的带权$\frac{D^*}{1-D^*}$来替代。然而，这样的判别器D不太可能通过训练得到，甚至不存在。为此，我们将最优$D^*$改为非最优判别器$D(x)$，据此，我们可以写出，在D给定下$p_r$的估计
            \begin{align*}
            \tilde{p}_r = \frac{D}{1-D}p_g
            \end{align*}
            上式说明，在D和G给定下，样本$x$在真实分布$p_r$中的估计值。\ding{172}回想极大似然估计，我们的目标是让样本出现的概率最大。现在可以求G，让G生成的假样本在真实分布$p_r$中的概率值最大，即
            \begin{align*}
            \max_G\  \tilde{p}_r(x)
            \end{align*}
            \par
            \ding{173}在GAN中，生成器G的目标是使两个分布$p_r,p_g$的JSD散度最小。这里，将JSD散度换为KL距离，有
            \begin{align*}
            \min_G \ KL(p_r||p_g)
            \end{align*}
            用$\tilde{p}_r$来替代$p_r$，有
            \begin{align*}
            \min_G \ KL(\tilde{p}_r||p_g)
            \end{align*}
            \par
            但可惜的是$\tilde{p}_r$并不是一个合理的概率分布，因为它的和并不为1。为此，使用归一化技术，令$r_D(x) = \frac{D(x)}{1-D(x)}$，定义归一化的$p_r$的估计为
            \begin{align*}
            q(x) = \frac{1}{Z(\theta')} \frac{D(x)}{1-D(x)} p_g(x) = \frac{r_D(x)}{Z(\theta')}p_g(x)
            \end{align*}
            其中：$Z(\theta')$为归一化因子，$Z(\theta') = \mathbb{E}_{p_g}[r_D(x)] = \sum_x p_g(x) \frac{D(x)}{1-D(x)}$。此时的$q(x)$是一个标准的概率分布，其和为1。当最优判别器是$D = D^* = \frac{1}{2}$时，$Z = 1$，$q(x) = p_g(x) = p_r(x)$，并且$q(x)$估计量的偏差仅依赖于$D(x)$，$D^*(x) = D(x)$是最小偏差。
            \par
            我们的目标是求G使$p_g$和$q$的KL距离最小(用$q$来代替$p_r$)
            \begin{align*}
            L_G(\theta_g) = KL(q(x)||p_{\theta_g}(x))
            \end{align*}
            上述目标有一个吸引人的性质：$q$是固定的。如果D被充分训练，则$q$总是接近数据分布$p_r$。定义目标的导数为$\nabla L_G = \mathbb{E}_q[\nabla_{\theta_g} \log p_{\theta_g}(x)]$，有
            \begin{align*}
            \nabla L_G =& \mathbb{E}_{p_g} \left[ \frac{q(x)}{p_g(x)} \nabla_{\theta_g}\log p_{\theta_g}(x) \right]\\
            =& \frac{1}{Z}\mathbb{E}_{p_{\theta_g}} \left[r_D(x) \nabla_{\theta_g}\log p_{\theta_g}(x) \right]
            \end{align*}
            \par
            Mali GAN通过如下的梯度估计量来求解G
            \begin{align}
            \label{近似目标}
            \nabla L_G(\theta_g) \approx \sum_{i=1}^m \left( \frac{r_D(x_i)}{\sum_i r_D(x_i)} - b \right) \nabla \log p_{\theta_g}(x_i) = \mathbb{E}(\{x_i\})
            \end{align}
            其中：$b$是一个baseline，用来增强学习以减小方差。在试验中，让$b$从0到1慢慢变大。下面，给出这种梯度近似的合理性。下述定理表明，当D接近最优时，上面的近似目标(\ref{近似目标})接近原始目标$KL(q(x)||p_g(x))$。此外，即使D没有接近最优，这个近似目标(\ref{近似目标})仍然是很好的。
            \begin{theorem}
            \par
            1.如果$D(x)$是最优的，有如下等式
            \begin{align*}
            \mathbb{E}_{p_r}[\log p_{\theta_d}(x)] = \frac{1}{Z(\theta')} \mathbb{E}_{p_g}[r_D(x)\log p_{\theta_g}(x)]
            \end{align*}
            其中：$Z(\theta') = \mathbb{E}_{p_g}[r_D(x)]$。
            \par
            2.如果$D(x)$被训练的很好，但不是最优，$\forall x$，$D(x)$在0.5到$\frac{p_r}{p_r+p_g}$，我们有：当$m\to\infty$时，almost surely
            \begin{align*}
            \mathbb{E}(\{x_i\}_{i=1}^m)\nabla _\theta KL(p_r||p_{\theta_g}) > 0
            \end{align*}
            \end{theorem}
        \subsubsection{Mali GAN算法}
            \par
            Mali GAN的伪代码如(\ref{code:Mali GAN})所示
            \begin{algorithm}[H]
                \caption{Minibatch stochastic gradient descent training of Mali GAN}\label{code:Mali GAN}
                \begin{algorithmic}[1]
                    \State 初始化：一个含参数$\theta_g$的生成器$p_{\theta_g}$；一个含参数$\theta_d$的判别器$D(x)$；baseline $b$；迭代数$t$，$t_{max}$；判别器训练次数$k$；批量大小$m$。
                    \For {$t=1,2,\dots,t_{max}$}
                        \State $//$更新D
                        \For {$k$ steps}
                            \State sample minibatch of m noise sample $\{z^{(1)},z^{(2)},\dots,z^{(m)}\}$ from $P_z$；生成$m$个假样本$x^{(1)} = G(z^{(1)}),x^{(2)} = G(z^{(2)}),\dots,x^{(m)} = G(z^{(m)})$。
                            \State sample minibatch of m example $\{x^{(1)},x^{(2)},\dots,x^{(m)}\}$ from $P_r$，即从原始数据$\{x_i\}_{i=1}^n$中挑出$m$个。
                            \State 求D的梯度
                            \begin{align*}
                            \nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^m [\log D_t(x^{(i)})+\log (1-D_t(G_t(z^{(i)})))]
                            \end{align*}
                            \State 求$D_{t+1} = D_t+\nabla_{\theta_d}$；
                        \EndFor
                        \State $//$ 更新G
                        \State sample minibatch of m noise sample $\{z^{(1)},z^{(2)},\dots,z^{(m)}\}$ from $P_z$；
                        \State 计算梯度
                        \begin{align*}
                        \sum_{i=1}^m \left( \frac{r_D(G(z^{(i)}))}{\sum_i r_D(G(z^{(i)}))} - b \right) \nabla \log p_{\theta_g}(G(z^{(i)}))
                        \end{align*}
                        \State 更新$G$
                        \begin{align*}
                        G_{t+1} = G_t + \nabla_{\theta_g}
                        \end{align*}
                    \EndFor
                \end{algorithmic}
            \end{algorithm}

    \subsection{Boundary Seeking GAN}
        \subsubsection{BGAN模型建立}
            \par
            在Mali GAN中，当$p_g(x)$已知时，在$D(x)$给定后，就可以得到$p_r$的近似$\tilde{p_r}$和$q$。并且
            \begin{align*}
            p_g(x) & = \sum_z g(x|z)p(z)\\
            & =\int_zg(x,z)\mathrm{d}z\\
            & =\int_z g(x|z)p(z)\mathrm{d}z
            \end{align*}
            G的目标是使$q$和$p_g$的KL距离最小
            \begin{align*}
            \min_G \ KL(q(x)||p_g(x))
            \end{align*}
            设$G$的参数为$\theta_g$，有
            \begin{align*}
            &\nabla_{\theta_g} KL(q(x)||p_g(x))\\
            ={}&\nabla_{\theta_g} \sum_x q(x)\log \frac{q(x)}{p_g(x)}\\
            \approx{}&-\sum_x q(x)\nabla_{\theta_g}\log p_g(x)\\
            ={}&-\sum_x \frac{1}{Z}p_g(x)\frac{D(x)}{1-D(x)} \nabla_{\theta_g}\log p_g(x)\\
            ={}&-\sum_x \frac{1}{Z}\sum_z g(x|z)p(z)\frac{D(x)}{1-D(x)}\nabla_{\theta_g}\log p_g(x)
            \end{align*}
            其中：$Z$是归一化因子，$Z = \sum _x p_g(x)\frac{D(x)}{1-D(x)}$
            \par
            上面这个梯度$\nabla_{\theta_g}$需要用MC等方法近似，并且会有很大的方差，尤其在解决$Z$时。The intuition here is to note that, as the conditional density,$ g(x|z)$ is unimodal(单峰的)，$g(x|z)$可以用来构建一个和$q(x)$类似的分布
            \begin{align*}
            \tilde{p}_z = \frac{1}{Z_z} g(x|z) \frac{D(x)}{1-D(x)}
            \end{align*}
            其中：我们使用了$\log p_g(x) = \log g(x|z) + \log p(z)$，$Z_z = \sum_x g(x|z) \frac{D(x)}{1-D(x)}$是边缘，确保$\tilde{p}_z$是一个概率分布。The gradients then become
            \begin{align*}
            \nabla_{\theta_g} KL(\tilde{p}_z(x)||g(x|z)) \approx& -\sum _x\tilde{p}_z(x) \nabla_{\theta_g(x|z)}\\
            \approx& -\sum_m \tilde{w}^{(m)} \nabla_{\theta_g}\log g(x^{(m)}|z)
            \end{align*}
            其中：$\tilde{w}^{(m)} = \frac{w^{(m)}}{\sum_{m'}w^{(m')}}$和$w^{(m)} = \frac{D(x^{(m)})}{1-D(x^{(m)})}$分别是归一化和非归一化权重；$x^{(m)}$是给定$z$后生成器生成的样本。当从$D(x)$角度看样本是相当糟糕时，即$w^{(m)}$很大或很小时，归一化是有帮助的。
            \par
            $\theta_g$可以采用批量样本来更新
            \begin{align*}
            \nabla_{\theta_g} \propto \frac{1}{N} \sum_n\sum _m \tilde{w}^{(m)} \nabla_{\theta_g} \log g(x^{(m)}|z^{(m)})
            \end{align*}

        \subsubsection{BGAN程序}
            \par
            Boundary Seeking GAN的TensorFolw程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 64
            h_dim = 128
            lr = 1e-3
            d_steps = 3
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            def log(x):
                return tf.log(x + 1e-8)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def generator(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                out = tf.nn.sigmoid(tf.matmul(D_h1, D_W2) + D_b2)
                return out
            G_sample = generator(z)
            D_real = discriminator(X)
            D_fake = discriminator(G_sample)
            D_loss = -tf.reduce_mean(log(D_real) + log(1 - D_fake))
            G_loss = 0.5 * tf.reduce_mean((log(D_fake) - log(1 - D_fake))**2)
            D_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(D_loss, var_list=theta_D))
            G_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(G_loss, var_list=theta_G))
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                X_mb, _ = mnist.train.next_batch(mb_size)
                z_mb = sample_z(mb_size, z_dim)
                _, D_loss_curr = sess.run(
                    [D_solver, D_loss],
                    feed_dict={X: X_mb, z: z_mb}
                )
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss],
                    feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}
                )
                if it % 1000 == 0:
                    print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}

    \subsection{Mode Regularized GAN}
        \subsubsection{MRGAN模型建立}
            \par
            GAN在许多任务上都表现良好，但GAN有两大缺点：1.训练极不稳定；2.生成的图片多样性较差。和无监督GAN相比，有监督CGAN的训练要相对稳定一些。而CGAN相对GAN而言，其目标中多了一个$I(c;G(z,c))$，也就是说，就是此项让GAN变得稳定了一些。而此项可以被视为一个正则项，我们自然考虑其他的正则方法，文献\cite{2016.Tong}就考虑了一些正则化GAN。
            \par
            假设生成器G是$G(z):Z\to X$的映射，相应的，我们考虑一个encoder $E(x):X\to Z$。并且假设$d$是某一种相似性度量，$p_r$是真实分布，$p_g$是生成分布。我们使用$\mathbb{E}_{x\sim p_r}[d(x,G\circ E(x)]$作为正则项，其中$G\circ E$是一个自动编码器。for $x\in M_0$，如果$G\circ E$是一个好的自动编码器，则$G\circ E$应该和$M_0$非常接近。在训练G时，添加正则项$\mathbb{E}_{x\sim p_r}[d(x,G\circ E(x)]$
            \begin{align*}
            & T_G = -\mathbb{E}_{z\sim p_z}[\log D(G(z))] +\mathbb{E}_{x\sim p_r}[\lambda_1 d(x,G\circ E(x))+\lambda_2\log D(G\circ E(x))]\\
            & T_E = \mathbb{E}_{x\sim p_r}[\lambda_1d(x,G\circ E(x))+ \lambda_2\log D(G\circ E(x))]
            \end{align*}
            \par
            The proposed algorithm divides the training procedure of GANs into two steps: a manifold step and a diffusion step. In the manifold step, we try to match the generation manifold and the real data manifold with the help of an encoder and the geometric metric loss. In the diffusion step, we try to distribute the probability mass on the generation manifold fairly according to the real data distribution.

        \subsubsection{MRGAN程序}
            \par
            MRGAN的伪代码如(\ref{code:MRGAN})所示
            \begin{algorithm}[htbp]
                \caption{Minibatch stochastic gradient descent training of MRGAN}\label{code:MRGAN}
                \begin{algorithmic}[1]
                    \State \textbf{Manifold Step:}。
                    \State 从真实分布$p_r$中抽取$m$个样本$\{x_1,x_2,\dots,x_m\}$。
                    \State 使用SGD来更新判别器$D_1$
                    \begin{align*}
                    \nabla_{\theta_d^1} \frac{1}{m} \sum_{i=1}^m [\log D_1(x_i)+\log (1-D_1(G(E(x_i))))]
                    \end{align*}
                    \State 使用SGD来更新生成器G
                    \begin{align*}
                    \nabla _{\theta_g} \frac{1}{m}\sum_{i=1}^m [\lambda\log D_1(G(E(x_i))) - ||x_i - G(E(x_i))||^2]
                    \end{align*}
                    \State \textbf{Diffusion Step:}
                    \State 从真实分布$p_r$中抽取$m$个样本$\{x_1,x_2,\dots,x_m\}$。
                    \State 从prior 分布$p_z$中抽取$m$个样本$\{z_1,z_2,\dots,z_m\}$。
                    \State 使用SGD更新判别器$D_2$
                    \begin{align*}
                    \nabla_{\theta_d^2}\frac{1}{m}\sum_{i=1}^m [\log D_2(G(E(x_i)))+\log (1-D_2(z_i))]
                    \end{align*}
                    \State 使用SGD来更新生成器G
                    \begin{align*}
                    \nabla_{\theta_g} \frac{1}{m}\sum_{i=1}^m[\log D_2(G(z_i))]
                    \end{align*}
                \end{algorithmic}
            \end{algorithm}
            \par
            MRGAN的pytorch程序如下
            \begin{lstlisting}[language = Python]
            import torch
            import torch.nn
            import torch.nn.functional as nn
            import torch.autograd as autograd
            import torch.optim as optim
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            from torch.autograd import Variable
            from tensorflow.examples.tutorials.mnist import input_data
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            mb_size = 32
            z_dim = 128
            X_dim = mnist.train.images.shape[1]
            y_dim = mnist.train.labels.shape[1]
            h_dim = 128
            cnt = 0
            lr = 1e-4
            lam1 = 1e-2
            lam2 = 1e-2
            def log(x):
                return torch.log(x + 1e-8)
            E = torch.nn.Sequential(
                torch.nn.Linear(X_dim, h_dim),
                torch.nn.ReLU(),
                torch.nn.Linear(h_dim, z_dim)
            )
            G = torch.nn.Sequential(
                torch.nn.Linear(z_dim, h_dim),
                torch.nn.ReLU(),
                torch.nn.Linear(h_dim, X_dim),
                torch.nn.Sigmoid()
            )
            D = torch.nn.Sequential(
                torch.nn.Linear(X_dim, h_dim),
                torch.nn.ReLU(),
                torch.nn.Linear(h_dim, 1),
                torch.nn.Sigmoid()
            )
            def reset_grad():
                G.zero_grad()
                D.zero_grad()
                E.zero_grad()
            def sample_X(size, include_y=False):
                X, y = mnist.train.next_batch(size)
                X = Variable(torch.from_numpy(X))
                if include_y:
                    y = np.argmax(y, axis=1).astype(np.int)
                    y = Variable(torch.from_numpy(y))
                    return X, y
                return X
            E_solver = optim.Adam(E.parameters(), lr=lr)
            G_solver = optim.Adam(G.parameters(), lr=lr)
            D_solver = optim.Adam(D.parameters(), lr=lr)
            for it in range(1000000):
                """ Discriminator """
                # Sample data
                X = sample_X(mb_size)
                z = Variable(torch.randn(mb_size, z_dim))
                # Dicriminator_1 forward-loss-backward-update
                G_sample = G(z)
                D_real = D(X)
                D_fake = D(G_sample)
                D_loss = -torch.mean(log(D_real) + log(1 - D_fake))
                D_loss.backward()
                D_solver.step()
                # Housekeeping - reset gradient
                reset_grad()
                """ Generator """
                # Sample data
                X = sample_X(mb_size)
                z = Variable(torch.randn(mb_size, z_dim))
                # Generator forward-loss-backward-update
                G_sample = G(z)
                G_sample_reg = G(E(X))
                D_fake = D(G_sample)
                D_reg = D(G_sample_reg)
                mse = torch.sum((X - G_sample_reg)**2, 1)
                reg = torch.mean(lam1 * mse + lam2 * log(D_reg))
                G_loss = -torch.mean(log(D_fake)) + reg
                G_loss.backward()
                G_solver.step()
                # Housekeeping - reset gradient
                reset_grad()
                """ Encoder """
                # Sample data
                X = sample_X(mb_size)
                z = Variable(torch.randn(mb_size, z_dim))
                G_sample_reg = G(E(X))
                D_reg = D(G_sample_reg)
                mse = torch.sum((X - G_sample_reg)**2, 1)
                E_loss = torch.mean(lam1 * mse + lam2 * log(D_reg))
                E_loss.backward()
                E_solver.step()
                # Housekeeping - reset gradient
                reset_grad()
                # Print and plot every now and then
                if it % 1000 == 0:
                    print('Iter-{}; D_loss: {}; E_loss: {}; G_loss: {}'
                          .format(it, D_loss.data.numpy(), E_loss.data.numpy(), G_loss.data.numpy()))
                    samples = G(z).data.numpy()[:16]
                    fig = plt.figure(figsize=(4, 4))
                    gs = gridspec.GridSpec(4, 4)
                    gs.update(wspace=0.05, hspace=0.05)
                    for i, sample in enumerate(samples):
                        ax = plt.subplot(gs[i])
                        plt.axis('off')
                        ax.set_xticklabels([])
                        ax.set_yticklabels([])
                        ax.set_aspect('equal')
                        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                    if not os.path.exists('out/'):
                        os.makedirs('out/')
                    plt.savefig('out/{}.png'
                                .format(str(cnt).zfill(3)), bbox_inches='tight')
                    cnt += 1
            plt.close(fig)
            \end{lstlisting}

    \subsection{DCGAN}
        \par
        由于GAN的模型不稳定性问题比较突出，因而在2016年出现的关于GAN训练技巧的成果有许多，目前被广泛应用的主要包括：DCGAN\footnote{http://www.leiphone.com/news/201703/Y5vnDSV9uIJIQzQm.html}\footnote{https://github.com/roatienza/Deep-Learning-Experiments/blob/master/Experiments/Tensorflow/GAN/dcgan\_mnist.py} (ICLR-2016) 和Improved GAN (NIPS-2016 workshop)，特别是DCGAN，几乎在各大GAN模型中都能看到它的身影。
        \par
        DCGAN\cite{2015.Radford} 的模型结构如图(\ref{fig:DCGAN网络结构图})所示所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/DCGAN_network.jpg}
                \caption{DCGAN网络结构图}
                \label{fig:DCGAN网络结构图}
                \end{figure}
        % \textcolor[rgb]{1 0 0}{todo:图片：DCGAN网络结构图}\\
        其输入为100维的噪声向量，经过一系列的strided conv操作，形成64$\times$64的图像，即为$G(z)$。而判别器结构与之类似，只是是由一系列的卷积操作构成 (而非strided conv)，最后由average pooling形成判别器的标量输出。在DCGAN\cite{2015.Radford}中，最主要的是提出了以下四条有助于稳定训练GAN的方法：
        \begin{enumerate}
        \item 去掉max pooling操作：用strided conv代替原来的pooling操作，使网络自动学习合适的采样核函数；
        \item 去掉全连接层：用global average pooling代替全连接层；虽然该操作可能会导致收敛速度变慢，但有助于整体训练的稳定性；
        \item 加入BN层：之前的LAPGAN\cite{2015.Denton}指出，如果像常规模型一样对所有层都施加BN，则会引起GAN的模型崩溃，而DCGAN通过对generator的输出层和discriminator的输入层不用BN，而其他层都用BN，则缓解了模型崩溃问题，并且有效避免了模型的振荡和不稳定问题。
        \item 激活函数的选择：在generator中除了输出层用tanh外，其余都用RELU函数；而在discriminator中采用leaky ReLU函数。
        \end{enumerate}

    \subsection{Improved GAN}
        \par
        文献\cite{2016.Tim}主要给出了5条有助于GAN稳定训练的经验：
        \begin{enumerate}
        \item 特征匹配：让生成器产生的样本与真实样本在判别器中间层的响应一致，即使判别器从真实数据和生成数据中提取的特征一致，而不是在判别器网络的最后一层才做判断，有助于提高模型的稳定性；其实验也表明在一些常规方法训练GAN不稳定的情况中，若用特征匹配则可以有效避免这种不稳定；
        \item Minibatch Discrimination：在判别器中，不再每次对每一个生成数据与真实数据的差异性进行比较，而是一次比较一批生成数据与真实数据的差异性。这种做法提高了模型的鲁棒性，可以缓解生成器输出全部相似或相同的问题；
        \item Historical Averaging：受fictitious  play的游戏算法启发，作者提出在生成器和判别器的目标函数中各加一个对参数的约束项
        \begin{align*}
        \bigg|\bigg|\theta - \frac{1}{t}\sum_{i=1}^t\theta_t\bigg|\bigg|^2
        \end{align*}
        其中：$\theta_i$表示在时刻$i$的模型参数，该操作可以在一些情况下帮助模型达到模型的平衡点；
        \item 单边标签平滑 (One-sided Label Smoothing)：当向GAN中引入标签数据时，最好是将常规的0、1取值的二值标签替换为如0.1、0.9之类的平滑标签，可以增加网络的抗干扰能力；但这里之所以说单边平滑，是因为假设生成数据为0.1而非0的话会使判别器的最优判别函数的形状发生变化，会使生成器偏向于产生相似的输出，因此对于取值0的标签保持不变，不用0.1一类的小数据替换，即为单边标签平滑；
        \item Virtual Batch Normalization：VBN相当于是BN的进阶版，BN是一次对一批数据进行归一化，这样的一个副作用是当“批”的大小不同时，BN操作之后的归一化常量会引起训练过程的波动，甚至超过输入信号$z$的影响(因$z$是随机噪声)；而VBN通过引入一个参考集合，每次将当下的数据$x$加入参考集合构建一个新的虚拟的batch，然后在这个虚拟的batch上进行归一化，如此可以缓解原始BN操作所引起的波动问题。
        \end{enumerate}

    \subsection{Least Squares GAN}
        \subsubsection{LSGAN模型建立}
            \par
            在GAN中，设$D(x)\in [0,1]$为样本$x$为真的概率，作为损失，我们将其取$\log$，设定为$\log D(x)$。我们的目标是用D将G所生成的样本/分布“拖”到真实数据流(data manifold)当中(1维线二维面三维体三维以上称为流形)，从而使G生成的样本类似于$p_r(x)$的样本。
            \par
            我们知道常规GAN中，判别器使用的是对数损失log loss($1-D$为损失，再取$\log$)。就简单的二分类问题而言，对数损失带来的决策边界如图(\ref{fig:LSGAN-sigmoid决策边界图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=6cm]{images/LSGAN-sigmoid.jpg}
                \caption{LSGAN-sigmoid决策边界图}
                \label{fig:LSGAN-sigmoid决策边界图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：LSGAN-sigmoid决策边界图-需要修改}\\
            因为D使用的是sigmoid函数，sigmoid函数饱和的十分迅速，所以即使是十分小的数据点$x$，该函数也会迅速忽略$x$到决策边界的距离。这意味着，sigmoid函数本质上不会惩罚远离决策边界的$x$，也就说明，我们满足于将样本正确分类，当$x$变得很大时，D的梯度就会快速下降为0。因此，sigmoid不关心样本点到决策边界的距离，只关心是否分类正确。而G的训练依赖于D的梯度，当D的梯度为0时，G就不再更新(GAN训练不稳定)。
            \par
            Least squares loss：就简单的二分类问题而言，最小平方损失的决策如图(\ref{fig:LSGAN-L2决策边界图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/LSGAN-L2decision.jpg}
                \caption{LSGAN-L2决策边界图}
                \label{fig:LSGAN-L2决策边界图}
                \end{figure}
            在L2损失中，距$w$远的数据将会获得与距离成正比的惩罚，因此梯度只有在$w$完全拟合$x$的情况下才为0。如果G没有捕获到数据流形，那么这将能确保D服从多信息梯度(information gradients)。在优化过程中，G使D的损失减小的唯一方式是尽可能的接近W($x = G(z)$接近$w$)。
            \par
            LSGAN设置L2损失$D(x)\in [0,1]$，将真样本概率值$D(x)$的期望设置为$b$，假样本概率值$D(x)$的期望设置为$a$，有
            \begin{align*}
            & \min_D \ V(D) = \frac{1}{2} \mathbb{E}_{x\sim p_r}[(D(x) - 1)^2] + \frac{1}{2}\mathbb{E}_{z\sim p_z}p[(D(G(z))-0)^2]\\
            & \min_G \ V(G) = \frac 12 \mathbb{E}_{z\sim p_z}[(D(G(z))-1)^2]
            \end{align*}
            我们将D和G的目标进行如下扩展
            \begin{align*}
            & \min_D \ V(D) = \frac{1}{2} \mathbb{E}_{x\sim p_r}[(D(x) - b)^2] + \frac{1}{2}\mathbb{E}_{z\sim p_z}p[(D(G(z))-a)^2]\\
            & \min_G \ V(G) = \frac{1}{2} \mathbb{E}_{x\sim p_r}[(D(x) - c)^2] + \frac 12 \mathbb{E}_{z\sim p_z}[(D(G(z))-c)^2]
            \end{align*}
            并且，注意到在G的目标中添加了$\mathbb{E}_{x\sim p_r}[(D(x) - c)^2]$，这并不改变最优值。在G给定的情况下，最优判别器为
            \begin{align*}
            D^*(x) = \frac{bp_r(x)+ap_g(x)}{p_r(x)+p_g(x)}
            \end{align*}
            将$D^*$带入到G的目标$V(G)$中，有
            \begin{align*}
            2C(G) &= \mathbb{E}_{x\sim p_r}[(D^*(x)-c)^2]+\mathbb{E}_{x\sim p_g}[(D^*(x)-c)^2]\\
            &=\mathbb{E}_{x\sim p_r} \left [\left( \frac{bp_r(x)+ap_g(x)}{p_r(x)+p_g(x)} - c \right)^2  \right] + \mathbb{E}_{x\sim p_g}\left [\left( \frac{bp_r(x)+ap_g(x)}{p_r(x)+p_g(x)} - c \right)^2  \right] \\
            & =\int_x p_r(x) \left( \frac{(b-c)p_r(x)+(a-c)p_g(x)}{p_r(x)+p_g(x)} \right)^2\mathrm{d}x \int_x p_g(x) \left( \frac{(b-c)p_r(x)+(a-c)p_g(x)}{p_r(x)+p_g(x)} \right)^2\mathrm{d}x \\
            &=\int_x \frac{[(b-c)p_r(x)+(a-c)p_g(x)]^2}{p_r(x)+p_g(x)} \mathrm{d}x\\
            &=\int_x \frac{[(b-c)(p_r(x)+p_g(x))-(b-a)p_g(x)]^2}{p_r(x)+p_g(x)}\mathrm{d}x
            \end{align*}
            \par
            如果我们设置$b-c =1,b-a=2$，则有
            \begin{align*}
            2C(G) & = \int_x \frac{\left( 2p_g(x)-(p_r(x)+p_g(x)) \right)^2  }{p_r(x)+p_g(x)}\mathrm{d}x\\
            & = \chi^2_{pearson}(p_r+p_g||2p_g)
            \end{align*}
            其中：$ \chi^2_{pearson}$是Pearson $\chi^2$散度，可以参考$f$-GAN。这说明此时的LSGAN是$f$-GAN的特例。我们可以设置$b=1,a=-1,c=0$，当然我们还可以设置其他值。

        \subsubsection{LSGAN程序}
            \par
            最小二乘GAN(LSGAN)的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 64
            h_dim = 128
            lr = 1e-3
            d_steps = 3
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def generator(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                out = tf.matmul(D_h1, D_W2) + D_b2
                return out
            G_sample = generator(z)
            D_real = discriminator(X)
            D_fake = discriminator(G_sample)
            D_loss = 0.5 * (tf.reduce_mean((D_real - 1)**2) + tf.reduce_mean(D_fake**2))
            G_loss = 0.5 * tf.reduce_mean((D_fake - 1)**2)
            D_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(D_loss, var_list=theta_D))
            G_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(G_loss, var_list=theta_G))
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                for _ in range(d_steps):
                    X_mb, _ = mnist.train.next_batch(mb_size)
                    z_mb = sample_z(mb_size, z_dim)
                    _, D_loss_curr = sess.run(
                        [D_solver, D_loss],
                        feed_dict={X: X_mb, z: z_mb}
                    )
                X_mb, _ = mnist.train.next_batch(mb_size)
                z_mb = sample_z(mb_size, z_dim)
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss],
                    feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}
                )
                if it % 1000 == 0:
                    print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}

    \subsection{Wasserstein GAN}
        \subsubsection{GAN问题分析}
            \par
            下面的内容参考了知乎上的关于WGAN的讨论\footnote{郑华滨在知乎回答https://zhuanlan.zhihu.com/p/25071913}以及炼数成金的相关内容\footnote{http://i.dataguru.cn/mportal.php?mod=view\&aid=10570}。
            \par
            自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。而Wasserstein GAN(下面简称WGAN)成功地做到了以下几点：
            \begin{enumerate}
            \item 彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度；
            \item 基本解决了collapse mode的问题，确保了生成样本的多样性；
            \item 训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高。
            \end{enumerate}
            \par
            作者在文献\cite{2017.Arjovsky}里从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在文献\cite{2017.Chen}中，又再从这个改进点出发给出了Wasserstein GAN，并给出了算法的流程。
            \par
            先回顾一下原始GAN的目标。在原始GAN中，\ding{172}判别器D要使来自真实分布的样本$x\sim P_r$被判别是来自真实分布$P_r$的概率尽可能大，让来自虚假分布的样本$x\sim P_g$被判别是来自真实分布的概率尽可能小，即最大化如下目标
            \begin{align*}
            \max_D \ \mathbb{E}_{x\sim P_r}[\log D(x)]  + \mathbb{E}_{x\sim P_g}[\log (1-D(x))]
            \end{align*}
            \ding{173}对于生成器G，我们的目标是让来自虚假分布的样本$x\sim P_g$被判别是来自真实分布的概率尽可能大，即
            \begin{align*}
            \max_G \ \mathbb{E}_{x\sim P_g}[D(x)]
            \end{align*}
            \par
            Goodfellow刚开始提出的目标是
            \begin{align}
            \label{GAN生成器原始目标1}
            \min \ \mathbb{E}_{x\sim P_g}[\log (1-D(x))]
            \end{align}
            之后将其改为
            \begin{align}
            \label{GAN生成器原始目标2}
            \min \ \mathbb{E}_{x\sim P_g}[1-\log D(x)]
            \end{align}
            称上面两个目标为 "the - log D alternative" 或 "the - log D trick"。文献\cite{2017.Arjovsky}分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。
        \subsubsection{第一种原始GAN形式的问题}
            \par
            第一种原始GAN形式(\ref{GAN生成器原始目标1})的问题是：判别器越好，生成器梯度消失越严重(因此我们要协调D和G的优化)。文献\cite{2017.Arjovsky}从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。
            \par
            首先，对GAN而言，在生成器 G 给定时，对于一个具体的样本，它可能来自真实分布也可能来自生成分布，它对D的损失函数的贡献是
            \begin{align*}
            -p_r(x)\log D(x) - p_g(x)\log [1-D(x)]
            \end{align*}
            令其关于$D(x)$的导数为0，得
            \begin{align*}
            -\frac{p_r(x)}{D(x)}+ \frac{p_g(x)}{1-D(x)}= 0
            \end{align*}
            化简得最优判别器为
            \begin{align}
            \label{最优判别器}
            D^*(x) = \frac{p_r(x)}{p_r(x)+p_g(x)}
            \end{align}
            \par
            这个结果从直观上很容易理解，就是看一个样本$ x $来自真实分布和生成分布的可能性的相对比例。如果$ p_r(x) = 0 $且$ p_g(x) \neq 0$，最优判别器就应该非常自信地给出概率0；如果$ p_r(x) = p_g(x)$，说明该样本是真是假的可能性刚好各一半，此时最优判别器也应该给出概率0.5。此后，
            Goodfellow证明了，当$D$固定时，$G$的loss有上界
            \begin{align*}
            2\log 2 - 2JSD(P_r||P_g)
            \end{align*}
            当固定$D$时，训练$G$直到收敛，可以发现$G$的loss会越来越小(趋于0)，这表明$JSD(P_r || P_g)$被最大化了，并且趋于$\log2$。如下图(\ref{fig:DCGAN梯度趋于0示意图})所示。
                \begin{figure}[H]
                \centering
                \includegraphics[width=14cm]{images/DCGAN_grandient0.jpg}
                \caption{DCGAN训练图}
                \label{fig:DCGAN梯度趋于0示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：DCGAN梯度趋于0示意图}\\
            而这会导致什么问题呢？在实践中人们发现，当D训练得更精确，G的更新会变得越差，训练变得异常地不稳定。为什么会产生这些这样的问题？为了探究背后的原因，我们就看看极端情况：判别器最优时，生成器的损失函数变成什么。给式(\ref{GAN生成器原始目标1})加上一个不依赖于生成器的项，使之变成
            \begin{align*}
            \mathbb{E}_{x\sim P_r}[\log D(x)] + \mathbb{E}_{x\sim P_g}[\log (1-D(x))]
            \end{align*}
            注意，最小化这个损失函数等价于最小化式(\ref{GAN生成器原始目标1})，而且它刚好是判别器损失函数的反。将最优判别器(\ref{最优判别器})代入上式，再进行简单的变换可以得到
            \begin{align}
            \label{公式5}
            \mathbb{E}_{x\sim P_r}\log \frac{p_r(x)}{\frac{1}{2}[p_r(x) + p_g(x)]} + E_{x\sim P_g}\log \frac{p_g(x)}{\frac{1}{2}[p_r(x)+p_g(x)]} - 2\log 2
            \end{align}
            变换成这个样子是为了引入 Kullback–Leibler divergence(简称KL散度)和 Jensen-Shannon divergence(简称JS散度)这两个重要的相似度衡量指标。
            KL散度(KL距离，前面多次介绍过)
            \begin{align*}
            KL(P_r||P_g) = \mathbb{E}_{x\sim P_r}\log \frac{p_r}{p_g}
            \end{align*}
            JS散度为
            \begin{align}
            \label{JS散度}
            JSD(P_r||P_g) = \frac{1}{2}KL \left( P_r \Big|\Big| \frac{P_r+P_g}{2} \right) + \frac{1}{2} KL\left( P_g \Big|\Big| \frac{P_r+P_g}{2} \right)
            \end{align}
            于是式(\ref{公式5})就可以继续写为
            \begin{align*}
            2JSD(P_r||P_g) - 2\log 2
            \end{align*}
            \par
            根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布$P_r$与生成分布$P_g$之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化$P_r$和$P_g$之间的JS散度。
            \par
            梯度消失的问题就出在这个JS散度上。我们希望$P_g$与$P_r$的JS散度尽可能小，这个希望在两个分布有所重叠的时候还可以求解，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略(下面解释什么叫可忽略)，它们的JS散度是多少呢？答案是log2，因为对于任意一个$x$只有四种可能：
            \begin{align*}
            p_r(x) = 0 \ \text{且} \ p_g(x) = 0\\
            p_r(x) \neq 0 \ \text{且} \ p_g(x) \neq 0\\
            p_r(x) = 0 \ \text{且} \ p_g(x) \neq 0\\
            p_r(x) \neq 0 \ \text{且} \ p_g(x) = 0
            \end{align*}
            \par
            上面的第一种对计算JS散度无贡献；第二种情况由于重叠部分可忽略，所以贡献也为0；第三种情况对式(\ref{JS散度})右边第一个项的贡献是
            \begin{align*}
            \log \frac{p_g}{\frac{1}{2}(p_g+0)} = \log 2
            \end{align*}
            第4种情况与之类似，所以最终有
            \begin{align*}
            JSD(P_r||P_g) = \log 2
            \end{align*}
            换句话说，无论$ P_r $跟$ P_g $是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$\log 2$，而这对于梯度下降方法意味着—梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的，即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。
            \par
            但是$ P_r $与$ P_g $不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当$ P_r $与$ P_g $的支撑集(support)是高维空间中的低维流形(manifold)时，$P_r $与$ P_g $重叠部分测度(measure)为0的概率为1。
            \par
            虽然论文给出的是严格的数学表述，但是直观上其实很容易理解。首先简单介绍一下这几个概念：
            \begin{enumerate}
            \item 支撑集(support)其实就是函数的非零部分子集，比如ReLU函数的支撑集就是$(0,+\infty)$，一个概率分布的支撑集就是所有概率密度非零部分的集合。
            \item 流形(manifold)是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度(intrinsic dimension)只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。
            \item 测度(measure)是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。
            \end{enumerate}
            \par
            回过头来看第一句话，“当$ P_r $与$ P_g $的支撑集是高维空间中的低维流形时”，这基本上是成立的。因为GAN中的生成器一般是从某个低维(比如100维)的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本(比如$64\times 64$的图片就有4096维)。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。
            \par
            “撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度(测度)为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积(测度)是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$ P_g $几乎不可能与$P_r$有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比$ P_r $和$ P_g $的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。
            \par
            至此，就得到了文献\cite{2017.Arjovsky}中关于生成器梯度消失的第一个论证：在(近似)最优判别器下，最小化生成器的loss等价于最小化$ P_r $与$ P_g $之间的JS散度，而由于$ P_r $与$ P_g $几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$\log 2$，最终导致生成器的梯度(近似)为0，梯度消失。
            \par
            接着作者从第二个角度进行论证，但是背后的思想也可以直观地解释：首先，$P_r $与$ P_g $之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。
            由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。
            最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数(1和0)，导致生成器的loss梯度为0，梯度消失。
            \par
            有了上述的理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。实验辅证如下图(\ref{fig:生成器梯度轨迹})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/Generator_gradient_trajectory.jpg}
                \caption{生成器梯度轨迹}
                \label{fig:生成器梯度轨迹}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：生成器梯度轨迹}\\
            先分别将DCGAN训练1、20、25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第一种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，生成器的梯度均迅速衰减。注意$y$轴是对数坐标轴。
            \par
            上面只是在直观上分析了GAN存在的问题，下面给出文献\cite{2017.Arjovsky}的理论分析：
            \begin{lemma}[Lemma1 ]
            设$g:\mathcal{Z}\to \mathcal{X}$是一个由仿射变换和逐点定义的非线性函数(ReLU、leaky ReLU或者诸如sigmoid、tanh、softplus之类的光滑严格递增函数)复合得到的复合函数，则$g(\mathcal{Z})$包含在可数多个流形的并集中，并且它的维数至多为$\dim(\mathcal{Z})$。因此，若$\dim(\mathcal{Z}) < \dim(\mathcal{X})$，则$g(\mathcal{Z})$在X中测度为0。
            \end{lemma}
            \par
            Lemma1表明，若generator(G)是一个神经网络，并且G的输入(随机高斯噪声)的维数比产生的图像的维数低，则无论怎样训练，G也只能产生整个图像空间中很小的部分，有多小呢？它在图像空间中只是一个零测集。
            \par
            训练GAN时，训练集总归是有限的，$P_r$一般可以看成是低维的流形；如果$P_g$也是低维流形，或者它与$P_r$的支撑集没有交集，则在 (D)达到最优时，JSD就会被最大化。D达到最优将导致G的梯度变得异常地差，训练将变得异常不稳定。
            下面的几个定理、引理就是证明$P_g$在上述两种情况下，最优的D是存在的。
            \begin{theorem}[Theorem2.1]
            若分布$P_r$和$P_g$的支撑集分别包含在两个无交紧致子集$\mathcal{M}$和$\mathcal{P}$中，则存在一个光滑的最优 $D*: \mathcal{X} \to [0,1]$，它的精度是1，并且，对任意的
            $x\in \mathcal{M} \cup \mathcal{P}$有
            \begin{align*}
            \nabla _x D^*(x) = 0
            \end{align*}
            \end{theorem}
            \par
            定理2.1表示：如果两个概率分布的支撑集没有交集，则完美的D总是存在的，并且(在两个分布的支撑集的并集上)D的梯度为0，也就是说，这时候任何梯度算法都将失效。这就是GAN训练的时候，(在两个概率分布的支撑集没有交集的情况下)当D训练效果很好的时候，G的更新将变得很差的原因。
            \begin{lemma}[Lemma 2]
            设$\mathcal{M}$和$\mathcal{P}$是$R^d$的两个非满维度的正则子流形，再设$\eta$和$\eta'$ 是任意的两个独立连续随机变量，定义两个扰动流形$\tilde{\mathcal{M}} = \mathcal{M} + \eta$，$\tilde{\mathcal{P}}= \mathcal{P} + \eta'$，则
            \begin{align*}
            P_{\eta,\eta'}(\tilde{\mathcal{M}}\text{不与}\tilde{\mathcal{P}}\text{完美对齐}) = 1
            \end{align*}
            \end{lemma}
            \par
            Lemma 2是为定理2.2做准备，它表明任意两个非满维的正则子流形都可以通过微小的扰动使得它们不是完美对齐(notperfectly align)的，即它们的交点都是横截相交(intersect transversally)的。在这里形象地说明一下横截相交和完美对齐：
            横截相交(intersect transversally)：对两个子流形，在任意一个交点处，两者的切平面能够生成整个空间，则称两个子流形横截相交。当然，如果它们没有交集，则根据定义，它们天然就是横截相交的。下图(\ref{fig:横截相交示意图})给出了一个示例
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/Cross_intersecting.jpg}
                \caption{横截相交示意图}
                \label{fig:横截相交示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：横截相交示意图}\\
            在交点P处，平面的切平面是其自身，直线的切平面也是其自身，它们可以张成全空间，因此是横截相交的，而两个直线没办法张成全空间，因此不是横截相交的；如果两个流形是相切的，在切点处它们的切平面是相同的，也不可能张成全空间，因此也不是横截相交的。
            完美对齐(perfectly align): 如果两个子流形有交集，并且在某个交点处，它们不是横截相交的。
            \par
            $P_r$和$P_g$的支撑集如果存在交集，那么根据Lemma2，我们总可以通过微小的扰动使得它们不是完美对齐的，也就是说，它们是横截相交的。
            \begin{lemma}[Lemma 3]
            设$\mathcal{M}$和$\mathcal{P}$是$R^d$的两个非完美对齐，非满维的正则子流形，$\mathcal{L} = \mathcal{M}\cap \mathcal{P} $，若$\mathcal{M}$和$\mathcal{P}$无界，则$\mathcal{L}$也是一个流形，且维数严格低于$\mathcal{M}$和$\mathcal{P}$的维数。若它们有界，则$\mathcal{L}$是至多四个维数严格低于全空间的流形之并。无论哪种情形，$\mathcal{L}$在$\mathcal{M}$或者$\mathcal{P}$中的测度均为0。
            \end{lemma}
            \par
            Lemma 3说的是，两个正则子流形(满足一定条件：非完美对齐，非满维)的交集的维数要严格低于它们自身的维数。也就是说，它们的交集只是冰山一角，小到相对它们自身可以忽略。对于$P_r$和$P_g$的支撑集来说，根据Lemma 2，我们总可以通过微小扰动使得它们是非完美对齐的，在根据Lemma 3，$P_r$和$P_g$的交集是微不足道。
            \begin{theorem}[Theorem2.2]
            设$P_r$和$P_g$分别是支撑集包含在闭流形$\mathcal{M}$和$\mathcal{P}$中的两个分布，且它们非完美对齐、非满维。进一步地，我们假设$P_r$和$P_g$在各自的流形中分别连续，即：若集合A在$\mathcal{M}$中测度为0，则$P_r(A) = 0$(在$P_g$上也有类似结果)，则存在精度为1的最优$ D^*:\mathcal{X}\to [0,1]$，并且几乎对$\mathcal{M}$或者$\mathcal{P}$中的任意点$x$，$D^*$在$x$的任意邻域内总是光滑的，且有
            \begin{align*}
            \nabla_x D^*(x) = 0
            \end{align*}
            \end{theorem}
            \par
            定理2.1证明的是对于$P_r$和$P_g$无交的情形下，最优的D是存在的。定理2.2承接Lemma 3，证明了在$P_r$和$P_g$的支撑集有交集，且横截相交的情况下，最优的D是存在的。这两个定理实际上把两种可能导致D最优，且梯度消失的情形在理论上做出证明，由于梯度的消失，G的更新将得不到足够的梯度，导致G很差。
            \begin{theorem}[Theorem2.3]
            在定理2.2的条件下，有
            \begin{align*}
            & JSD(P_r||P_g) = \log 2\\
            & KL(P_r||P_g) = +\infty\\
            & KL(P_g||P_r) = +\infty
            \end{align*}
            \end{theorem}
            \par
            定理2.3表明，随着D越来越好，D的loss将越来越小，趋于0，因此$P_r$和$P_g$的JSD被最大化，达到最大值$\log2$，这时，$P_r$和$P_g$的交叉熵达到无穷大，也就是说，即使两个分布之间的差异任意地小，它们之间的KL散度仍然会被最大化，趋于无穷。这是什么意思呢？利用KL散度来衡量分布间的相似性在这里并不是一个好的选择。因此，我们有必要寻求一个更好的衡量指标。
            \begin{theorem}[Theorem2.4 (Vanishing gradients on the generator)]
            设$g_\theta:\mathcal{Z}\to \mathcal{X}$是一个可微函数，有它导出分布$P_g$。再设$P_r$为真实数据分布，$D$是一个可微的discriminator。如果 Theorem 2.1 和 Theorem 2.2 的条件能够满足，且$\forall \varepsilon>0 $，$||D-D^*||<\varepsilon$，以及$\exists M>0$，$\mathbb{E}_{z\sim p(z)}\left[||J_\theta g_\theta(z)||_2^2\right] \leqslant M^2$，则
            \begin{align*}
            ||\nabla_\theta \mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_\theta(z)))\right]||_2 <M\frac{\epsilon}{1-\epsilon}
            \end{align*}
            \end{theorem}
            \begin{Proof}
            在证明Theorem2.1和Theorem2.2时，我们说$D^*$在$P_g$的支撑集上是locally 0。基于此，我们对 the support使用Jensen不等式和chain rule，有
            \begin{align*}
            ||\nabla_\theta \mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_\theta(z)))\right]||_2^2 &\leqslant \mathbb{E}_{z\sim p(z)}\left[ \frac{||\nabla_\theta D(g_\theta(z))||_2^2}{|1-D(g_\theta(z))|^2} \right]\\
            & \leqslant \mathbb{E}_{z\sim p(z)}\left[ \frac{||\nabla_\theta D(g_\theta(z))||_2^2||J_\theta g_\theta(z)||_2^2}{|1-D(g_\theta(z))|^2} \right]\\
            &<\mathbb{E}_{z\sim p(z)}\left[ \frac{(||\nabla_\theta D(g_\theta(z))||_2+\epsilon)^2||J_\theta g_\theta(z)||_2^2}{(|1-D(g_\theta(z))|-\epsilon)^2} \right]\\
            &=\mathbb{E}_{z\sim p(z)} \left[\frac{\epsilon^2||J_{\theta}g_\theta(z)||_2^2}{(1-\epsilon)^2}  \right]\\
            & \leqslant M^2\frac{\epsilon^2}{(1-\epsilon)^2}
            \end{align*}
            由此得到
            \begin{align*}
            ||\nabla_\theta \mathbb{E}_{z\sim p(z)}\left[\log(1-D(g_\theta(z)))\right]||_2 <M\frac{\epsilon}{1-\epsilon}
            \end{align*}
            $\square$
            \end{Proof}
            \par
            定理2.4 探究了generator在前面所述情况下回出现什么问题，它说明了若G采用original cost function(零和博弈)，那么它的梯度的上界被D与最优的$D^*$之间的距离bound住。通俗的说，我们训练GAN的时候，D越接近最优的$D^*$，则G的梯度就越小，如果梯度太小了，梯度算法不能引导G变得更好。
            \begin{corollary}[corollary 2.1]
            在定理2.4的假设下，有
            \begin{align*}
            \lim_{||D-D^*||\to 0}\nabla_\theta \mathbb{E}_{z\sim p(z)}[\log (1-D(g_\theta(z)))]=0
            \end{align*}
            \end{corollary}
            推论2.1是定理2.4的极限情况。
        \subsubsection{第二种原始GAN形式的问题}
            \par
            第二种原始GAN形式(\ref{GAN生成器原始目标2})的问题是：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，这导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。文献\cite{2017.Arjovsky}又是从两个角度进行了论证：
            \par
            如前文所说，Ian Goodfellow提出的“- log D trick”是把生成器loss改成
            \begin{align}
            \label{公式3}
            \mathbb{E}_{x\sim P_g}[-\log D(x)]
            \end{align}
            上文推导已经得到在最优判别器$D^*$下
            \begin{align}
            \label{公式9}
            \mathbb{E}_{x\sim P_r}[\log D^*(x)] + \mathbb{E}_{x\sim P_g}[\log(1-D^*(x))] = 2JSD(P_r || P_g) - 2\log 2
            \end{align}
            可以把KL散度(注意下面是先$g$后$r$)变换成含$D^*$的形式：
            \begin{align}
            \label{公式10}
            KL(P_g || P_r) &= \mathbb{E}_{x \sim P_g} [\log \frac{p_g(x)}{p_r(x)}] \notag\\
            &= \mathbb{E}_{x \sim P_g} \left[\log \frac{p_g(x) / (p_r(x) + p_g(x))}{p_r(x) / (p_r(x) + p_g(x))}\right] \notag\\
            &= \mathbb{E}_{x \sim P_g} \left[\log \frac{1 - D^*(x)}{D^*(x)}\right] \notag\\
            &= \mathbb{E}_{x \sim P_g} \log [1 - D^*(x)] - \mathbb{E}_{x \sim P_g} \log D^*(x)
            \end{align}
            由式(\ref{公式9})(\ref{公式10})可得最小化目标的等价变形
            \begin{align}
            \mathbb{E}_{x \sim P_g} [-\log D^*(x)] &= KL(P_g || P_r) - \mathbb{E}_{x \sim P_g} \log [1 - D^*(x)] \notag \\ &= KL(P_g || P_r) - 2JSD(P_r || P_g) + 2\log 2 + \mathbb{E}_{x\sim P_r}[\log D^*(x)]
            \end{align}
            注意上式最后两项不依赖于生成器G，最终得到最小化(\ref{公式3})等价于最小化
            \begin{align}
            \label{公式11}
            KL(P_g || P_r) - 2JSD(P_r || P_g)
            \end{align}
            \par
            这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的问题。
            \par
            第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，$KL(P_g || P_r)$与$KL(P_r || P_g)$是有差别的。以前者为例
            \begin{enumerate}
                \item 当$P_g(x)\rightarrow 0$而$P_r(x)\rightarrow 1$时，$P_g(x) \log \frac{P_g(x)}{P_r(x)} \rightarrow 0$，对$KL(P_g || P_r)$贡献趋近0；
                \item 当$P_g(x)\rightarrow 1$而$P_r(x)\rightarrow 0$时，$P_g(x) \log \frac{P_g(x)}{P_r(x)} \rightarrow +\infty$，对$KL(P_g || P_r)$贡献趋近正无穷。
            \end{enumerate}
            \par
            换言之，$KL(P_g || P_r)$对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。下面，我们给出文献\cite{2017.Arjovsky}中的理论分析：
            \begin{theorem}[Theorem 2.5]
            设连续分布$P_r$和$P_{g_\theta}$的密度函数为$p_r$和$p_{g_\theta}$。在参数为$\theta=\theta_0$时的最优生成器为
            \begin{align*}
            D^*=\frac{p_r}{p_{g_{\theta_0}}+p_r}
            \end{align*}
            则
            \begin{align*}
            \mathbb{E}_{z\sim p(z)}[-\nabla _\theta\log D^*(g_\theta(z))|_{\theta=\theta_0}] = \nabla_\theta[KL(P_{g_\theta}||P_r) - 2JSD(P_{g_\theta}||P_r)]|_{\theta=\theta_0}
            \end{align*}
            \end{theorem}
            \begin{Proof}
            从GAN的原始论文我们已经知道
            \begin{align*}
            \mathbb{E}_{z\sim p(z)}[\nabla_\theta \log(1-D^*(g_\theta(z)))|_{\theta=\theta_0}] = \nabla_\theta 2JSD(P_{g_\theta}||P_r)|_{\theta=\theta_0}
            \end{align*}
            此外，Huszar于2016指出
            \begin{align*}
            KL(P_{g_\theta}||P_r) & = \mathbb{E}_{x\sim P_{g_\theta}}\left[ \log\frac{p_{g_\theta(x)}}{p_r(x)} \right]\\
            & =\mathbb{E}_{x\sim P_{g_\theta}}\left[ \log\frac{p_{g_{\theta_0}(x)}}{p_r(x)} \right] - \mathbb{E}_{x\sim P_{g_\theta}}\left[ \frac{p_{g_\theta}(x)}{p_{g_{\theta_0}}(x)} \right]\\
            &=-\mathbb{E}_{x\sim P_{g_\theta}}\left[ \log \frac{D^*(x)}{1-D^*(x)} \right]-KL(P_{g_\theta}||P_{g_{\theta_0}})\\
            &=-\mathbb{E}_{z\sim p(z)}\left[ \log \frac{D^*(g_\theta(z))}{1-D^*(g_\theta(z))} \right]-KL(P_{g_\theta}||P_{g_{\theta_0}})
            \end{align*}
            在$\theta = \theta_0$处求导，我们有
            \begin{align*}
            \nabla_\theta KL(P_{g_\theta}||P_{g_{\theta_0}}) &= -\nabla_\theta\mathbb{E}_{z\sim p(z)} \left[\log \frac{D^*(g_\theta(z))}{1-D^*(g_\theta(z))}\right]\Big|_{\theta=\theta_0} - \nabla_\theta KL(P_{g_\theta}||P_{g_{\theta_0}})|_{\theta=\theta_0}\\
            &=\mathbb{E}_{z\sim p(z)} \left[-\nabla_\theta\log \frac{D^*(g_\theta(z))}{1-D^*(g_\theta(z))}\right]\Big|_{\theta=\theta_0}
            \end{align*}
            用JSD减去上述等式，即可得到Theorem 2.5。$\square$
            \end{Proof}
            \par
            定理2.5研究了G的loss为the$ -\log D$ cost时将会出现的问题。我们可以看到，JSD越大G的梯度反而会越小，也就是说，它可能会引导两个分布往相异的方向，此外，上式的KL项虽对产生无意义图像会有很大的惩罚，但是对mode collapse惩罚很小，也就是说，GAN训练时很容易落入局部最优，产生mode collapse。KL散度不是对称的，但JSD是对称的，因此JSD并不能改变这种状况。这就是我们在训练GAN时经常出现mode collapse的原因。
            \begin{theorem}[Theorem 2.6 Instability of generator gradient updates]
            设$g_\theta:\mathcal{Z}\to \mathcal{X}$是一个可微函数，由它可导出分布$P_g$。再设$P_r$为真实数据的分布，且满足定理2.1或者定理2.2的条件之一。令$D$是一个discriminator，满足$D^* - D = \epsilon$为高斯白噪声，且$\nabla_x D^* - \nabla_x D = r$也为高斯白噪声，则有
            \begin{align*}
            \mathbb{E}_{z\sim p(z)} [-\nabla_\theta \log D(g_\theta(z))]
            \end{align*}
            的每一维均服从期望和方差为正无穷的中心化柯西分布。
            \end{theorem}
            \par
            定理2.6告诉我们，若G采用the –$\log D$ cost，在定理2.1或者定理2.2的条件下，当$D$与$D^*$足够接近时，G的梯度会呈现强烈震荡，这也就是说，G的更新会变得很差，可能导致GAN训练不稳定。
            \par
            实验辅证如下图(\ref{fig:WGAN前作Figure 3})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/WGAN_make_Figure3.jpg}
                \caption{DCGAN训练1、20、25个epoch的训练结果}
                \label{fig:WGAN前作Figure 3}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：WGAN前作Figure 3}\\
            先分别将DCGAN训练1、20、25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第二种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，蓝色和绿色曲线中生成器的梯度迅速增长，说明梯度不稳定，红线对应的是DCGAN相对收敛的状态，梯度才比较稳定。
            \par
            图(\ref{fig:WGAN前作Figure 3})给出了定理2.6的实验模拟的效果，在DCGAN尚未收敛时，固定G，训练D将导致G的梯度产生强烈震荡。当DCGAN收敛时，这种震荡得到有效的抑制。
        \subsubsection{WGAN之前的一个过渡解决方案}
            \par
            原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量(KL散度、JS散度)不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。
            \par
            文献\cite{2017.Arjovsky}针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声。直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是(在第一种原始GAN形式下)梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火(annealing)，慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上就是对原文的直观解释。
            \par
            既然general GAN采用的loss不是一种好的选择，有什么loss能够有效避免这种情形吗？
            一个可行的方案是\uline{打破定理的条件，给D的输入添加噪声}。后续的几个定理对添加噪声的方法作了回答。
            \par
            在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，可得判别器的最小loss为
            \begin{align}
            \min L_D(P_{r+\epsilon}, P_{g+\epsilon}) &= - \mathbb{E}_{x\sim P_{r+\epsilon}}[\log D^*(x)] - \mathbb{E}_{x\sim P_{g+\epsilon}}[\log(1-D^*(x))] \\ &= 2\log 2 - 2JSD(P_{r+\epsilon} || P_{g+\epsilon})
            \end{align}
            其中$P_{r+\epsilon}$和$P_{g+\epsilon}$分别是加噪后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！不过，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。
            \begin{theorem}[Theorem 3.1]
            若$X$满足分布$P_X$，且它的支撑集落在$\mathcal{M}$中，$\epsilon$是一个密度函数为$p_\epsilon$的绝对连续分布，则$P_{X+\epsilon}$也是一个绝对连续分布，具有密度函数
            \begin{align*}
            p_{X+\epsilon} = \mathbb{E}_{y\sim P_X}[p_\epsilon(x-y)]\\
            =\int_\mathcal{M}p_{\epsilon}(x-y)\mathrm{d}P_X(y)
            \end{align*}
            \end{theorem}
            \begin{corollary}[corollary 3.1]
            \begin{enumerate}
            \item 如果$\epsilon \sim N(0,\sigma^2I)$，则
            \begin{align*}
            p_{X+\epsilon}(x) = \frac{1}{Z}\int_\mathcal{M}e^{-\frac{||y-x||^2}{2\sigma^2}}\mathrm{d}P_X(y)
            \end{align*}
            \item 如果$\epsilon\sim N(0,\Sigma)$，则
            \begin{align*}
            p_{X+\epsilon}(x) = \frac{1}{Z}\mathbb{E}_{y\sim P_X}\left[e^{-\frac{1}{2}||y-x||_{\Sigma^{-1}}^2}\right]
            \end{align*}
            \item 如果$p_\epsilon(x)\propto \frac{1}{||x||^{d+1}}$，则
            \begin{align*}
            p_{X+\epsilon}(x) = \frac{1}{Z}\mathbb{E}_{y\sim P_X}\left[\frac{1}{||x-y||^{d+1}}\right]
            \end{align*}
            \end{enumerate}
            \end{corollary}
            \par
            定理3.1和推论3.1表明，$\epsilon$的分布会影响我们对距离的选择。对于$P_{g+\epsilon}$和$P_{r+\epsilon}$，此时的最优判别器为
            \begin{align*}
            D^*(x) = \frac{p_{r_\epsilon(x)}}{p_{r+\epsilon}(x)+p_{g+\epsilon}(x)}
            \end{align*}

            \begin{theorem}[Theorem 3.2]
            设$P_r$和$P_g$分别是支撑集落在$\mathcal{M}$和$\mathcal{P}$中的两个分布，且$\epsilon \sim N(0,\sigma^2I)$，则梯度具有以下形式
            \begin{align*}
            \mathbb{E}_{z\sim p(z)}[\nabla_\theta \log (1-D^*(g_\theta(z)))] &= \mathbb{E}_{z\sim p(z)}\bigg[ a(z)\int_\mathcal{M}p_\epsilon(g_\theta(z)-y)\nabla_\theta||g_\theta(z)-y||^2\mathrm{d}P_r(y)\\
            &\quad -b(z)\int_\mathcal{P}p_\epsilon(g_\theta(z)-y)\nabla_\theta||g_\theta(z)-y||^2\mathrm{d}P_g(y)\bigg]
            \end{align*}
            其中：$a(z),b(z)$是两个正值函数。更进一步的，$b>a$当且仅当$p_{r+\epsilon} > p_{g+\epsilon}$；$b<a$当且仅当$p_{r+\epsilon} < p_{g+\epsilon}$。
            \end{theorem}
            \par
            定理3.2证明了G的梯度可以分为两项，第一项表明，G会被引导向真实数据分布移动，第二项表明，G会被引导向概率很高的生成样本远离。作者指出，上述的梯度格式具有一个很严重的问题，那就是由于$g(\mathcal{Z})$是零测集，D在优化时将忽略该集合；然而G却只在该集合上进行优化。进一步地，这将导致D极度容易受到生成样本的影响，产生没有意义的样本。
            \begin{corollary}[corollary 3.2]
            设$\epsilon,\epsilon'\sim N(0,\sigma^2I)$以及$\tilde{g}_{\theta}(z)=g_\theta(z)+\epsilon' $，则
            \begin{align*}
            \mathbb{E}_{z\sim p(z),\epsilon'}[\nabla_\theta\log (1-D^*(\tilde{g}_\theta(z)))]& = \mathbb{E}_{z\sim p(z),\epsilon'} \bigg[a(z)\int_\mathcal{M}p_\epsilon(\tilde{g}_\theta(z)-y)\nabla_\theta||\tilde{g}_\theta(z)-y||^2 \mathrm{d}P_r(y) \\
            &\quad -b(z)\int_\mathcal{P}p_\epsilon(\tilde{g}_\theta(z)-y)\nabla_\theta||\tilde{g}_\theta(z)-y||^2\mathrm{d}P_g(y)\bigg]\\
            &=2\nabla_\theta JSD(P_{r+\epsilon}||P_{g+\epsilon})
            \end{align*}
            \end{corollary}
            \par
            上述推论中的$a,b$和Theorem3.2相同，主要的不同是对D的输入添加噪声，在训练的过程中将引导噪声样本向真实数据流形的方向移动，这可以看成是引导样本的一个小邻域向真实数据移动。这可以解决D极度容易受到生成样本的影响的问题。
            \begin{Proof}
            在求解生成器时，判别器是固定的，$g_\theta(z)$是唯一依赖于$\theta$的量(for every $z$)。对我们的损失函数求导，有
            \begin{align*}
            &\mathbb{E}_{z\sim p(z)}[\nabla_\theta\log(1-D^*(g_\theta(z)))]\\
            ={}&\mathbb{E}_{z\sim p(z)}\left[ \nabla_\theta\log \frac{p_{g+\epsilon}(g_\theta(z))}{p_{r+\epsilon}(g_\theta(z))+ p_{g+\epsilon}(g_\theta(z))}   \right]\\
            ={}&\mathbb{E}_{z\sim p(z)}\left[ \nabla_\theta\log p_{g+\epsilon}(g_\theta(z))- \nabla_\theta\log (p_{r+\epsilon}(g_\theta(z))+p_{g+\epsilon}(g_\theta(z)))  \right]\\
            ={}&\mathbb{E}_{z\sim p(z)}\left[ \frac{\nabla_\theta p_{g+\epsilon}(g_\theta(z))}{p_{g+\epsilon}(g_\theta(z))} - \frac{\nabla_\theta p_{g+\epsilon}(g_\theta(z))+\nabla_\theta p_{r+\epsilon}(g_\theta(z))}{p_{g+\epsilon}(g_\theta(z))+ p_{r+\epsilon}(g_\theta(z))}    \right]\\
            ={}&\mathbb{E}_{z\sim p(z)}\bigg[ \frac{1}{p_{g+\epsilon}(g_\theta(z))+ p_{r+\epsilon}(g_\theta(z))} \nabla_\theta[p_{r+\epsilon}(g_\theta(z))] \\
            & \quad -  \frac{1}{p_{g+\epsilon}(g_\theta(z))+ p_{r+\epsilon}(g_\theta(z))} \frac{p_{r+\epsilon}(g_\theta(z))}{p_{g+\epsilon}(g_\theta(z))}\nabla_\theta[p_{g+\epsilon}(g_\theta(z))]
             \bigg]
            \end{align*}
            令$\epsilon$的密度为$\frac{1}{Z}e^{-\frac{||x||^2}{2\sigma^2}}$。现在，我们定义
            \begin{align*}
            & a(z) = \frac{1}{2\sigma^2} \frac{1}{p_{g+\epsilon}(g_\theta(z))+ p_{r+\epsilon}(g_\theta(z))}\\
            & b(z) = \frac{1}{2\sigma^2} \frac{1}{p_{g+\epsilon}(g_\theta(z))+ p_{r+\epsilon}(g_\theta(z))}\frac{p_{r+\epsilon}(g_\theta(z))}{p_{g+\epsilon}(g_\theta(z))}
            \end{align*}
            前面我们说$a,b$是正实数。根据$a,b$的表达式，我们有$b=a\frac{p_{r+\epsilon}}{p_{g+\epsilon}}$，并且$b>a$当且仅当$p_{r+\epsilon}>p_{g+\epsilon}$，以及$b<a$当且仅当$p_{r+\epsilon}<p_{g+\epsilon}$，这正是我们想要的。继续上面的证明，有
            \begin{align*}
            &\mathbb{E}_{z\sim p(z)}[\nabla_\theta\log(1-D^*(g_\theta(z)))]\\
            ={}&\mathbb{E}_{z\sim p(z)}[2\sigma^2a(z)\nabla_\theta[-p_{r+\epsilon}(g_\theta(z))] - 2\sigma^2b(z)\nabla_\theta[-p_{g+\epsilon}(g_\theta(z))]]\\
            ={}&\mathbb{E}_{z\sim p(z)}\biggl[ 2\sigma^2a(z)\int_\mathcal{M}-\nabla_\theta \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\mathrm{d}p_r(y) \\
            &\quad -  2\sigma^2b(z)\int_\mathcal{P}-\nabla_\theta \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\mathrm{d}p_g(y)  \biggr]\\
            ={}&\mathbb{E}_{z\sim p(z)}\biggl[ a(z)\int_\mathcal{M} \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\nabla_\theta ||g_\theta(z)-y||^2 \mathrm{d}p_r(y) \\
            & \quad -  b(z)\int_\mathcal{P}\frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\nabla_\theta ||g_\theta(z)-y||^2\mathrm{d}p_g(y)  \biggr]\\
            ={}&\mathbb{E}_{z\sim p(z)}\biggl[ a(z)\int_\mathcal{M} p_\epsilon(g_\theta(z)-y) \nabla_\theta ||g_\theta(z)-y||^2 \mathrm{d}p_r(y) \\
            &\quad -  b(z)\int_\mathcal{P} p_\epsilon(g_\theta(z)-y)\nabla_\theta ||g_\theta(z)-y||^2\mathrm{d}p_g(y)  \biggr]
            \end{align*}
            % \begin{align*}
            % &\mathbb{E}_{z\sim p(z)}[\nabla_\theta\log(1-D^*(g_\theta(z)))]\\
            % ={}&\mathbb{E}_{z\sim p(z)}[2\sigma^2a(z)\nabla_\theta[-p_{r+\epsilon}(g_\theta(z))] - 2\sigma^2b(z)\nabla_\theta[-p_{g+\epsilon}(g_\theta(z))]]\\
            % ={}&\mathbb{E}_{z\sim p(z)}\left[ 2\sigma^2a(z)\int_\mathcal{M}-\nabla_\theta \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\mathrm{d}p_r(y) -  2\sigma^2b(z)\int_\mathcal{P}-\nabla_\theta \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\mathrm{d}p_g(y)  \right]\\
            % ={}&\mathbb{E}_{z\sim p(z)}\biggl[ a(z)\int_\mathcal{M} \frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\nabla_\theta ||g_\theta(z)-y||^2 \mathrm{d}p_r(y) \\
            % & \quad -  b(z)\int_\mathcal{P}\frac{1}{Z}e^{-\frac{||g_\theta(z)-y||_2^2}{2\sigma^2}}\nabla_\theta ||g_\theta(z)-y||^2\mathrm{d}p_g(y)  \biggr]\\
            % ={}&\mathbb{E}_{z\sim p(z)}\biggl[ a(z)\int_\mathcal{M} p_\epsilon(g_\theta(z)-y) \nabla_\theta ||g_\theta(z)-y||^2 \mathrm{d}p_r(y) \\
            % &\quad -  b(z)\int_\mathcal{P} p_\epsilon(g_\theta(z)-y)\nabla_\theta ||g_\theta(z)-y||^2\mathrm{d}p_g(y)  \biggr]
            % \end{align*}
            Finishing the proof. $\square$
            \end{Proof}
            \begin{definition}[Wasserstein距离]
            $\mathcal{X}$上的两个分布$P,Q$的Wasserstein距离/度量/散度$W(P,Q)$定义为
            \begin{align*}
            W(P,Q) = \inf_{\gamma \in \Gamma}\int_{\mathcal{X}\times \mathcal{X}}||x-y||_2\mathrm{d}\gamma(x,y)
            \end{align*}
            其中，$\Gamma$是$\mathcal{X}\times \mathcal{X}$上所有具有边界分布$P$和$Q$的联合分布集。
            \end{definition}
            \par
            对Wasserstein距离，$\Pi (P_r, P_g)$中每一个分布的边缘分布都是$P_r$和$P_g$。对于每一个可能的联合分布$\gamma$而言，可以从中采样$(x, y) \sim \gamma$得到一个真实样本$x$和一个生成样本$y$，并算出这对样本的距离$||x-y||$，所以可以计算该联合分布$\gamma$下样本对距离的期望值$\mathbb{E}_{(x, y) \sim \gamma} [||x - y||]$。在所有可能的联合分布中能够对这个期望值取到的下界$\inf_{\gamma \sim \Pi (P_r, P_g)} \mathbb{E}_{(x, y) \sim \gamma} [||x - y||]$，就定义了Wasserstein距离。
            \par
            直观上可以把$\mathbb{E}_{(x, y) \sim \gamma} [||x - y||]$理解为在$\gamma$这个“路径规划”下把$P_r$这堆“沙土”挪到$P_g$“位置”所需的“消耗”，而$W(P_r, P_g)$就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover(推土机)距离。
            \par
            Wasserstein距离表示从一个分布转移成另一个分布所需的最小代价。下图(\ref{fig:Wasserstein距离：分布转移示意图})给出了一个离散分布下的例子，将$f_1(x)$迁移成$f_2(x)$最小代价即是移动$f_1(x)$在最大值处的2个单位的概率到最小值处，这样就得到了分布$f_2(x)$。更复杂的离散转移情形则需要求解规划问题，可以考虑使用最优传输理论。
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/Wasserstein_distribution.jpg}
                \caption{分布转移示意图}
                \label{fig:Wasserstein距离：分布转移示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：Wasserstein距离：分布转移示意图}
            \begin{lemma}[Lemma4]
            若$\epsilon$是零均值的随机向量，则我们有
            \begin{align*}
            W(P_X,P_{X+\epsilon}) \leqslant V^{\frac{1}{2}}
            \end{align*}
            其中：$V = \mathbb{E}[||\epsilon||_2^2]$是$\epsilon$的方差。
            \end{lemma}
            \begin{Proof}
            令$x\sim P_X$，$y = x+\epsilon$并且$\epsilon$和$x$独立。令$r$为$x,y$的积分域，它有边界$P_X$和$P_{X+\epsilon}$。Therefore
            \begin{align*}
            W(P_X,P_{X+\epsilon})& \leqslant \int ||x-y||_2\mathrm{d}\gamma(x,y)\\
            & = \mathbb{E}_{x\sim P_X}\mathbb{E}_{y\sim x+\epsilon} [||x-y||_2]\\
            &=\mathbb{E}_{x\sim P_X}\mathbb{E}{y\sim x+\epsilon}[||\epsilon||_2]\\
            &=\mathbb{E}_{x\sim P_X}\mathbb{E}_\epsilon [||\epsilon||_2]\\
            &=\mathbb{E}_\epsilon[||\epsilon||_2]\\
            & \leqslant \mathbb{E}_\epsilon[||\epsilon||_2^2]^{\frac{1}{2}} = V^{\frac{1}{2}}
            \end{align*}
            where the last inequality was due to Jensen. $\square$
            \end{Proof}
            引理4表明，一个分布于它添加扰动后的分布的Wasserstein距离能被扰动的标准差bound住。
            \begin{theorem}[Theorem 3.3]
            设$P_r$和$P_g$是任意的两个分布，$\epsilon$是一个零均值，方差为$V$的随机向量。若$P_{r+\epsilon}$和$P_{g+\epsilon}$的支撑集落在直径为$C$的球内，则
            \begin{align*}
            W(P_r,P_g) \leqslant 2 V^{\frac{1}{2}}+2C\sqrt{JSD(P_{r+\epsilon}||P_{g+\epsilon})}
            \end{align*}
            \end{theorem}
            \begin{Proof}
            \begin{align*}
            W(P_r) & \leqslant W(P_r||P_{r+\epsilon})+W(P_{r+\epsilon},P_{g+\epsilon})+W(P_{g+\epsilon},P_g)\\
             & \leqslant 2V^{\frac{1}{2}} + W(P_{r+\epsilon},P_{g+\epsilon})\\
             & \leqslant 2V^{\frac{1}{2}} + C\delta(P_{r+\epsilon},P_{g+\epsilon})\\
             & \leqslant 2V^{-\frac{1}{2}} + C(\delta(P_{r+\epsilon},P_m)+\delta(P_{g+\epsilon},P_m) )\\
             & \leqslant 2V^{\frac{1}{2}} + C \left( \sqrt{\frac{1}{2}KL(P_{r+\epsilon}||P_m)} + \sqrt{\frac{1}{2}KL(P_{g+\epsilon}||P_m)} \right) \\
             & \leqslant 2V^{\frac{1}{2}} + 2C\sqrt{JSD(P_{r+\epsilon}||P_{g+\epsilon})}
            \end{align*}
            \par
            上述推导的过程是：first used the Lemma 4 to bound everything but the middle term as a funtion of $V$. After that, we followed by the fact that $W(P.Q)\leqslant C\delta (P,Q)$with $\delta$ the total variation, which is a popular Lemma arizing from the Kantorovich - Rubinstein duality.After that, we used the reiangular inequality on $\delta$ and $P_m$ the mixture distribution between $P_{g+\epsilon}$ and $P_{r+\epsilon}$. Finally, we used Pinsker's inequality and later the fact that each individual KL is only one of the non-negative summands of the JSD.
            \end{Proof}
            \par
            定理3.3告诉我们一个有趣的事实，上式右边两项均能被控制。第一项可以通过逐步减小噪声来逐步减小；第二项可以通过训练GAN(给D的输入添加噪声)来最小化。
            \par
            作者指出，这种通过给D的输入添加噪声的解决方案具有一大好处，那就是我们不需要再担心训练过程。由于引入了噪声，我们可以训练D直到最优而不会遇到G的梯度消失或者训练不稳定的问题，此时G的梯度可以通过推论3.2给出。加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是这种解决方法仍然没能够提供一个衡量训练进程的数值指标。
            \par
            总而言之，上面从理论上研究了GAN训练过程中经常出现的两大问题：G的梯度消失、训练不稳定。并且提出了利用地动距离来衡量$P_r$和$P_g$的相似性、对D的输入引入噪声来解决GAN的两大问题，作者证明了地动距离具有上界，并且上界可以通过有效的措施逐步减小。
            \par
            这可以说是一个临时性的解决方案，作者甚至没有给出实验进行验证。在WGAN\cite{2017.Chen}这篇文章中，作者提出了更完善的解决方案，并且做了实验进行验证。下面我们就来看一下这篇文章。

        \subsubsection{Wasserstein距离的优越性质}
            \paragraph{常见距离}
            Martin Arjovsky在文献\cite{2017.Chen}进一步论述了为什么选择Wasserstein距离(地动距离)。
            设$\mathcal{X}$是一个紧致度量空间，这里讨论的图像空间$[0,1]^d$就是紧致度量空间。用$\Sigma$表示$\mathcal{X}$上的所有博雷尔集，用$\mathrm{Prob}(\mathcal{X})$表示定义在$\mathcal{X}$上的概率度量空间。给定$\mathrm{Prob}(\mathcal{X})$上的两个分布$P_r,P_g$，我们可以定义它们的距离/散度(注意：散度不是距离，它不是对称的。距离和散度都可以用于衡量两个分布的相似程度)
            \begin{enumerate}
            \item 全变差(Total Variation)距离
            \begin{align*}
            \delta(P_r,P_g) = \sup_{A\in \Sigma}|P_r(A)-P_g(A)|
            \end{align*}
            \item KL散度(Kullback-Leibler divergence)
            \begin{align*}
            KL(P_r||P_g) = \int \log \left( \frac{p_r(x)}{p_g(x)} \right) p_r(x)\mathrm{d}\mu(x)
            \end{align*}
            \item JS散度(Jensen - Shannon divergence)
            \begin{align*}
            JS(P_r,P_g) = KL(P_r||P_m) + KL(P_g||P_m)
            \end{align*}
            其中：$P_m = \frac{P_r+P_g}{2}$。
            \item Wasserstein距离/地动距离(Wasserstein/Earth - Mover)
            \begin{align}
            \label{eq:Wasserstein距离}
            W(P_r,P_g) = \inf_{\gamma\in \Pi(P_r,P_g)}\mathbb{E}_{(x,y\sim \gamma)}[||x-y||]
            \end{align}
            其中：$\Pi(P_r,P_g)$表示以$P_r,P_g$为边缘分布的所有联合分布组成的集合。
            \end{enumerate}
            \par
            Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。
            \par
            用一个简单的例子来看一下这四种距离/散度是怎么计算的。考虑下图(\ref{fig:2个均匀分布距离示意图})的两个均匀分布
                \begin{figure}[H]
                \centering
                \includegraphics[width=4cm]{images/Two_uniform_distribution_distances.jpg}
                \caption{2个均匀分布距离示意图}
                \label{fig:2个均匀分布距离示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：2个均匀分布距离示意图} \\
            二维平面上，$P_1$是沿着$y$轴的$[0,1]$区间上的均匀分布，$P_2$是沿着$x=0$，在$y$轴的$[0,1]$区间上的均匀分布。简而言之，我们可以把$P_1$和$P_2$看成是两条平行的线段。容易计算
            \begin{align*}
            &\delta(P_1,P_2) =
            \left\{
            \begin{aligned}
            1, \quad \theta \neq 0\\
            0,\quad \theta = 0
            \end{aligned}
            \right.\\
            &KL(P_1||P_2) = KL(P_2||P_1) =
            \left\{
            \begin{aligned}
            +\infty ,\quad \theta \neq 0\\
            0,\quad \theta = 0
            \end{aligned}
            \right.\\
            &JS(P_1,P_2) =
            \left\{
            \begin{aligned}
            \log 2,\quad \theta \neq 0\\
            0,\quad \theta =0
            \end{aligned}
            \right.\\
            &W(P_1,P_2) = |\theta|
            \end{align*}
            \par
            当$\theta \to 0$时，$W\to 0$，然而TV距离、KL散度、JS散度都不收敛。KL散度和JS散度是突变的，要么最大要么最小，而Wasserstein距离却是平滑的，如果我们要用梯度下降法优化$\theta$这个参数，前两者根本提供不了梯度，但Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，但是Wasserstein却可以提供有意义的梯度。
            更严谨的结论由下面的定理给出。
            \begin{theorem}[Theorem 1]
            设$P_r$是定义在$\mathcal{X}$上的一个固定分布，$z$是定义在$\mathcal{Z}$空间上的随机变量。再设$g:\mathcal{Z}\times R^d\to \mathcal{X}$是一个函数，记为$g_\theta(z)$。记$g_\theta(Z)$的分布为$P_\theta$，则
            \begin{enumerate}
            \item  若$g$关于$\theta$连续，则$W(P_r,P_\theta)$也连续；
            \item 若$g$满足局部Lipschitz条件，局部Lipschitz常数为$L(\theta,z)$，且$\mathbb{E}_{z\sim p(z)}L(\theta,z)< +\infty$，则$W(P_r,P_\theta)$处处连续，且几乎处处可微。
            \end{enumerate}
            \end{theorem}
            \par
            上述两个结论对JS散度和KL散度均不成立。定理1表明，地动距离与JS散度、KL散度相比，具有更好的性质。
            \begin{corollary}[corollary 1]
            设$g_\theta$是任意一个前向传播网络，带有参数$\theta$，并且$p(z)$是关于$z$的先验概率，满足$\mathbb{E}_{z\sim p(z)}||z|| < +\infty$。$g$满足局部Lipschitz条件，局部L常数为$L(\theta,z)$，且$\mathbb{E}_{z\sim p(z)}L(\theta,z)<+\infty$，则$W(P_r,P_\theta)$处处连续，且几乎处处可微。
            \end{corollary}
            \par
            上述推论1(corollary 1)表明，将地动距离作为神经网络的目标函数是可行的。
            \begin{theorem}[Theorem 2]
            设$P$是紧致空间$\mathcal{X}$上的一个分布，并且$(P_n)_{n\in \mathbb{N}}$是$\mathcal{X}$上的一个分布序列，则当$n\rightarrow \infty$时
            \begin{enumerate}
            \item 下面两个命题是等价的
            \begin{enumerate}
            \item $\delta(P_n,P)\to 0$ with $\delta$ the total variation distace;
            \item $JS(P_n,P)\to 0$。
            \end{enumerate}
            \item 下面两个命题是等价的
            \begin{enumerate}
            \item $W(P_n,P)\to 0$.
            \item $P_n$依分布收敛于$P$，$P_n\xrightarrow{D} P$。
            \end{enumerate}
            \item $KL(P_n||P)\to 0$或者$KL(P||P_n)\to 0$能导出结论1.
            \item 结论1能导出结论2.
            \end{enumerate}
            \end{theorem}
            \par
            定理2(Theorem 2)表明，如果分布的支撑集在低维流形上，KL散度、JS散度和TV距离并不是好的loss，而地动(EM)距离则很合适。这启发我们可以用地动距离(EM)来设计loss以替换原来GAN采用的KL散度。


        \subsubsection{从Wasserstein距离到WGAN}
            \par
            采用Wasserstein距离作为loss的GAN称为WassersteinGAN，一般简写为WGAN。直接考虑Wasserstein距离需要算$\inf$，计算是很困难的，因为Wasserstein距离定义(\ref{eq:Wasserstein距离})中的$\inf_{\gamma \sim \Pi (P_r, P_g)}$没法直接求解。考虑它的Kantorovich-Rubinstein对偶形式
            \begin{align*}
            W(P_r,P_\theta) = \sup_{||f||_L \leqslant 1}\mathbb{E}_{x\sim P_r}[f(x)] - \mathbb{E}_{x\sim P_\theta}[f(x)]
            \end{align*}
            其中：$||f||_L \leqslant 1$是所有的1-Lipschitz函数$f:\mathcal{X}\to R$。也就是说，Wasserstein距离实际上需要考虑所有的1-Lipschitz函数。如果我们考虑的是K-Lipschitz函数，这Wasserstein距离变为原来的$K$倍

            \begin{align}
            \label{公式13}
            W(P_r, P_g) = \frac{1}{K} \sup_{||f||_L \leq K} \mathbb{E}_{x \sim P_r} [f(x)] - \mathbb{E}_{x \sim P_g} [f(x)]
            \end{align}
            \par
            式(\ref{公式13})的意思就是在要求函数$f$的Lipschitz常数$||f||_L$不超过$K$的条件下，对所有可能满足条件的$f$取到$\mathbb{E}_{x \sim P_r} [f(x)] - \mathbb{E}_{x \sim P_g} [f(x)]$的上界，然后再除以$K$。特别地，我们可以用一组参数$w$来定义一系列可能的函数$f_w$，此时求解式(\ref{公式13})可以近似变成求解如下形式
            \begin{align}
            \label{公式14}
            K \cdot W(P_r, P_g) \approx \max_{w: |f_w|_L \leq K} \mathbb{E}_{x \sim P_r} [f_w(x)] - \mathbb{E}_{x \sim P_g} [f_w(x)]
            \end{align}
            \par
            可以把$f$用一个带参数$w$的神经网络来表示。由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列$f_w$虽然无法囊括所有可能，但是也足以高度近似式(\ref{公式13})要求的那个$\sup_{||f||_L \leq K} $了。
            \par
            最后，还不能忘了满足式(\ref{公式14})中$||f_w||_L \leq K$这个限制。我们其实不关心具体的$K$是多少，只要它不是正无穷就行，因为它只是会使得梯度变大$K$倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络$f_\theta$的所有参数$w_i$的不超过某个范围$[-c, c]$，比如$w_i \in [- 0.01, 0.01]$。此时关于输入样本$x$的导数$\frac{\partial f_w}{\partial x}$也不会超过某个范围，所以一定存在某个不知道的常数$K$使得$f_w$的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完$w$后把它clip回这个范围就可以了。
            \par
            到此为止，我们可以构造一个含参数$w$、最后一层不是非线性激活层的判别器网络$f_w$，在限制$w$不超过某个范围的条件下，使得
            \begin{align}
            \label{公式15}
            L = \mathbb{E}_{x \sim P_r} [f_w(x)] - \mathbb{E}_{x \sim P_g} [f_w(x)]
            \end{align}
            尽可能取到最大，此时$L$就会近似真实分布与生成分布之间的Wasserstein距离(忽略常数倍数$K$)。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器$f_w$做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。
            \par
            接下来生成器要近似地最小化Wasserstein距离，可以最小化$L$，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到L的第一项与生成器无关，就得到了WGAN的两个loss：
            \begin{align}
            \label{公式16，WGAN生成器loss函数}
            - \mathbb{E}_{x \sim P_g} [f_w(x)]
            \end{align}
            和
            \begin{align}
            \label{公式17，WGAN判别器loss函数}
            \mathbb{E}_{x \sim P_g} [f_w(x)]- \mathbb{E}_{x \sim P_r} [f_w(x)]
            \end{align}
            \par
            式(\ref{公式15})是式(\ref{公式17，WGAN判别器loss函数})的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。
            \par
            记$G = g_\theta,D = f_w$，则上式(\ref{公式15})写为
            \begin{align*}
            \max_D\  \mathbb{E}_{x\sim P_r}[D(x)] - \mathbb{E}_{z\sim p(z)}[D(G(z))]
            \end{align*}
            我们再次回顾一下原GAN中的目标
            \begin{align*}
            \max_D \mathbb{E}_{x\sim P_r}[\log D(x)] - \mathbb{E}_{z\sim p(z)}[\log (1-D(G(z)))]
            \end{align*}
            可以看到，如果把GAN的目标函数的$\log$去掉，则两者只相差一个常数，也就是说，WGAN在训练的时候与GAN几乎一样，除了loss计算的时候不取对数！Loss function中的对数函数导致了GAN训练的不稳定！
            \begin{theorem}[Theorem 3]
            设$P_r$是任一分布，$P_\theta$是$g_\theta(Z)$的分布，其中$Z$的先验概率密度函数为$p(z)$，$g$满足局部Lipschitz条件，局部Lipschitz常数为$L(\theta,z)$，且$E_{z\sim p(z)} L(\theta,z)<+\infty $，则下述问题存在解$f:\mathcal{X}\to R$
            \begin{align*}
            \max _{||f||_L \leqslant 1} \mathbb{E}_{x\sim P_r}[f(x)] - \mathbb{E}_{x\sim P_\theta }[f(x)]
            \end{align*}
            并且，我们有
            \begin{align*}
            \nabla_\theta W(P_r,P_\theta) = -\mathbb{E}_{z\sim p(z)}[\nabla _\theta f(g_\theta(z))]
            \end{align*}
            when both terms are well-defined
            \end{theorem}
            \par
            定理3(Theorem 3)证明了若D和G的学习能力足够强的话(因此目标函数能够被最大化)，WGAN是有解的。改进后相比原始GAN的算法实现流程却只改了四点：
            \begin{enumerate}
            \item 判别器最后一层去掉sigmoid；
            \item 生成器和判别器的loss不取log；
            \item 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数$c$；
            \item 不要用基于动量的优化算法(包括momentum和Adam)，推荐RMSProp，SGD也行。
            \end{enumerate}
            \par
            前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。
        \subsubsection{WGAN程序}
            \par
            WGAN算法伪代码如(\ref{code:WGAN})所示
            \begin{algorithm}[htbp]
                \caption{WGAN,our proposed algorithm. All experiments in the used the default values $\alpha = 0.00005$,$c=0.01$,$m=64$,$n_{critic}=5$}\label{code:WGAN}
                \begin{algorithmic}[1]
                    \State 初始化：学习率$\alpha$，修剪参数$c$；批量大小$m$；循环$n_{critic}$；初始化critic的参数$w_0$，生成器G的参数$\theta_0$。
                    \While {未达到停止准则}
                        \For {$t=1$ to $n_{critic}$}
                            \State 采样$\{x^{(i)}\}_{i=1}^m\sim P_r$；
                            \State 采样$\{z^{(i)}\}_{i=1}^m\sim P_z$；
                            \State
                            \begin{align*}
                            g_w \leftarrow \nabla_w \left[\frac{1}{m}\sum_{i=1}^m f_w(x^{(i)}) - \frac{1}{m}\sum_{i=1}^mf_w(g_\theta(z^{(i)}))\right]
                            \end{align*}
                            \State $w\leftarrow w+\alpha \cdot \mathrm{RMSProp}(w,g_w)$；
                            \State $w\leftarrow \mathrm{clip}(w,-c,c)$
                        \EndFor
                        \State 采样$\{z^{(i)}\}_{i=1}^m\sim P_z$；
                        \State 更新$g_\theta \leftarrow \nabla_\theta\frac{1}{m}\sum_{i=1}^mf_w(g_\theta(z^{(i)}))$
                        \State $\theta \leftarrow \theta - \alpha \cdot \mathrm{RMSProp}(w,g_\theta)$
                    \EndWhile
                \end{algorithmic}
            \end{algorithm}

            \par
            WGAN 源码实现\footnote{https://github.com/martinarjovsky/WassersteinGAN}和
            \footnote{https://github.com/wiseodd/generative-models}。下面给出WGAN的TensorFlow程序
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 10
            h_dim = 128
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def generator(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def discriminator(x):
                D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)
                out = tf.matmul(D_h1, D_W2) + D_b2
                return out
            G_sample = generator(z)
            D_real = discriminator(X)
            D_fake = discriminator(G_sample)
            D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)
            G_loss = -tf.reduce_mean(D_fake)
            D_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)
                        .minimize(-D_loss, var_list=theta_D))
            G_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)
                        .minimize(G_loss, var_list=theta_G))
            clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D]
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                for _ in range(5):
                    X_mb, _ = mnist.train.next_batch(mb_size)
                    _, D_loss_curr, _ = sess.run(
                        [D_solver, D_loss, clip_D],
                        feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}
                    )
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss],
                    feed_dict={z: sample_z(mb_size, z_dim)}
                )
                if it % 100 == 0:
                    print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    if it % 1000 == 0:
                        samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})

                        fig = plot(samples)
                        plt.savefig('out/{}.png'
                                    .format(str(i).zfill(3)), bbox_inches='tight')
                        i += 1
            plt.close(fig)
            \end{lstlisting}
            \par
            WGAN实验：对WGAN作者做了不少实验验证，下面只提比较重要的三点。第一，判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关。Wasserstein距离越小，G产生的图像质量就越高。先前的GAN由于训练不稳定，我们很难通过loss去判断G产生的质量(先前的GAN的loss大小并不能表明产生图像质量的高低)，如下图(\ref{fig:Wasserstein距离与生成器的生成图片质量})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/Wasserstein_picture.jpg}
                \caption{Wasserstein距离与生成器的生成图片质量}
                \label{fig:Wasserstein距离与生成器的生成图片质量}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo：图片：Wasserstein距离与生成器的生成图片质量}\\
            第二，WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多，如图(\ref{fig:WAGN和DCGAN对比图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/WAGN_and_DCGAN.jpg}
                \caption{WAGN和DCGAN对比图}
                \label{fig:WAGN和DCGAN对比图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：WAGN和DCGAN对比图}\\
            但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，如果一起拿掉Batch Normalization的话，DCGAN就崩了而WGAN不会，如图(\ref{fig:DCGAN去掉BN的崩溃})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/DCGAN_remove_BN.jpg}
                \caption{DCGAN去掉BN的崩溃}
                \label{fig:DCGAN去掉BN的崩溃}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：DCGAN去掉BN的崩溃}\\
            如果WGAN和原始GAN都使用多层全连接网络(MLP)，不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足，如图(\ref{fig:WGAN和DCGAN去掉CNN对比结果})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/WGAN_and_DCGAN_remove_CNN.png}
                \caption{WGAN和DCGAN去掉CNN对比结果}
                \label{fig:WGAN和DCGAN去掉CNN对比结果}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：WGAN和DCGAN去掉CNN对比结果}\\
            第三，在所有WGAN的实验中未观察到collapse mode，作者也只说应该是解决了。
            % \par
            % 最后补充一点论文没提到，但是我个人觉得比较微妙的问题。判别器所近似的Wasserstein距离能够用来指示单次训练中的训练进程，这个没错；接着作者又说它可以用于比较多次训练进程，指引调参，我倒是觉得需要小心些。比如说我下次训练时改了判别器的层数、节点数等超参，判别器的拟合能力就必然有所波动，再比如说我下次训练时改了生成器两次迭代之间，判别器的迭代次数，这两种常见的变动都会使得Wasserstein距离的拟合误差就与上次不一样。那么这个拟合误差的变动究竟有多大，或者说不同的人做实验时判别器的拟合能力或迭代次数相差实在太大，那它们之间还能不能直接比较上述指标，我都是存疑的。
            % 评论区的知友$\@ Minjie Xu $进一步指出，相比于判别器迭代次数的改变，对判别器架构超参的改变会直接影响到对应的Lipschitz常数$K$，进而改变近似Wasserstein距离的倍数，前后两轮训练的指标就肯定不能比较了，这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的$K_2$相对前面$K_1$的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。


            % \subsubsection{总结}
            %     \par
            %     WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。
            %     \par
            %     WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。
            %     \par
            %     WGAN本作引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。

    \subsection{Improved WGAN}
        \subsubsection{问题分析}
            \par
            WGAN虽然克服了GAN梯度消失等问题，但是在某些设置下，WGAN生成的样本仍然是低质量的，甚至不收敛。文献\cite{2017.Ishaan}的作者发现，WGAN强行使critic是lipschitz连续的权重修剪技术(weight clipping)会导致WGAN失败。为了强行使用lipschitz连续，作者在improved WGAN中设置了一个交替的方法：惩罚critic梯度的范数。相对而言，Improved WGAN有更快的收敛速度和更高的图像质量。
            \par
            WGAN的价值函数是通过 Kantorovich-Rubinstein对偶建立的
            \begin{align*}
            \min_G\ \max_{D\in \mathcal{D}} \ \mathbb{E}_{x\sim p_r}[D(x)] - \mathbb{E}_{\tilde{x}\sim p_g}[D(\tilde{x})]
            \end{align*}
            其中：$\mathcal{D}$是一个1-lipschitz函数集，$\tilde{x} = G(z),z\sim p_z$。一个公开的问题是如何有效的对critic进行lipschitz约束？ Arjovsky在WGAN中使用了权重裁剪技术，使权重在$[-c,c]$范围内(每当更新完一次判别器的参数之后，就检查判别器的所有参数的绝对值有没有超过一个阈值。通过在训练过程中保证判别器的所有参数有界，就保证了判别器不能对两个略微不同的样本给出天差地别的分数值，从而间接实现了Lipschitz限制)。
            \par
            如果在Kantorovich-Rubinstein对偶$D^*$下，最优的critic是可微的，并且$x$是生成分布$p_g$的一个样本，那么，存在一个$p_r$中的点$y$，$D^*$的梯度在所有点$x_t = (1-t)x+ty$直接通向$y$，即
            \begin{align*}
            \nabla D^*(x_t) = \frac{y-x_t}{||y-x_t||}
            \end{align*}
            这意味着最佳WGAN critic的梯度范数为1(almost everywhere $p_r$ and $p_g$)。作者发现WGAN的优化通常是困难的，即便当优化成功时，critic也可能会有比较粗糙的值。下面，我们将展示这些问题及它们的影响(weight clipping的实现方式存在两个严重问题)。
            \par
            实验表明，修剪每一个权重或者修剪权重的1阶范数、2阶范数都会导致相同的问题，这有可能是因为clip“损伤”了WGAN的训练。但是，我们不能声称每一次训练都有问题，特别是当WGAN权重剪枝和batch normalization技术一起使用的时候。有些时候，BN是有用的，在某些时候，特别是深度网络时，优化仍然困难。在Improved WGAN中没有BN的WGAN仍可以成功训练。
            \par
            优化带权重约束的critic相当于优化所有k-lipschitz函数的一个小子集。作者发现，这会导致许多问题，即便当优化任务收敛后，critic也可能收敛到一个非常差的情况。最优的critic(在WGAN损失函数下)的梯度范数为1，然而在权重修剪约束下，大多数网络在学习简单函数时，只能够达到的梯度范数为$k$。因此，通过权重修剪来达到k-lipschitz约束会使critic变成简单函数。例如在权重修剪下，最优critic可能包含许多重复的隐含神经元，忽略网络中的对称性，这最终被汇总来最大化the out 的最终比例。这种策略在最大化$p_r$和$p_g$散度时可能是最优的，但是这会导致在训练G时缺失有价值的梯度。
            \par
            为了证明这一点，我们训练WGAN critic(clipping)来优化3个实验分布：保持生成分布$p_g$固定，在真实分布$p_r$中添加单位方差的高斯噪声，在图(\ref{fig:critics的价值曲面})中给出critics的价值曲面
                \begin{figure}[H]
                \centering
                \includegraphics[width=10cm]{images/Critics_of_value_of_the_surface.jpg}
                \caption{critics的价值曲面}
                \label{fig:critics的价值曲面}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：critics的价值曲面}\\
            注意，在Improved WGAN的critic中忽略了BN。在3种实验分布下，通过权重修剪训练的critics忽略了数据分布的高阶矩，并且非常简单的接近最优函数。相比之下，Improved WGAN没有这种问题。
            \par
            如果权重被约束的太小，前层的反向传播带来的梯度会消失。另一方面，如果权重被约束的太大，网络会发生梯度爆炸。这是因为Weight clipping独立地限制每一个网络参数的取值范围，在这种情况下，最优的策略就是尽可能让所有参数走极端，要么取最大值要么取最小值！为了验证这一点，作者统计了经过充分训练的判别器中所有网络参数的数值分布，在图(\ref{fig:WGAN梯度消失和爆炸})(b)左图中展示了这一情况。这样带来的结果就是，判别器会非常倾向于学习一个简单的映射函数(想想看，几乎所有参数都是$\pm0.01$，这可以直接视为一个二值神经网络)。判别器没能充分利用自身的模型能力，经过它回传给生成器的梯度也会跟着变差。
                \begin{figure}[H]
                \centering
                \includegraphics[width=14cm]{images/WGAN_grandient_boom.jpg}
                \caption{WGAN梯度消失和爆炸}
                \label{fig:WGAN梯度消失和爆炸}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：WGAN梯度消失和爆炸}\\
            \par
            为了证明基于权重裁剪的WGAN会发生梯度消失和爆炸，我们在 Swiss Roll实验分布上训练WGAN。并且设置权重修剪参数$c$为$[10^{-1},10^{-2},10^{-3}]$，并绘制critic loss的梯度的模。WGAN中的critic和G都是12-层depReLuMLPs，并且没有BN。在图(\ref{fig:WGAN梯度消失和爆炸})(a)中，横轴代表判别器从低到高第几层，纵轴代表梯度回传到这一层之后的尺度大小(注意纵轴是对数刻度)，c是clipping threshold。结果表明：对于每个$c$，梯度会指数增长或减小，因为我们在网络中移动更远。
            \par
            在WGAN中使用BN技术，梯度消失或爆炸问题可能会有所减缓。然而，即使使用BN，非常deep WGAN critics 也经常获得坏的情况，甚至学习失败。
        \subsubsection{梯度惩罚}
            \par
            前面提到，Lipschitz限制是要求判别器的梯度不超过$K$，那我们何不直接设置一个额外的loss项来体现这一点呢？比如
            \begin{align*}
            ReLU(||\nabla_x D(x)||_p-K)
            \end{align*}
            不过，既然判别器希望尽可能拉大真假样本的分布差距，那自然是希望梯度越大越好，变化幅度越大越好，所以判别器在充分训练之后，其梯度norm其实就会是在$K$附近。知道了这一点，我们可以把上面的loss改成要求梯度norm离$K$越近越好，效果是类似
            \begin{align*}
            [||\nabla_x D(x)||_p-K]^2
            \end{align*}
            前面提到过最佳WGAN critic的梯度范数为1(almost everywhere $p_r$ and $p_g$)。我们将$K$设置为1，将上述目标和WGAN原来critic的目标loss加权合并，得到新的critic loss
            \begin{align*}
            L_{critic} = \mathbb{E}_{\tilde{x}\sim p_g}[D(\tilde{x})] - \mathbb{E}_{x\sim p_r}[D(x)] + \lambda \mathbb{E}_{x\sim p_{x}}[(||\nabla_{x}D(x)||_2 - 1)^2]
            \end{align*}
            \par
            上面的目标中有些个问题，3个loss项都是期望的形式，在实现上要变成采样的形式。前面两个期望的采样是一般的，第一个期望是从真样本集里面采，第二个期望是从生成器的噪声输入分布采样后，再由生成器映射到样本空间。可是第三个分布要求我们在整个样本空间$P_x$上采样，这变得非常棘手。由于维度灾难问题，如果要通过采样的方式在图片或自然语言这样的高维样本空间中估计期望值，所需样本量是指数级的，实际上没法做到。作者提出，其实我们没必要在整个样本空间上施加Lipschitz限制，只要重点抓住生成样本集中区域、真实样本集中区域以及夹在它们中间的区域就行了。具体来说，我们先随机采一对真假样本，还有一个0-1的随机数：
            \begin{align*}
            \epsilon \sim U[0,1],\quad x\sim p_r, \quad \tilde{x}\sim p_g
            \end{align*}
            然后在$ x_r $和$ x_g $的连线上随机插值采样
            \begin{align*}
            \hat{x} = \epsilon x+(1-\epsilon)\tilde{x}
            \end{align*}
            定义$\tilde{x}$的分布为$p_{\tilde{x}}$，并且$\hat{x}$是$p_r,p_g$的线性采样样本。最终得到Imoroved WGAN的loss
            \begin{align*}
            L_{critic} = \mathbb{E}_{\tilde{x}\sim p_g}[D(\tilde{x})] - \mathbb{E}_{x\sim p_r}[D(x)] + \lambda \mathbb{E}_{\hat{x}\sim p_{\hat{x}}}[(||\nabla_{\tilde{x}}D(\tilde{x})||_2 - 1)^2]
            \end{align*}
            \par
            在$\lambda$较大的情况下，我们构建的最优critic仍然是Kantorovich-Rubinstein对偶下的最优critic。因此，给定critic足够的能力，G的代价函数仍能回复真实的Wasserstein距离，这个在原始剪枝WGAN中不是必然发生的。梯度部分$||\nabla_{\tilde{x}}D(\tilde{x})||_2$是无参数D关于点$\tilde{x}$的梯度。
            \par
            超参数$\lambda$设置为10。许多GAN在G和D中都采用了BN技术，但在 Improved WGAN中，BN不适用，这是由于我们是对每个样本独立地施加梯度惩罚，判别器的模型架构中不能使用Batch Normalization，因为它会引入同个batch中不同样本的相互依赖关系。如果需要的话，可以选择其他normalization方法，如Layer Normalization、Weight Normalization和Instance Normalization，这些方法就不会引入样本之间的依赖，这里推荐Layer Normalization。

        \subsubsection{Improved WGAN程序}
            \par
            Mali GAN的伪代码如(\ref{code:Mali GAN})所示
            \begin{algorithm}[htbp]
                \caption{WGAN with gradient penalty.We use default values of $\lambda = 10$，$n_{critic} = 5$，$\alpha = 0.0001$，$\beta_1=0.5$，$\beta_2 = 0.9$.}
                \begin{algorithmic}[1]
                    \State 初始化：梯度约束的超参数$\lambda$；critic的循环次数$n_{critic}$；迭代数$t$，$t_{max}$；判别器训练次数$k$；批量大小$m$；Adam的超参数$\alpha,\beta_1,\beta_2$。
                    \For {$t=1,2,\dots,t_{max}$}
                        \For {$k = 1,\dots,n_{critic}$ }
                            \For {$i = 1,\dots,m$}
                                \State Sample real data $x\sim p_r$, latent variable $z\sim p_z$,a random number $\epsilon \sim U[0,1]$。
                                \State $\tilde{x} \leftarrow G_\theta(z)$
                                \State $\hat{x} \leftarrow \epsilon x+(1-\epsilon)\tilde{x}$
                                \State $L^{(i)} \leftarrow D_w(\tilde{x}) - D_w(x) +\lambda(||\nabla_{\hat{x}}D_w(\hat{x})||_2 - 1)^2 $
                            \EndFor
                            \State $w \leftarrow Adam(\nabla_w\frac{1}{m}\sum_{i=1}^m L^{(i)},w,\alpha,\beta_1,\beta_2)$
                        \EndFor
                        \State Sample a batch of latent variables $\{z^{(i)}\}_{i=1}^m \sim p(z)$
                        \State $\theta \leftarrow Adam(\nabla_w\frac{1}{m}\sum_{i=1}^m -D_w(G_\theta(z)),\theta,\alpha,\beta_1,\beta_2)$
                    \EndFor
                \end{algorithmic}
            \end{algorithm}
            \par
            Improved WGAN的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 10
            h_dim = 128
            lam = 10
            n_disc = 5
            lr = 1e-4
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def G(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def D(X):
                D_h1 = tf.nn.relu(tf.matmul(X, D_W1) + D_b1)
                out = tf.matmul(D_h1, D_W2) + D_b2
                return out
            G_sample = G(z)
            D_real = D(X)
            D_fake = D(G_sample)
            eps = tf.random_uniform([mb_size, 1], minval=0., maxval=1.)
            X_inter = eps*X + (1. - eps)*G_sample
            grad = tf.gradients(D(X_inter), [X_inter])[0]
            grad_norm = tf.sqrt(tf.reduce_sum((grad)**2, axis=1))
            grad_pen = lam * tf.reduce_mean(grad_norm - 1.)**2
            D_loss = tf.reduce_mean(D_fake) - tf.reduce_mean(D_real) + grad_pen
            G_loss = -tf.reduce_mean(D_fake)
            D_solver = (tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5)
                        .minimize(D_loss, var_list=theta_D))
            G_solver = (tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5)
                        .minimize(G_loss, var_list=theta_G))
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                for _ in range(n_disc):
                    X_mb, _ = mnist.train.next_batch(mb_size)
                    _, D_loss_curr = sess.run(
                        [D_solver, D_loss],
                        feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}
                    )
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss],
                    feed_dict={z: sample_z(mb_size, z_dim)}
                )
                if it % 1000 == 0:
                    print('Iter: {}; D loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    if it % 1000 == 0:
                        samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})
                        fig = plot(samples)
                        plt.savefig('out/{}.png'
                                    .format(str(i).zfill(3)), bbox_inches='tight')
                        i += 1
            plt.close(fig)
            \end{lstlisting}
            \par
            Improved WGAN和clipping WGAN等在CIFAR-10上收敛速度的比较如图(\ref{fig:Improved WGAN的收敛速度})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/Improved_WGAN.jpg}
                \caption{Improved WGAN的收敛速度}
                \label{fig:Improved WGAN的收敛速度}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：Improved WGAN的收敛速度}

    \subsection{Loss Sensitive GAN}
        \subsubsection{LS-GAN模型建立}
            \par
            在损失敏感生成对抗网络(LS-GAN)中，我们放弃学习一个判别器D ，而是设置一个损失函数$L_\theta(x)$，并且假设真实样本$x\sim P_r$有小的损失，假样本$x = G(z),z\sim p_z$有大的损失。对于一个给定的$G_\phi$，我们的目标是求$L_\theta$(即$\theta$)使得
            \begin{align*}
            \min_\theta \ \mathbb{E}_{x\sim p_r}L_\theta(x) - \mathbb{E}_{z\sim p_z}L_\theta(G_\phi(z))
            \end{align*}
            \par
            要求真假样本的损失在一定范围内，可以设置如下约束(constraint)
            \begin{align*}
            L_\theta(x)  \leqslant L_\theta(G_\phi(z)) - \Delta(x,G_\phi(z))
            \end{align*}
            其中：$\Delta(x,G_\phi(z))$表示$x$和$G_\phi(z)$之间的不同。现在引入松弛变量$\xi_{x,z}$
            \begin{align*}
            & L_\theta(x) - \xi_{x,z} \leqslant L_\theta(G_\phi(z)) - \Delta(x,G_\phi(z))\\
            & \xi_{x,z} \geqslant 0
            \end{align*}
            当$G_\phi(z)$违反约束时，$\xi_{x,z}$可能是非0的。对于一个给定的$G_\phi$，参数$\theta$的损失函数的训练目标为
            \begin{align*}
            &\min_\theta \ \mathbb{E}_{x\sim p_r} L_\theta(x) + \lambda \mathbb{E}_{x\sim p_r,z\sim p_z} \xi_{x,z}\\
            &s.t. \left\{
            \begin{aligned}
            & L_\theta(x) - \xi_{x,z}  \leqslant L_\theta(G_\phi(z)) - \Delta(x,G_\phi(z))\\
            & \xi_{x,z} \geqslant 0
            \end{aligned}
            \right.
            \end{align*}
            其中：$\lambda$是权重参数。目标中的第一项是真实样本损失最小，第二项是违反约束造成的损失的期望$\mathbb{E} \xi_{x,z}$最小。不失为一般性，我们要求损失函数是非正的，后面将会指出，在某些情况下，非正要求可以去掉。
            \par
            在给定最优损失$L_{\theta^*}$后，对生成器G而言，目标为
            \begin{align*}
            \min_\phi \ \mathbb{E}_{z\sim p_z} L_{\theta^*}(G_\phi(z))
            \end{align*}
            $L_\theta,G_\phi$仍然是交替优化的，最优参数$(\theta^*,\phi^*)$的优化过程为：\ding{172}对$\theta$的优化是在固定$\phi^*$的基础上，求
            \begin{align*}
            \min _\theta S(\theta,\phi^*) = \mathbb{E}_{x\sim p_r}L_\theta(x) + \lambda \mathbb{E}_{x\sim p_r,z\sim p_z} (\Delta(x,G(z))+L_\theta(x)-L_\theta(G(z)))_+
            \end{align*}
            其中：$(a)_+ = \max(a,0)$。
            \par
            \ding{173}对$\phi$的优化是在固定$\theta^*$的基础上，求
            \begin{align*}
            \min _\phi \ T(\theta^*,\phi) = \mathbb{E}_{z\sim p_z}L_{\theta^*}(G(z))
            \end{align*}
            注意到，当假样本$G(z)$的损失和真样本$x$的损失在约束范围内，即$L_\theta(x) - L_\theta(G(z))+\Delta (x,G(z))<0$时，$S(\theta,\phi^*)$第二项的损失为0。这使得当生成样本和真实样本很接近时，我们不必要求他们的$L$函数非得有一个固定间隔，因为这个时候生成的样本已经非常好了。这样LS-GAN就可以集中力量提高那些距离真实样本还很远，真实度不那么高的样本，这样就可以更合理的使用LS-GAN的建模能力。在后面，一旦限定了建模能力后，不用再担心模型的生成能力有损失了，这个我们称“按需分配”。图(\ref{fig:LSGAN-figure1})阐述了LS-GAN背后的“按需分配”的想法。
                \begin{figure}[H]
                \centering
                \includegraphics[width=10cm]{images/LSGAN-figure1.jpg}
                \caption{LSGAN-figure1}
                \label{fig:LSGAN-figure1}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：LSGAN-figure1}\\
            边界(magin)是为了区分真假样本，它不是一个固定的常数，它依赖于数据。当生成器生成越来越好的样本时，它会消失。假设真实密度函数$p_r$是lipschitz的，以便于证明结论。
            \par
            设$(\theta^*,\phi^*)$是上面优化问题的纳什均衡，我们可以得到，当$\lambda\to \infty$时，由$G_{\phi^*}$得到的密度$p_{G^*}$将收敛到真实分布$p_r$。为了证明这个结论，先进行如下定义
            \begin{definition}[Lipschitz 函数]
            对于任意的两个样本$x,z$，称损失函数$F(x)$是Lipschitz连续的，如果
            \begin{align*}
            |F(x) - F(z)| \leqslant k \Delta(x,z)
            \end{align*}
            其中：$k$为lipschitz常数，$k<\infty$；$\Delta$为距离度量。
            \end{definition}
            \par
            先将LS-GAN要建模的样本分布$p_r$限定在lipschitz密度上，即
            \begin{Assumption}[1]
            数据密度$p_r$有劲支撑集，且是Lipschitz连续的。
            \end{Assumption}
            \par
            对于Lipschitz密度，简言之，Lipschitz密度就是要求$p_r$不能变化的太快，密度的变化随着样本的变化不能无限的大，要有个度。不过这个都可以非常大，只要不是无限大就好。这个假设还是很弱的，大部分分布都满足之，比如：我们将一个图像调的稍微亮一些，它看上去仍然应该是真实的图像。在真实图像中，密度在lipschitz假设下不应该有突然的、剧烈的变化。
            \begin{lemma}[1]
            在假设1下，给定一个纳什均衡$(\theta^*,\phi^*)$，并且$p_{G^*}$是lipschitz连续的，有
            \begin{align*}
            \int_x|p_r(x) - p_{G^*}(x)|\mathrm{d}x \leqslant \frac{2}{\lambda}
            \end{align*}
            因此，当$\lambda\to \infty$时，$p_{G^*}$收敛到$p_r$。
            \end{lemma}
            \par
            在证明引理1之前，先给出如下引理
            \begin{lemma}[4]
            对于2个概率分布$p(x)$和$q(x)$，如果$p(x) \geqslant \eta q(x)$ a.e (almost everywhere)，有
            \begin{align*}
            \int_x|p(x) - q(x)|\mathrm{d}x \leqslant \frac{2(1-\eta)}{\eta}
            \end{align*}
            其中：$\eta\in (0,1]$。
            \end{lemma}
            \begin{Proof}
            我们有如下等式和不等式
            \begin{align*}
            & \int_x|p(x) - q(x)|\mathrm{d}x\\
            ={}&\int_x\mathbbm{1}_{[p(x)\geqslant q(x)]}(p(x)-q(x))\mathrm{d}x+\int_x \mathbbm{1}_{[p(x)<q(x)]}(q(x)-p(x))\mathrm{d}x\\
            ={}& \int_x \left( 1-\mathbbm{1}_{[p(x)<q(x)]} \right) (p(x) - q(x))\mathrm{d}x + \int_x \mathbbm{1}_{[p(x) - q(x)]}(q(x) - p(x))\mathrm{d}x\\
            ={}&2\int_x \mathbbm{1}_{[p(x)<q(x)]}(q(x)-p(x))\mathrm{d}x\\
            \geqslant{}&2 \left( \frac{1}{\eta} - 1 \right) \int_x \mathbbm{1}_{[p(x)<q(x)]}p(x)\mathrm{d}x\\
            \geqslant{}& \frac{2(1-\eta)}{\eta}
            \end{align*}
            $\square$
            \end{Proof}
            \par
            现在来证明引理1。
            \begin{Proof}
            假设$(\theta^*,\phi^*)$是优化问题$S,T$的一个纳什均衡，那么，一方面我们有
            \begin{align*}
            S(\theta^*,\phi^*) &\geqslant \mathbb{E}_{x\sim p_r} L_{\theta^*}(x)+\lambda \mathbb{E}_{x\sim p_r,z\sim p_z}(\Delta(x,G(z))+L_{\theta^*}(x) - L_{\theta^*}(G(z)))\\
            &=\int_xp_r(x)L_{\theta^*}(x)\mathrm{d}x +\lambda\mathbb{E}_{x\sim p_r,z\sim p_z}\Delta(x,G(z)) \\
            & \quad+\lambda\int_x p_r(x)L_{\theta^*}(x)\mathrm{d}x - \lambda\int_{G(z)}p_{G^*}(G(z))L_{\theta^*}(G(z))\mathrm{d} G(z)\\
            &= \int_x((1+\lambda)p_r(x) - \lambda p_{G^*}(x) )L_{\theta^*}(x)\mathrm{d}x+\lambda \mathbb{E}_{x\sim p_r,z\sim p_z}\Delta(x,G(z))
            \end{align*}
            上面的第一个不等式使用了$(a)_+ \geqslant a$。
            \par
            对于任意的$G_\phi$，我们也会有$T(\theta^*,\phi^*) \geqslant T(\theta^*,\phi)$，$\phi^*$是$T(\theta^*,\phi^*)$的最小点。特别地，可以将$T(\theta^*,\phi)$中的$p_{G}(x)$用$p_r(x)$替代，有
            \begin{align*}
            \int_x L_{\theta^*} (x)p_{G^*}(x)\mathrm{d}x \leqslant \int _x L_{\theta^*}(x)p_r(x)\mathrm{d}x
            \end{align*}
            对$S(\theta^*,\phi^*)$应用上述不等式，有
            \begin{align}
            \label{LS-GAN:eq0}
            S(\theta^*,\phi^*) &\geqslant \int_x p_r(x)L_{\theta^*}(x)\mathrm{d}x + \lambda \mathbb{E}_{x\sim p_r,z\sim p_z} \Delta(x,G(z))\notag \\
            & \geqslant \lambda \mathbb{E}_{x\sim p_r,z\sim p_z} \Delta(x,G(z))
            \end{align}
            上式得后一个不等式使用了$L_\theta(x)$非负的条件。
            \par
            另一方面，考虑一个具体的损失函数(loss funtion)
            \begin{align}
            \label{LS-GAN:eq1:具体的损失函数}
            L_\theta(x) = \alpha(-(1-\lambda)p_r(x) + \lambda p_g(x))_+
            \end{align}
            其中：$\alpha$是一个小的正常数。$L_\theta(x)$是一个非扩张函数(nonexpansive function)。根据$p_r,p_g$的Lipschitz连续假设，有
            \begin{align}
            \label{LS-GAN:eq2}
            \Delta(x,G(z)) + L_\theta(x) - L_\theta(G(z)) \geqslant 0
            \end{align}
            将$L_\theta(x)$代入到$S(\theta,\phi^*)$中，有
            \begin{align*}
            S(\theta,\phi^*) =& \int_x((1+\lambda)p_r(x) - \lambda p_g(x))L_\theta(x)\mathrm{d}x + \lambda \mathbb{E}_{x\sim p_r,z\sim p_z} \Delta(x,G^*(x))\\
            =& -\alpha\int_x(-(1-\lambda)p_r(x)+\lambda p_g(x))_+^2\mathrm{d}x +\lambda \mathbb{E}_{x\sim p_r,z\sim p_z}\Delta (x,G(z))
            \end{align*}
            第一个等式利用了式(\ref{LS-GAN:eq2})，第二个等式利用了式(\ref{LS-GAN:eq1:具体的损失函数})。假设$(1+\lambda)p_r(x) - \lambda p_{G^*}(x) < 0$在一个非零测度上，则上面的等式有一个严格上界
            \begin{align*}
            S(\theta^*,\phi^*) \leqslant S(\theta,\phi^*) < \lambda \mathbb{E}_{x\sim p_r,z\sim p_z}\Delta(x,G(z))
            \end{align*}
            这个结论与式(\ref{LS-GAN:eq0})相违背。因此，我们一定会有
            \begin{align*}
            p_r(x) \geqslant \frac{\lambda}{1+\lambda}p_{G^*}(x) \quad a.e
            \end{align*}
            利用引理4，有
            \begin{align*}
            \int_x|p_r(x) - p_{G^*}(x)|\mathrm{d}x \leqslant \frac{2}{\lambda}
            \end{align*}
            当$\lambda \to \infty$时，有
            \begin{align*}
            \int_x |p_r(x) - p_{G^*}(x)| \mathrm{d}x \to 0
            \end{align*}
            这证明了当$\lambda\to \infty$时，$p_{G^*}$收敛到$p_r$。$\square$
            \end{Proof}
            \begin{lemma}[2]
            在假设1下，存在一个纳什均衡$(\theta^*,\phi^*)$，并且$L_{\theta^*},p_{G^*}$是lipschitz连续的。
            \end{lemma}
            \par
            将引理1和引理2合并，有如下定理
            \begin{theorem}[Theorem 1]
            在假设1下，纳什均衡$(\theta*,\phi^*)$存在，并且
            \begin{enumerate}
            \item $L_{\theta^*}$和$p_{G^*}$是Lipschitz连续；
            \item $\int_x |p_r(x) - p_{G^*}(x)|\mathrm{d}x \leqslant \frac{2}{\lambda}\to 0$,a.s，$\lambda\to \infty$；
            \item $p_r(x) \geqslant \frac{\lambda}{1+\lambda} p_{G^*}(x)$。
            \end{enumerate}
            \end{theorem}
            \par
            上述定理说明，当把$L$函数限定在Lipschitz连续的函数类上时，得到$p_{G^*}(x)$和$p_r$是完全一致的，前面的WGAN在对距离/散度$f$函数做出Lipschitz连续约束后，其实也是将生成样本的密度假设为lipschitz密度。
        \subsubsection{LS-GAN程序}
            \par
            用批量方法来计算LS-GAN的梯度。设$\mathcal{X} = \{x_1,x_2,\dots,x_m\}$是从真实分布$p_r$中采集的$m$个样本；$\mathcal{Z}_m = \{z_1,z_2,\dots,z_m\}$是从$p_z$中采集到的$m$个样本，并且通过G，会有$m$个假样本$\{G(z_i)\}_{i=1}^m$。我们的优化模型是
            \begin{align*}
            \min_\theta\ S_m (\theta,\phi^*) &= \frac{1}{m} \sum_{i=1}^m L_\theta(x_i) + \frac{\lambda}{m}\sum_{i=1}^m(\Delta(x_i,G_{\phi^*}(z_i))+L_\theta(x_i) - L_\theta(G_{\phi^*}(z_i)))_+
            \end{align*}
            和
            \begin{align*}
            \min_\phi \ T_k(\theta^*,\phi) = \frac{1}{k} \sum_{i=1}^k L_{\theta^*}(G_\phi(z_i'))
            \end{align*}
            其中：随机向量$z_k' = \{z_1',z_2',\dots,z_k'\}$可以与$z_m$不同。
            \par
            LS-GAN的伪代码如(\ref{code:LS-GAN})所示，LS-GAN的Lua程序可以参考\footnote{https://github.com/guojunq/lsgan}。
            \begin{algorithm}[htbp]
                \caption{Learning algorithm for LS-GAN.}\label{code:LS-GAN}
                \begin{algorithmic}[1]
                    \State 初始化：超参数$\lambda$；迭代数$t$，$t_{max}$；判别器训练次数$n_D$；批量大小$m$。
                    \For {$t=1,2,\dots,t_{max}$}
                        \For {$n_D$ step }
                            \State $//$更新损失函数
                            \State Sample a minibatch from $\mathcal{X}_m$；
                            \State Sample a minibatch form $\mathcal{Z}_m$；
                            \State 更新损失函数$L_\theta$
                            \begin{align*}
                            \min_\theta\ S_m (\theta,\phi^*) &= \frac{1}{m} \sum_{i=1}^m L_\theta(x_i) + \frac{\lambda}{m}\sum_{i=1}^m(\Delta(x_i,G_{\phi^*}(z_i))+L_\theta(x_i) - L_\theta(G_{\phi^*}(z_i)))_+
                            \end{align*}
                        \EndFor
                        \State Sample a set of $z_k'$ of $k$ random noises;
                        \State 更新生成器G
                        \begin{align*}
                        \min_\phi \ T_k(\theta^*,\phi) = \frac{1}{k} \sum_{i=1}^k L_{\theta^*}(G_\phi(z_i'))
                        \end{align*}
                    \EndFor
                \end{algorithmic}
            \end{algorithm}
        \subsubsection{泛化能力 generalization ability}
            \par
            上面证明了$p_G\triangleq p_g$收敛到真实密度$p_r$，但这是建立在$p_r,p_g$的期望可以被直接计算。但可惜的是，在实际算法中，并不能直接计算期望$\mathbb{E}_{p_r},\mathbb{E}_{p_g}$，只能对其做数值上的近似，这依赖于样本数目$m,k$。我们自然知道，当样本数目$m,k$很大时，可以很到的近似期望$\mathbb{E}_{p_r},\mathbb{E}_{p_g}$。现在，我们好奇的是，增加样本的量，$p_G$是否会收敛到$p_r$。并且，我们也希望知道多少样本$m,k$是合适的。
            \par
            首先考虑从$S(\theta,\phi^*)$的泛化能力。$S(\theta,\phi^*)$的目标是训练一个损失函数$L_\theta$，因此，它会告诉我们一个训练好的损失函数是否可以泛化。在给定$G_{\phi^*}$后，考虑真实的目标
            \begin{align*}
            S = \min_\theta \ S(\theta,\phi^*)
            \end{align*}
            和实验(算法)中的目标
            \begin{align*}
            S_m = \min_\theta \ S_m(\theta,\phi^*)
            \end{align*}
            我们要研究随着样本量$m$的增加，距离$|S_m - S|$是否有界以及如何使它有界。如果LS-GAN是可以泛化的，在中等样本数量时，距离$|S_m-S|$应该以概率收敛到0。如果LS-GAN不可以泛化，$S_m$和$S$之间会有一个非0的间隙，这意味着LS-GAN对实验样本是过拟合的，它不能推广到真实分布$p_r$。
            \par
            为了说明泛化能力，我们先给出损失函数空间的假设以及它的domain。
            \begin{Assumption}[2]
            1.损失函数$L_\theta(x)$对参数$\theta$是$k_L$-lipschitz的，即
            \begin{align*}
            |L_\theta(x) - L_{\theta'}(x)| \leqslant k_L||\theta-\theta'|| \quad \forall x
            \end{align*}
            2.损失函数$L_\theta(x)$对$x$是$k$-lipschitz的，即
            \begin{align*}
            |L_\theta(x) - L_\theta(x')| \leqslant k||x-x'||
            \end{align*}
            3.2个样本的距离是有界的，即
            \begin{align*}
            |\Delta (x,x')| \leqslant B_\Delta
            \end{align*}
            \end{Assumption}
            \par
            由上面的假设2，有如下定理
            \begin{theorem}[2]
            在假设2下，给定概率$1-\eta$，当样本数量
            \begin{align*}
            m \geqslant \frac{CNB_\Delta(k+1)^2 \log(k_LN/\eta\varepsilon)}{\varepsilon^2}
            \end{align*}
            时，有
            \begin{align*}
            |S_m - S| \leqslant \varepsilon
            \end{align*}
            其中：$C$是一个足够大的常数，$N$是loss function的参数个数。
            \end{theorem}
            \par
            下面，我们来证明上述定理。为简单，下面我们忽略$S(\theta,\phi^*),S_m(\theta,\phi^*)$的第一部分，因为在$\lambda\to +\infty$时，第一部分会消失。并且，如果将第一部分考虑进来，下面的证明也只会有一点点的变化。为了证明定理2，我们需要如下引理：
            \begin{lemma}[6]
            \label{LS-GAN：引理6}
            对所有损失函数$L_\theta$，给定概率$1-\eta$，当样本数量$m$为
            \begin{align*}
            m \geqslant \frac{CNB_\Delta(k+1)^2 \log(k_LN/\eta\varepsilon)}{\varepsilon^2}
            \end{align*}
            有
            \begin{align*}
            |S_m(\theta,\phi^*) - S(\theta,\phi^*)| \leqslant \varepsilon
            \end{align*}
            其中：$C$是一个足够大的常数。
            \end{lemma}
            \par
            上述引例的证明需要运用MCdiarmid不等式，$(\cdot)_+$是1-lipschitz的以及$|S_m(\theta,\phi^*) - S(\theta,\phi^*)|$有界。然后，为了得到所有损失函数界(bound)的union，一个标准的$\epsilon$-net将会被构建，以产生有限的点，这些有限点是足够稠密的，能够覆盖损失函数的参数空间。
            \begin{Proof}
            考虑损失函数$L_\theta$，并从真实分布$p_r$和重构分布$p_{G^*}$中采集$m$个样本$\{x_i,z_{G_i}\}_{i=1}^m$以计算$S_m(\theta,\phi^*)$。为了应用McDiarmid不等式，当一个样本改变时，我们需要限定函数改变的界，当第$j$个样本被$x_i'$和$z_{G_i}'$替代时，我们用$S_m^i(\theta,\phi^*)$表示，那么，我们有
            \begin{align*}
            &|S_m(\theta,\phi^*) - S^i_m(\theta,\phi^*)|\\
            ={}&\frac{1}{m} |(\Delta(x_i,z_{G_i})+L_\theta(x_i) - L_\theta(z_{G_i}))_+ - (\Delta(x_i',z_{G_i}')+ L_\theta(x_i') - L_\theta(z_{G_i}'))_+|\\
            \leqslant{}&\frac{1}{m}|\Delta(x_i,z_{G_i})-\Delta(x_i',z_{G_i}')| + \frac{1}{m}|L_\theta(x_i) - L_\theta(x_i')  | + \frac{1}{m}|L_\theta(z_{G_i}) - L_\theta(z_{G_i}')| \\
            \leqslant {}&\frac{1}{m}(2B_\Delta+k\Delta(x_i,x_i')+k\Delta(z_{G_i},z_{G_i}'))\\
            \leqslant{}&\frac{2}{m}(1+k)B_\Delta
            \end{align*}
            第一个不定式使用了$(\cdot)_+$是1-lipschitz的事实；第二个不等式使用了$\Delta(x,z_G)$是被$B_\Delta$界限的，并且$L_\theta(x)$关于$x$是k-lipschitz的。
            \par
            现在，我们可以使用McDiarmid不等式了。注意到
            \begin{align*}
            S(\theta,\phi^*) = \mathbb{E}_{\substack{x_i\sim p_r\\z_{G_i}\sim p_G\\
            i=1,2,\dots,m}} S_m(\theta,\phi^*)
            \end{align*}
            有
            \begin{align*}
            P\{|S_m(\theta,\phi^*) - S(\theta,\phi^*)| \geqslant \varepsilon /2\} \leqslant 2\exp \left\{- \frac{\varepsilon^2m}{8(1+k)^2B_\Delta^2}  \right\}
            \end{align*}
            上述所述的界适用于单一损失函数$L_\theta$，为了得到联合边界(union bound)，我们考虑一个$\varepsilon/8k_L$-net$\mathcal{N}$，即对任意的$L_\theta$，在网络中都有一个$\theta'\in \mathcal{N}$，使得
            \begin{align*}
            ||\theta-\theta'|| \leqslant \varepsilon/8 k_L
            \end{align*}
            这个标准的网络可以被建立用来容纳有限的损失函数，使得$|\mathcal{N} |\leqslant O(N\log (k_LN/\varepsilon))$，其中：$N$是损失函数的个数。
            \par
            因此，给定概率$1-\eta$，for all $\theta\in \mathcal{N}$，我们有如下联合边界
            \begin{align*}
            |S_m(\theta,\phi^*) - S(\theta,\phi^*)| \leqslant \frac{\varepsilon}{2}
            \end{align*}
            当
            \begin{align*}
            m \geqslant \frac{CNB_\Delta^2(k+1)^2\log (k_LN/\eta\varepsilon)}{\varepsilon^2}
            \end{align*}
            \par
            最后一步是在更广泛的$\mathcal{N}$上找到所有损失函数的联合边界，为此，我们考虑如下不等式
            \begin{align*}
            &|S(\theta,\phi^*)-S(\theta',\phi^*)|\\
            ={}&|\mathbb{E}_{\substack{x\sim p_r\\z_G\sim p_G}}(\Delta(x,z_G)+L_\theta(x)-L_\theta(z_G) )_+ -\mathbb{E}_{\substack{x\sim p_r\\z_G\sim p_G} }(\Delta(x,z_G)+L_{\theta'}(x) - L_{\theta'}(z_G))_+  |\\
            \leqslant{}& \mathbb{E}_{x\sim p_r}|L_\theta(x) - L_{\theta'}(x)|+\mathbb{E}_{z_G\sim p_G}| L_\theta(z_G) - L_{\theta'}(z_G) |\\
            \leqslant {}& 2k_L||\theta - \theta '||
            \end{align*}
            这里第一个不等式使用了$(\cdot)_+$是1-lipschitz的事实，第二个不等式使用了$L_\theta$关于$\theta$是$k_L$-lipschitz。同样的，我们有
            \begin{align*}
            |S_m(\theta,\phi^*) - S_m(\theta',\phi^*)| \leqslant 2 k_L||\theta-\theta'||
            \end{align*}
            \par
            现在，我们能够获得所有损失函数的联合边界。对任意的 $\theta$，通过构建还可以找到一个$\theta'\in \mathcal{N}$，使得$||\theta-\theta'|| \leqslant \varepsilon/8k_L$。并且，给定概率$1-\eta$后，有
            \begin{align*}
            |S_m(\theta,\phi^*) - S(\theta,\phi^*)| &\leqslant |S_m(\theta,\phi^*) - S_m(\theta',\phi^*)|\\
            & \quad + |S_m(\theta,\phi^*) - S(\theta',\phi^*)| +  |S(\theta',\phi^*) - S_m(\theta,\phi^*)| \\
            & \leqslant 2k_L||\theta-\theta'|| + \frac{\varepsilon}{2}+2k_L||\theta-\theta'||\\
            & \leqslant \frac{\varepsilon }{4} +\frac{\varepsilon}{2}+\frac{\varepsilon}{4} = \varepsilon
            \end{align*}
            由此，证明了引理6。
            $\square$
            \end{Proof}
            \par
            下面来证明定理2
            \begin{Proof}
            首先限制$S_m - S$。考虑$L_{\theta^*}$最小化$S(\theta,\phi^*)$，给定概率$1-\eta$，当
            \begin{align*}
            m \geqslant \frac{CNB_\Delta^2(k+1)^2\log (k_LN/\eta\varepsilon)}{\varepsilon^2}
            \end{align*}
            有
            \begin{align*}
            S_m - S \leqslant S_m(\theta^*,\phi^*) - S(\theta^*,\phi^*) \leqslant \varepsilon
            \end{align*}
            这里第一个不等式使用了$S_m \leqslant S_m(\theta^*,\phi^*)$，$\theta^*$可能不使$S_m$最小；第二个不等式直接使用上面的引理6。同样，可以证明另一个direction，给定概率$1-\eta$，有
            \begin{align*}
            S-S_m \geqslant S(\theta^*,\phi^*) - S_m(\theta^*,\phi^*) \geqslant \varepsilon
            \end{align*}
            $\square$
            \end{Proof}
            \par
            相似的，能够获得目标$T(\theta,\phi)$的泛化能力。考虑
            \begin{align*}
            T_k = \min_\phi \ T_k(\theta^*,\phi)
            \end{align*}
            和
            \begin{align*}
            T = \min_\phi \ T(\theta^*,\phi)
            \end{align*}
            仍然需要考虑生成函数空间的假设以及它们的domain。
            \begin{Assumption}[3]
            1.生成函数$G_\phi(x)$关于参数$\phi$是$\rho_G$-lipschitz的，即
            \begin{align*}
            |G_\phi(z) - G_{\phi'}(z)| \leqslant \rho_G||\phi - \phi'||\quad \forall z
            \end{align*}
            2.$G_\phi(z)$关于$z$是$\rho$-lipschitz的，即
            \begin{align*}
            |G_\phi(z) - G_\phi(z')| \leqslant \rho||z - z'||
            \end{align*}
            3.来自$p_z$的样本$z$是有界的，即
            \begin{align*}
            ||z|| \leqslant B_z
            \end{align*}

            \end{Assumption}
            \par
            根据假设3，我们有关于$T(\theta,\phi)$的泛化定理
            \begin{theorem}[3]
            给定概率$1-\eta$，当样本数量
            \begin{align*}
            k \geqslant \frac{C'MB_z^2k^2\rho^2\log(k_L\rho_GM/\eta\varepsilon)}{\varepsilon^2}
            \end{align*}
            有
            \begin{align*}
            |T_k - T| \leqslant \varepsilon
            \end{align*}
            其中：$G'$是足够大的常数，$M$是生成函数的参数个数。
            \end{theorem}
        % \subsubsection{非参数分析}
        %     \par
        \subsubsection{GLS-GAN}
            \par
            前面提到过WGAN使用EM距离来替代原始GAN中的JS散度，这个EM距离的特点就是：即使D完美分割真假样本，EM距离也不会为0，仍然可以为G提供梯度以进行训练。现在，我们断言WGAN也是建立在Lipschitz密度上的，为了证明此断言，将WGAN记为
            \begin{align*}
            f_w^* & = \arg\max_{f_w\in \mathcal{F}_1} \ U(f_w,g_\phi^*)\\
            & \triangleq \mathbb{E}_{x\sim p_r}[f_w(x)] - \mathbb{E}_{z\sim p_z}[f_w(g_\phi^*(z))]
            \end{align*}
            以及
            \begin{align*}
            g_\phi^* = \arg\max \ V(f_w^*,g_\phi) \triangleq \mathbb{E}_{z\sim p_z}[f_w^*(g_\phi(z))]
            \end{align*}
            这里$f,g$函数分别是WGAN的批评函数(critics)和G网络。批评函数是WGAN里的概念，对应GAN的D，其数值越大，则样本真实度越高。
            \par
            设$p_{g_\phi^*}$是由$g_\phi^*$产生的分布密度，我们有如下引理
            \begin{lemma}[3]
            在假设1下，给的WGAN的解$(f_w^*,g_\phi^*)$，并且设定$p_{g_\phi}*$是lipschitz的，有
            \begin{align*}
            \int _x |p_r(x) - p_{g_\phi^*}(x)|\mathrm{d}x = 0
            \end{align*}
            \end{lemma}
            \par
            上述引理表明，WGAN和LS-GAN都是建立在相同的lipschitz条件上的。WGAN在对$f$函数做出lipschitz连续约束后(即生成样本密度$p_{g_\phi^*}$为lipschitz密度)，$p_{g_\phi^*}$收敛到$p_r(x)$。
            \begin{Proof}
            假设$(f_w^*,g_\phi^*)$是WGAN的解。一方面，我们有
            \begin{align*}
            U(f_w^*,g_\phi^*) = \int_x f_w^*(x)p_r(x)\mathrm{d}x - \int_xf_w^*(x)p_{g_\phi^*}(x)\mathrm{d}x <0
            \end{align*}
            这里的不等式使用了$V(f_w^*,g_\phi^*) \geqslant V(f_w^*,g_\phi)$(使用$p_r(x)$来替代$p_{g_\phi}(x)$)。考虑一个特例：$f_w(x) \triangleq \alpha(p_r(x)-p_{g_\phi^*}(x))_+$，因为我们假设$p_r(x),p_{g_\phi^*}(x)$是lipschitz，当$\alpha$很小时，$f_w(x)\in L_1$。将$f_w(x)$带入到$U(f_w,g_\phi^*)$，我们有
            \begin{align*}
            U(f_w,g_\phi^*) = \alpha\int_x (p_r(x) - p_{g_{\phi^*}}(x))_+^2\mathrm{d}x
            \end{align*}
            假设$p_r(x) >p_{g_\phi^*}(x)$在一个非零测度上，有
            \begin{align*}
            U(f_w^*,g_\phi^*) \geqslant U(f_w,g_\phi^*) \geqslant 0
            \end{align*}
            这和$U(f_w^*,g_\phi^*) \leqslant 0$相矛盾，所以必有
            \begin{align*}
            p_r(x) \leqslant p_{g_\phi^*}(x) \quad a.e.
            \end{align*}
            再使用引理4，有
            \begin{align*}
            \int_x |p_r(x) -p_{g_\phi^*(x)}|\mathrm{d}x = 0
            \end{align*}
            $\square$
            \end{Proof}
            \par
            在证明引理1时，仅使用了$(a)_+$的两个性质：\ding{172}$(a)_+ \geqslant a$ for any $a$；\ding{173}$(a)_+ = a$ for $a \geqslant 0$。其实这可以用任意的代价函数$C(a)$来代替$(a)_+$，只要$C(a)$满足$(a)_+$上面的两个性质。将$C(a)$引出的LS-GAN称为GLS-GAN。非常有意思的是，LS-GAN和WGAN是GLS-GAN的2个特例。
            \par
            形式上，如果代价函数$C(a)$满足
            \begin{enumerate}
            \item $C(a) \geqslant a$ for any $a\in R$;
            \item $C(a) = a$ for any $a\in R^+$.
            \end{enumerate}
            则引理1关于$p_r,p_g$一致的结论仍然成立。新的GLS-GAN就是在这样一个代价函数$C$下，求解损失$L_\theta$。给定一个$G_\phi^*$，我们使用如下目标
            \begin{align*}
            S_C(\theta,\phi^*) = \mathbb{E}_{x\sim p_r,z\sim  p_z} C(\Delta(x,G_{\phi^*}(z))+L_\theta(x) - L_\theta(G_{\phi^*}(z)))
            \end{align*}
            来训练$L_\theta(x)$。这里$S_C$高度依赖代价函数$C$。为简单，我们在$S_C$中仅考虑$S(\theta,\phi^*)$的第二项
            \begin{align*}
            S(\theta,\phi^*) = \mathbb{E}_{x\sim p_r}(x) + \lambda\mathbb{E}_{x\sim p_r,z\sim p_z}(\Delta(x,z_G)+L_\theta(x) -L_\theta(z_G))_+
            \end{align*}
            。但是，这并不影响结论，因为当$\lambda\to \infty$时，$S(\theta,\phi^*)$第一项将消失。
            \par
            在引理1下，可以证明如下引理
            \begin{lemma}[5]
            在假设1下，给的$S_C(\theta,\phi^*)$和$T(\theta^*,\phi)$的一个纳什均衡$(\theta^*,\phi^*)$，并假设代价函数$C(a)$满足2个条件，有
            \begin{align*}
            \int _x|p_r(x) - p_{G^*}(x)|\mathrm{d}x = 0
            \end{align*}
            \end{lemma}
            \par
            在给定损失函数$L_{\theta^*}$下，求解$G_\phi$的方法和LS-GAN是一样的
            \begin{align}
            \min_\phi \ \mathbb{E}_{z\sim p_z} L_{\theta^*}(G_\phi(z))
            \end{align}
            \par
            至此，GLS-GAN的核心思想就介绍完了。下面，给出具体的例子。什么代价函数$C(a)$满足2个条件？一个显然的选择是 Leaky Rectifical linear，即$C_v(a) = \max(a,va)$(含参数$v$的Leaky Rectifical linear)，参数$v$在区间$(-\infty,1]$上。现在来说明LS-GAN和WGAN是GLS-GAN的特例：
            \ding{172}可以发现，当$v=0$时$C_0(a) = (a)_+$，有
            \begin{align*}
            LS-GAN = GLS-GAN(C_0)
            \end{align*}
            \ding{173} 当$v=1$时，有$C_1(a) = a$，带入$S_C(\theta,\phi^*)$，有
            \begin{align*}
            S_{C_1}(\theta,\phi^*) &= \mathbb{E}_{x\sim p_r,z\sim p_z} (\Delta (x,G_{\phi^*}(z))+L_\theta(x) - L_\theta(G_{\phi^*}(z)))\\
            &=\mathbb{E}_{x\sim p_r} L_\theta(x) - \mathbb{E}_{z\sim p_z}L_\theta(G_{\phi^*}(z)) + \mathbb{E}_{\substack{x\sim p_r\\z\sim p_z}}(\Delta(x,G_{\phi^*}(z)))
            \end{align*}
            上式得最后一项是一个和损失函数$L_\theta$有关的常数项，可以忽略。于是，我们有
            \begin{align*}
            S_{C_1}(\theta,\phi^*) = \mathbb{E}_{x\sim p_r}L_\theta(x) - \mathbb{E}_{z\sim p_z}L_\theta(G_{\phi^*}(z))
            \end{align*}
            上式是WGAN的目标，所以有
            \begin{align*}
            WGAN = GLS-GAN(C_1)
            \end{align*}
            \par
            这说明在WGAN和LS-GAN之间，有一大片的空白区域$GLS_GAN(C_v)$等待我们去发掘。虽然理论上分析GLS-GAN可以产生和真实样本已知的密度，但实际如何还有待验证。
            \par
            既然作为特例的WGAN和LS-GAN都取得了不错的成绩，我们有理由相信GLS-GAN也会取得不凡的表现。更广泛的，可以采取非LeakReLU的代价函数，来构架GLS-GAN。比如，可以尝试$\alpha\in [0,1]$的Exponential Linear Unit (ELU)
            \begin{align*}
            C_\alpha(a) = \max (0,a)+\min(0,\alpha(e^\alpha-1))
            \end{align*}
            GLS-GAN的程序可以参考\footnote{https://github.com/guojunq/glsgan}。

    \subsection{Coupled GAN}
        \subsubsection{CoGAN模型建立}
            \par
            原始GAN的训练过程面临着训练不稳定的困难。Coupled GAN 为了克服这个问题，在模型中设置了2个GAN，在求解梯度时，将2个GAN(G和D)的梯度求平均，作为最终的梯度。
            \par
            将G和D设置为多层传感器结构，对G而言，2个$G_1,G_2$的感知器层数为$m_1,m_2$，并且不要求$m_1 = m_2$
            \begin{align*}
            G_1(z) = g_1^{(m_1)}(g_1^{(m_1-1)}(\cdots g_1^{(2)}(g_1^{(1)}(z))))\\
            G_2(z) = g_2^{(m_1)}(g_2^{(m_1-1)}(\cdots g_2^{(2)}(g_2^{(1)}(z))))
            \end{align*}
            设其中权重为
            \begin{align*}
            \theta_{g_1}^{(i)}\quad \theta_{g_2}^{(j)} \quad i=1,2\dots m_1\quad j=1,2\dots m_2
            \end{align*}
            我们不必要求所有层的权重梯度都求平均，只需要几层(例如：$k$层求平均)。同样的方法处理D网络，2个D的层数设为$n_1,n_2$
            \begin{align*}
            D_1(x_1) = f_1^{(n_1)}(f_1^{(n_1-1)}(\cdots f_1^{(2)}(f_1^{(1)}(x_1))))\\
            D_2(x_2) = f_2^{(n_1)}(f_2^{(n_1-1)}(\cdots f_2^{(2)}(f_2^{(1)}(x_2))))
            \end{align*}
            设其中权重为
            \begin{align*}
            \theta_{f_1}^{(i)}\quad \theta_{f_2}^{(j)} \quad i=1,2\dots n_1\quad j=1,2\dots n_2
            \end{align*}
            并设定共有$l$层要共享权重。Coupled GAN的目标设置为
            \begin{align*}
            \min_{G_1,G_2}\ \max_{D_1,D_2} \ \mathbb{E}_{x_1\sim p_{r1}} [\log D_1(x_1)] + \mathbb{E}_{z\sim p_z}[\log (1-D_1(G_1(z)))] \\
            +\mathbb{E}_{x_2\sim p_{r2}} [\log D_2(x_2)] + \mathbb{E}_{z\sim p_z}[\log (1-D_2(G_2(z)))]
            \end{align*}
            其网络结构如图(\ref{fig:Coupled GAN网络结构图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/Coupled_GAN_network.jpg}
                \caption{Coupled GAN网络结构图}
                \label{fig:Coupled GAN网络结构图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：Coupled GAN网络结构图}
        \subsubsection{CoGAN程序}
            \par
            CoGAN的伪代码如(\ref{code:CoGAN})所示，
            \begin{algorithm}[htbp]
                \caption{Mini-batch stochastic gradient descent for training CoGAN.}\label{code:CoGAN}
                \begin{algorithmic}[1]
                    \State 初始化：网络参数$\theta_{f_1^{(i)}},\theta_{f_2^{(i)}},\theta_{g_1^{(i)}},\theta_{g_s^{(i)}}$；$t,t_{max}$；批量大小$N$。
                    \For {$t=1,2,\dots,t_{max}$}
                        \State 从$p_z$中选取$N$个样本$\{z^1,z^2,\dots,z^N\}$；
                        \State 从$p_{r1}$中选取$N$个样本$\{x_1^1,x_1^2,\dots,x_1^N\}$；
                        \State 从$p_{r2}$中选取$N$个样本$\{x_2^1,x_2^2,\dots,x_2^N\}$；
                        \State 计算判别器$f_1^t$参数的梯度
                        \begin{align*}
                        \nabla_{\theta_{f_1^{(i)}}} \frac{1}{N}\sum_{j=1}^N - \log f_1^t(x_1^j) - \log (1-f_1^t(g_1^t(z^j)))
                        \end{align*}
                        \State 计算判别器$f_2^t$参数的梯度
                        \begin{align*}
                        \nabla_{\theta_{f_2^{(i)}}} \frac{1}{N}\sum_{j=1}^N - \log f_2^t(x_2^j) - \log (1-f_2^t(g_2^t(z^j)))
                        \end{align*}
                        \State 两个判别器之间进行参数平均共享。
                        \State 根据参数的梯度更新判别器$f_1^{t+1}$和$f_2^{t+1}$。
                        \State 计算生成器$g_1^t$参数的梯度
                        \begin{align*}
                        \nabla_{\theta_{g_1^{(i)}}} \frac{1}{N}\sum_{j=1}^N  - \log (1-f_1^{t+1}(g_1^t(z^j)))
                        \end{align*}
                        \State 计算判别器$f_2^t$参数的梯度
                        \begin{align*}
                        \nabla_{\theta_{g_2^{(i)}}} \frac{1}{N}\sum_{j=1}^N - \log (1-f_2^{t+1}(g_2^t(z^j)))
                        \end{align*}
                        \State 两个生成器之间进行参数平均共享。
                        \State 根据参数的梯度更新生成器$g_1^{t+1}$和$g_2^{t+1}$。
                    \EndFor
                \end{algorithmic}
            \end{algorithm}
            \par
            CoGAN的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            import scipy.ndimage.interpolation
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            mb_size = 32
            X_dim = mnist.train.images.shape[1]
            y_dim = mnist.train.labels.shape[1]
            z_dim = 10
            h_dim = 128
            eps = 1e-8
            lr = 1e-3
            d_steps = 3
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X1 = tf.placeholder(tf.float32, shape=[None, X_dim])
            X2 = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G1_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G1_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            G2_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G2_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            def G(z):
                h = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G1 = tf.nn.sigmoid(tf.matmul(h, G1_W2) + G1_b2)
                G2 = tf.nn.sigmoid(tf.matmul(h, G2_W2) + G2_b2)
                return G1, G2
            D1_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D1_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D2_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D2_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D_b2 = tf.Variable(tf.zeros(shape=[1]))
            def D(X1, X2):
                h1 = tf.nn.relu(tf.matmul(X1, D1_W1) + D1_b1)
                h2 = tf.nn.relu(tf.matmul(X2, D2_W1) + D2_b1)
                D1_out = tf.nn.sigmoid(tf.matmul(h1, D_W2) + D_b2)
                D2_out = tf.nn.sigmoid(tf.matmul(h2, D_W2) + D_b2)
                return D1_out, D2_out
            theta_G = [G1_W2, G2_W2, G1_b2, G2_b2]
            theta_G_shared = [G_W1, G_b1]
            theta_D = [D1_W1, D2_W1, D1_b1, D2_b1]
            theta_D_shared = [D_W2, D_b2]
            # Train D
            G1_sample, G2_sample = G(z)
            D1_real, D2_real = D(X1, X2)
            D1_fake, D2_fake = D(G1_sample, G2_sample)
            D1_loss = -tf.reduce_mean(tf.log(D1_real + eps) + tf.log(1. - D1_fake + eps))
            D2_loss = -tf.reduce_mean(tf.log(D2_real + eps) + tf.log(1. - D2_fake + eps))
            D_loss = D1_loss + D2_loss
            # Train G
            G1_loss = -tf.reduce_mean(tf.log(D1_fake + eps))
            G2_loss = -tf.reduce_mean(tf.log(D2_fake + eps))
            G_loss = G1_loss + G2_loss
            # D optimizer
            D_opt = tf.train.AdamOptimizer(learning_rate=lr)
            # Compute the gradients for a list of variables.
            D_gv = D_opt.compute_gradients(D_loss, theta_D)
            D_shared_gv = D_opt.compute_gradients(D_loss, theta_D_shared)
            # Average by halfing the shared gradients
            D_shared_gv = [(0.5 * x[0], x[1]) for x in D_shared_gv]
            # Update
            D_solver = tf.group(
                D_opt.apply_gradients(D_gv), D_opt.apply_gradients(D_shared_gv)
            )
            # G optimizer
            G_opt = tf.train.AdamOptimizer(learning_rate=lr)
            # Compute the gradients for a list of variables.
            G_gv = G_opt.compute_gradients(G_loss, theta_G)
            G_shared_gv = G_opt.compute_gradients(G_loss, theta_G_shared)
            # Average by halfing the shared gradients
            G_shared_gv = [(0.5 * x[0], x[1]) for x in G_shared_gv]
            # Update
            G_solver = tf.group(
                G_opt.apply_gradients(G_gv), G_opt.apply_gradients(G_shared_gv)
            )
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            X_train = mnist.train.images
            half = int(X_train.shape[0] / 2)
            # Real image
            X_train1 = X_train[:half]
            # Rotated image
            X_train2 = X_train[half:].reshape(-1, 28, 28)
            X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=(1, 2))
            X_train2 = X_train2.reshape(-1, 28*28)
            # Cleanup
            del X_train
            def sample_X(X, size):
                start_idx = np.random.randint(0, X.shape[0]-size)
                return X[start_idx:start_idx+size]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                X1_mb, X2_mb = sample_X(X_train1, mb_size), sample_X(X_train2, mb_size)
                z_mb = sample_z(mb_size, z_dim)
                _, D_loss_curr = sess.run(
                    [D_solver, D_loss],
                    feed_dict={X1: X1_mb, X2: X2_mb, z: z_mb}
                )
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss], feed_dict={z: z_mb}
                )
                if it % 1000 == 0:
                    sample1, sample2 = sess.run(
                        [G1_sample, G2_sample], feed_dict={z: sample_z(8, z_dim)}
                    )
                    samples = np.vstack([sample1, sample2])
                    print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'
                          .format(it, D_loss_curr, G_loss_curr))
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}

    \subsection{Dual GAN}
        \subsubsection{Dual GAN模型建立}
            \par
            下面，主要考虑条件GAN，因为很多计算机视觉的问题都可以被看成是一种“图片翻译”问题。例如，一张人脸的照片以及与之对应的一张素描之间的相互转换就可以看成是从一张图片“翻译”为另外一张图片(我们可以将素描图片作为生成器$G$的输入的一部分)。事实上，更一般的，边界探测、图像分割、图片的风格化和抽象化等等都可以被视为是这样一种“翻译”问题。
            \par
            而说到“翻译”，很容易会想到其在自然语言处理领域中的一些应用。近年来在机器翻译领域也有许多有意思的新进展。其中一种新的做法是对偶学习(dual learning)，这种学习的方式为解决无监督学习中遇到的困难提供了新的思路。简要介绍一下这种学习方法的基本思路：假如现在小明只能讲中文， Alice 只会讲英文，他们两个人虽然都不懂对方的语言，但是他们希望能够可以中英文之间的两个翻译模型(中译英，英译中)。怎样可以实现他们的这个目的呢？首先，对于一个英文的句子，Alice 先用翻译工具将其翻译为中文，由于她并不懂中文，于是她直接把句子发给了小明；但小明又不懂英文，于是小明只能按照中文的语言习惯判断这个句子是否通顺，这可以帮助小明判断这个“英译中”的系统是否做得很好，随后，小明把他修改过的句子再用“中译英”的系统翻译成英文，并把英文句子发给 Alice。Alice 虽然不懂中文，但她能比较经过这一大圈的翻译之后，得到的新句子与最初的版本是否相似。这一信息可以帮助判断是否两个翻译模型都表现良好。随着“对偶学习”过程的持续进行，未标注的数据也得到了充分的利用，利用这些信息，可以帮助提高对偶任务中的两个翻译模型。这种对偶学习的想法为进一步改进现有的翻译模型提出了崭新的思路。如果把这种对偶学习的方法也用到基于GAN的图片的“翻译”上，会得到怎样的效果呢？这会是一个非常有趣的问题。
            \par
            DualGAN 算法就是将基本的 GAN 再进一步扩展为两个相互耦合的的 GAN，其中存在着两个生成器和两个判别器。如图(\ref{fig:DualGAN结构示意图})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=14cm]{images/DualGAN_structure.jpg}
                \caption{DualGAN结构示意图}
                \label{fig:DualGAN结构示意图}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：DualGAN结构示意图}\\
            以素描与照片之间的相互“翻译”为例。设$U$为素描图像集，$V$为照片图像集，原始任务是学习一个生成器$G_A:U\rightarrow V$，$G_A$是从素描$u\sim U$到照片$v\sim V$的映射。与这个生成器对应的有一个判别器 $D_A$，二者构成第一个GAN。与原始任务相对应，存在一个对偶任务：训练一个生成器 $G_B:V\rightarrow U$，将照片转换为素描，与这个生成器所对应的同样有一个判别器 $D_B$，二者形成了第二个GAN(对偶GAN)。
            \par
            在这样的基本框架下，接下来考虑怎样利用对偶学习的思路训练 GAN。首先介绍“生成”的思路，通过生成器$ G_A $可以对素描图片$ u$ 进行翻译，最终得到类似照片的图片，其中包含的噪声为$ z$，翻译的结果即为 $G_A(u,z)$ ，把这个翻译的结果扔给另一个专门用于生成素描图片的生成器$ G_B$，得到的结果$ G_B(G_A(u, z),z') $即为对原有的素描图片的一次重构，这里的$ z'$ 同样是噪声。接下来考虑与这一过程对偶的一个过程，首先将照片$ v $用生成器$ G_B$翻译为素描图$ G_B(v,z') $，然后再用生成器$ G_A $对生成的素描图进行翻译，得到 $G_A(G_B(v,z'),z)$ 。接下来介绍“判别”的思路，与生成器$ G_A $对应的判别器$ D_A $判断一张图片是否像一张照片，而与生成器$ G_B $对应的判别器$ D_B $则判断一张图片是否像一张素描图。对应于上面提到的对偶的生成过程，系统最终希望最小化重构误差，即希望最小化在两次迭代后得到的结果与原始图片之间的误差$|| G_A(G_B(v,z'),z)-v || $和$|| G_B(G_A(u,z),z')-u || $。
            \par
            像传统GAN训练判别器D那样，在DualGAN中，判别器D的目标仍然是将真假样本区分开。由于WGAN在许多方面优于GAN，DualGAN采用WGAN作为GAN的替代，相应的判别器$D_A$和$D_B$的损失函数定义为
            \begin{align*}
            l_A^d(u,v) = D_A(G_A(u,z)) - D_A(v)\\
            l_B^d(u,v) = D_B(G_B(v,z')) - D_B(u)
            \end{align*}
            其中：$u\sim U,v\sim V$。
            \par
            对于生成器$G$而言，$G_A$和$G_B$有共同的目标，因此二者使用同一损失函数。之前的条件图像合成方法发现，使用$L1$距离替代$L2$距离是较好的，因为$L2$经常导致图像模糊。因此，我们使用$L1$距离来衡量重构误差，添加到GAN生成器G的目标中，有
            \begin{align*}
            l^g(u,v) &= \lambda_U||u-G_B(G_A(u,z),z')||+\lambda_V||v-G_A(G_B(v,z'),z)||\\
            &\quad -D_A(G_B(v,z')) - D_B(G_A(u,z))
            \end{align*}
            其中：$u\sim U,v\sim V$，$\lambda_U,\lambda_V$是两个惩罚权重。合适的$\lambda_U,\lambda_V$是$100\sim 1000$，并且，如果$U$是自然图片而$V$不是，那么将$\lambda_U$设置的比$\lambda_V$小是有用的。
        \subsubsection{Dual GAN程序及代码}
            \par
            上面我们提到过，在DualGAN中使用WGAN来替代GAN。下面，给出DualGAN中的一些设置。我们训练$n_{critic}$步判别器$D$，然后训练1步$G$；使用mini-batch的批量梯度下降方法求解模型中的优化问题，并使用RMSProp作为求解器(Adam等基于动量的方法可能导致训练不稳定)；$n_{critic}$一般设置为$2\sim 4$，批量大小一般为$1\sim 4$，权重修剪(wight clipping)参数$c$一般设置在$0.01\sim 0.1$。DualGAN的算法伪代码如(\ref{code:DualGAN})所示
            \begin{algorithm}[H]
                \caption{DualGAN training procedure}\label{code:DualGAN}
                \begin{algorithmic}[1]
                    \State 初始化：图像数据集$U$和$V$；GAN $A$的生成器参数为$\theta_A$，判别器参数为 $\omega_A$；GAN $B$的生成器参数为$\theta_B$，判别器参数为 $\omega_B$；修剪参数$c$；批量大小$m$；循环$n_{critic}$。
                    \State 随机初始化$\omega_i,\theta_i$，$i\in \{A,B\}$。
                    \While {未达到停止准则}
                        \For {$t=1$ to $n_{critic}$}
                            \State 采样$\{u^{(k)}\}_{k=1}^m\sim U$，$\{v^{(k)}\}_{k=1}^m\sim V$；
                            \State 更新参数$\omega_A$
                            \begin{align*}
                            \frac{1}{m} \sum_{k=1}^m l_A^d ( u^{(k)},v^{(k)} )
                            \end{align*}
                            \State 更新参数$\omega_B$
                            \begin{align*}
                            \frac{1}{m} \sum_{k=1}^m l_B^d ( u^{(k)},v^{(k)} )
                            \end{align*}
                            \State $clip(\omega_A,-c,c)$，$clip(\omega_B,-c,c)$；
                        \EndFor
                        \State 采样$\{u^{(k)}\}_{k=1}^m\sim U$，$\{v^{(k)}\}_{k=1}^m\sim V$；
                        \State 更新$\theta_A,\theta_B$
                        \begin{align*}
                        \frac{1}{m} \sum_{k=1}^m l^g ( u^{(k)},v^{(k)} )
                        \end{align*}
                    \EndWhile
                \end{algorithmic}
            \end{algorithm}
            \par
            DualGAN的TensorFlow代码如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            import scipy.ndimage.interpolation
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            mb_size = 32
            X_dim = mnist.train.images.shape[1]
            y_dim = mnist.train.labels.shape[1]
            z_dim = 10
            h_dim = 128
            eps = 1e-8
            lr = 1e-3
            d_steps = 3
            lam1, lam2 = 1000, 1000
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X1 = tf.placeholder(tf.float32, shape=[None, X_dim])
            X2 = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            G1_W1 = tf.Variable(xavier_init([X_dim + z_dim, h_dim]))
            G1_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G1_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G1_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            G2_W1 = tf.Variable(xavier_init([X_dim + z_dim, h_dim]))
            G2_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G2_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G2_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            def G1(X1, z):
                inputs = tf.concat([X1, z], 1)
                h = tf.nn.relu(tf.matmul(inputs, G1_W1) + G1_b1)
                return tf.nn.sigmoid(tf.matmul(h, G1_W2) + G1_b2)
            def G2(X2, z):
                inputs = tf.concat([X2, z], 1)
                h = tf.nn.relu(tf.matmul(inputs, G2_W1) + G2_b1)
                return tf.nn.sigmoid(tf.matmul(h, G2_W2) + G2_b2)
            D1_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D1_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D1_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D1_b2 = tf.Variable(tf.zeros(shape=[1]))
            D2_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D2_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D2_W2 = tf.Variable(xavier_init([h_dim, 1]))
            D2_b2 = tf.Variable(tf.zeros(shape=[1]))
            def D1(X):
                h = tf.nn.relu(tf.matmul(X, D1_W1) + D1_b1)
                return tf.matmul(h, D1_W2) + D1_b2
            def D2(X):
                h = tf.nn.relu(tf.matmul(X, D1_W1) + D1_b1)
                return tf.matmul(h, D2_W2) + D2_b2
            theta_G1 = [G1_W1, G1_W2, G1_b2, G1_b2]
            theta_G2 = [G2_W1, G2_b1, G2_W2, G2_b2]
            theta_G = theta_G1 + theta_G2
            theta_D1 = [D1_W1, D1_W2, D1_b1, D1_b2]
            theta_D2 = [D2_W1, D2_b1, D2_W2, D2_b2]
            # D
            X1_sample = G2(X2, z)
            X2_sample = G1(X1, z)
            D1_real = D1(X2)
            D1_fake = D1(X2_sample)
            D2_real = D2(X1)
            D2_fake = D2(X1_sample)
            D1_G = D1(X1_sample)
            D2_G = D2(X2_sample)
            X1_recon = G2(X2_sample, z)
            X2_recon = G1(X1_sample, z)
            recon1 = tf.reduce_mean(tf.reduce_sum(tf.abs(X1 - X1_recon), 1))
            recon2 = tf.reduce_mean(tf.reduce_sum(tf.abs(X2 - X2_recon), 1))
            D1_loss = tf.reduce_mean(D1_fake) - tf.reduce_mean(D1_real)
            D2_loss = tf.reduce_mean(D2_fake) - tf.reduce_mean(D2_real)
            G_loss = -tf.reduce_mean(D1_G + D2_G) + lam1*recon1 + lam2*recon2
            D1_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)
                         .minimize(D1_loss, var_list=theta_D1))
            D2_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)
                         .minimize(D2_loss, var_list=theta_D2))
            G_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)
                        .minimize(G_loss, var_list=theta_G))
            clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in theta_D1 + theta_D2]
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            X_train = mnist.train.images
            half = int(X_train.shape[0] / 2)
            # Real image
            X_train1 = X_train[:half]
            # Rotated image
            X_train2 = X_train[half:].reshape(-1, 28, 28)
            X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=(1, 2))
            X_train2 = X_train2.reshape(-1, 28*28)
            # Cleanup
            del X_train
            def sample_X(X, size):
                start_idx = np.random.randint(0, X.shape[0]-size)
                return X[start_idx:start_idx+size]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                for _ in range(d_steps):
                    X1_mb, X2_mb = sample_X(X_train1, mb_size), sample_X(X_train2, mb_size)
                    z_mb = sample_z(mb_size, z_dim)
                    _, _, D1_loss_curr, D2_loss_curr, _ = sess.run(
                        [D1_solver, D2_solver, D1_loss, D2_loss, clip_D],
                        feed_dict={X1: X1_mb, X2: X2_mb, z: z_mb}
                    )
                _, G_loss_curr = sess.run(
                    [G_solver, G_loss], feed_dict={X1: X1_mb, X2: X2_mb, z: z_mb}
                )
                if it % 1000 == 0:
                    sample1, sample2 = sess.run(
                        [X1_sample, X2_sample],
                        feed_dict={X1: X1_mb[:4], X2: X2_mb[:4], z: sample_z(4, z_dim)}
                    )
                    samples = np.vstack([X1_mb[:4], sample1, X2_mb[:4], sample2])
                    print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'
                          .format(it, D1_loss_curr + D2_loss_curr, G_loss_curr))
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}
        \subsubsection{Dual GAN实验结果}
            \par
            根据这一基本思路，就可以真的来对图片做各种处理了。下面了展示这一算法得到的一些结果。这些相关结果分别与真实情况(ground truth)和其它算法得到的结果进行了比较，可以发现这一算法的确有着不错的表现。
            将DualGAN和GAN、CGAN在图片翻译数据集上进行比较。日景图片与夜景图片之间的转换结果如图(\ref{fig:DualGAN日景图片与夜景图片之间的转换})所示
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/DualGAN.jpg}
                \caption{DualGAN日景图片与夜景图片之间的转换}
                \label{fig:DualGAN日景图片与夜景图片之间的转换}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：DualGAN日景图片与夜景图片之间的转换}\\
            素描与照片之间的相互翻译结果如图(\ref{fig:DualGAN素描与照片之间的相互翻译})所示
            \begin{figure}[H]
            \centering
            \begin{subfigure}[b]{0.4\textwidth}
            \includegraphics[width=\textwidth]{images/DualGAN_picture_translation1.jpg}
            \caption{}
            \end{subfigure}
            \begin{subfigure}[b]{0.4\textwidth}
            \includegraphics[width=\textwidth]{images/DualGAN_picture_translation2.jpg}
            \caption{}
            \end{subfigure}
            \caption{DualGAN素描与照片之间的相互翻译}
            \label{fig:DualGAN素描与照片之间的相互翻译}
            \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：DualGAN素描与照片之间的相互翻译(b)}

    \subsection{Boundary Equilibrium GAN}
        \subsubsection{BEGAN模型建立}
            \par
            注：GAN以生成器G为主，D为辅，可以设计以D为主，以G为辅的网络结构。
            BEGAN\cite{2017.David}使用一个自动编码器作为判别器(在EBGAN\cite{2016.Junbo}中首先提出)。典型的GAN想要直接匹配数据分布，而BEGAN的目标是用一个来自Wassers tein距离的损失来匹配自动编码器的损失分布。这一目标是通过在典型GAN的目标中添加一个equilibeium部分实现的。equilibeium部分用于平衡D和G，和GAN相比，BEGAN有更简单的训练程序和网络结构。
            \paragraph{自动编码器的Wasserstein距离}我们希望学习残差分布而不是直接学习样本分布。首先说明一个自动编码器的损失近似一个 normal distribution，然后计算真实样本和生成样本的自动编码器的损失分布的Wassertein距离。定义$\mathcal{L}:R^{N_x}\to R$是像素自动编码器的损失
            \begin{align*}
            \mathcal{L}(v) =|v-D(v)|^\eta
            \end{align*}
            其中：$D:R^{N_x}\to R^{N_x}$是自动编码器，$\eta\in \{1,2\}$，$v\in  R^{N_x}$是一个维度为$N_x$的样本。对于足够多的像素点，如果假设各像素点的loss是独立同分布的，根据中心极限定理，图像的损失分布服从一个近似正太分布。在BEGAN中，我们使用原始图像和重建后图像的$L_1$范数作为loss。在实验中作者发现，在实验数据上，loss distribution 真的接近正态。
            \par
            给定两个正态分布$\mu_1 = N(m_1,C_1),\mu_2 = N(m_2,C_2)$，其均值为$m_1,m_2\in R^p$，协方差矩阵为$C_1,C_2\in R^{p\times p}$，二者的平方Wasserstein距离定义为
            \begin{align*}
            W(\mu_1,\mu_2)^2 = ||m_1-m_2||_2^2 + \mathrm{Tr}(C_1+C_2-2(C_2^{1/2}C_1C_2^{1/2})^{1/2})
            \end{align*}
            特别地，当$p=1$时，平方Wsaaerstein距离简化为
            \begin{align*}
            W(\mu_1,\mu_2)^2 = ||m_1-m_2||_2^2 +(c_1+c_2-2\sqrt{c_1c_2})
            \end{align*}
            \par
            我们希望在实验中优化$W^2$时，只需要优化$||m_1-m_2||_2^2$即可，而当$\frac{c_1+c_2-2\sqrt{c_1c_2}}{||m_1-m_2||_2^2}$是常数或者单调增时，真的就只需要优化$||m_1-m_2||_2^2$。这使得我们可以将目标简化为
            \begin{align*}
            W(\mu_1,\mu_2)^2 \propto ||m_1-m_2||_2^2
            \end{align*}
            值得一提的是，我们是准备优化loss分布的$W^2$距离，而不是样本分布。设定训练误差分布比训练样本分布更稳定。
            \paragraph{GAN的目标}我们求$D$来最大化$W^2 \propto ||m_1-m_2||_2^2$。设$\mu_1$是损失$\mathcal{L}(x)$的分布，这里的$x$是真实样本；设$\mu_2$是损失$\mathcal{L}(G(z))$的分布，这里$G:R^{N_x}\to R^{N_x}$是一个生成器，$z\in [-1,1]^{N_z}$是$N_z$维的随机量。
            \par
            由于$m_1,m_2\in R^+$，所以$W^2$只有2种可能
            \begin{align*}
            (a)\left\{
            \begin{aligned}
            &W(\mu_1,\mu_2) \propto m_1-m_2\\
            &m_1\to \infty\\
            &m_2\to 0
            \end{aligned}
            \right.
            \quad
            or
            \quad
            (b)\left\{
            \begin{aligned}
            &W(\mu_1,\mu_2) \propto m_2-m_1\\
            &m_1\to 0\\
            &m_2\to \infty
            \end{aligned}
            \right.
            \end{align*}
            我们按照目标选择(b)这种情况，因为最小的$m_1$自然地自动编码真实图像。设D和G的参数分别为$\theta_d,\theta_g$，通过最小化D和G的损失$\mathcal{L}_D,\mathcal{L}_G$来求解参数
            \begin{align*}
            & \mathcal{L}_D = \mathcal{L}(x;\theta_d) - \mathcal{L}(G(z_D;\theta_g);\theta_g)\\
            & \mathcal{L}_G = \mathcal{L}(G(z_G;\theta_g);\theta_d)
            \end{align*}
            其中：$z_G,z_D$是来自$z$的样本。下面，将$G(\cdot,\theta_g)$简记为$G(\cdot)$，将$L(\cdot,\theta_d)$简记为$L(\cdot)$。
            \par
            和WGAN相比，上面的目标主要有两方面的不同：\ding{172}BEGAN是在假设的正态损失间构建分布；\ding{173}BEGAN不需要k-lipschitz假设。
            \paragraph{Equilibrium}在实践中，保持D和G的平衡是至关重要的，当
            \begin{align*}
            \mathbb{E}[\mathcal{L}(x)] = \mathbb{E}[\mathcal{L}(G(z))]
            \end{align*}
            时，我们认为二者是平衡的。如果我们生成的样本不能被D辨识真假，那么真假样本的误差分布应该相同。这个观点允许我们通过分配G和D来平衡the effect，因此，不存在赢的一方。
            \par
            当存在完美的平衡时，如果$m_1-m_2\to 0$，则$\frac{c_1+c_2-2\sqrt{c_1c_2}}{||m_1-m_2||_2^2}$变得不稳定。通过引入一个超参数$\gamma\in [0,1]$来解决这个问题
            \begin{align*}
            \gamma = \frac{\mathbb{E}[\mathcal{L}(G(z))]}{\mathbb{E}[\mathcal{L}(x)] }
            \end{align*}
            \par
            在我们的模型中，D有两个主要的目标：\ding{172}自动编码真实图像；\ding{173}判别真实图像判别真实图像。$\gamma$部分能够平衡这两个目标，较小的$\gamma$导致低的图像多样性(diversity)，因为D集中更多的力量去编码真实图像。我们称$\gamma$为 diversity ratio。
            \paragraph{Boundary Equilibrium GAN}BEGAN的目标是
            \begin{align*}
            & \mathcal{L}_D = \mathcal{L}(x) - k_t\mathcal{L}(G(z_D))\quad& \theta_d\\
            & \mathcal{L}_G = \mathcal{L}(G(z_G))\quad& \theta_g\\
            & k_{t+1} = k_t + \lambda_k(\gamma\mathcal{L}(x)-\mathcal{L}(G(z_G))) \quad& \text{for each training step t}
            \end{align*}
            我们使用比例控制定理( Proportional Control Theory)来保持等式$\mathbb{E}[\mathcal{L}(G(z))]=\gamma \mathbb{E}[\mathcal{L}(x)]$。这里通过变量$k_t\in [0,1]$来决定在梯度下降时，将多少“注意力”放在$\mathcal{L}(G(z_D))$。
            \par
            初始化$k_0 = 0$，$\lambda_k$随着$k$的增加而增加。在主要的学习部分，$\lambda_k$是基于$k$的学习率。本质上，这种平衡可以被视为一个闭环反馈控制形式，其中，在每一步调整$k_t$以维持方程$\gamma = \frac{\mathbb{E}[\mathcal{L}(G(z))]}{\mathbb{E}[\mathcal{L}(x)]}$。
            \par
            在早期的训练过程中，G趋于产生易于自动编码器重建的数据，因为生成数据接近于0，真实数据分布还没有被准确的学习。在整个训练过程中$\mathcal{L}(x) > \mathcal{L}(G(z))$是由平衡约束来实现的。和传统的交替优化G和D的GAN相比， 我们提出的方法在训练时不需要稳定。在训练时使用Adam方法，并设置批量大小为16。
            \par
            通过Equilibrium的概念，我们获得了一个度量收敛性的全局量，可以设计收敛过程是寻找带$|\gamma\mathcal{L}(x)-\mathcal{L}(G(z_G))|$的 closest reconstruction $\mathcal{L}(x)$，表示为
            \begin{align*}
            \mathcal{M}_{global} = \mathcal{L}(x)+ |\gamma\mathcal{L}(x)-\mathcal{L}(G(z_G))|
            \end{align*}
            这个收敛性度量$\mathcal{M}_{global}$可以用于确定网络什么时候达到最终状态，或者判定模型是否崩溃。

        \subsubsection{BEGAN模型程序}
            \par
            BEGAN的TensorFlow程序如下
            \begin{lstlisting}[language = Python]
            import tensorflow as tf
            from tensorflow.examples.tutorials.mnist import input_data
            import numpy as np
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            import os
            mb_size = 32
            X_dim = 784
            z_dim = 64
            h_dim = 128
            lr = 1e-3
            m = 5
            lam = 1e-3
            gamma = 0.5
            k_curr = 0
            mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)
            def plot(samples):
                fig = plt.figure(figsize=(4, 4))
                gs = gridspec.GridSpec(4, 4)
                gs.update(wspace=0.05, hspace=0.05)
                for i, sample in enumerate(samples):
                    ax = plt.subplot(gs[i])
                    plt.axis('off')
                    ax.set_xticklabels([])
                    ax.set_yticklabels([])
                    ax.set_aspect('equal')
                    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')
                return fig
            def xavier_init(size):
                in_dim = size[0]
                xavier_stddev = 1. / tf.sqrt(in_dim / 2.)
                return tf.random_normal(shape=size, stddev=xavier_stddev)
            X = tf.placeholder(tf.float32, shape=[None, X_dim])
            z = tf.placeholder(tf.float32, shape=[None, z_dim])
            k = tf.placeholder(tf.float32)
            D_W1 = tf.Variable(xavier_init([X_dim, h_dim]))
            D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            D_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            D_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))
            G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))
            G_W2 = tf.Variable(xavier_init([h_dim, X_dim]))
            G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))
            theta_G = [G_W1, G_W2, G_b1, G_b2]
            theta_D = [D_W1, D_W2, D_b1, D_b2]
            def sample_z(m, n):
                return np.random.uniform(-1., 1., size=[m, n])
            def G(z):
                G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)
                G_log_prob = tf.matmul(G_h1, G_W2) + G_b2
                G_prob = tf.nn.sigmoid(G_log_prob)
                return G_prob
            def D(X):
                D_h1 = tf.nn.relu(tf.matmul(X, D_W1) + D_b1)
                X_recon = tf.matmul(D_h1, D_W2) + D_b2
                return tf.reduce_mean(tf.reduce_sum((X - X_recon)**2, 1))
            G_sample = G(z)
            D_real = D(X)
            D_fake = D(G_sample)
            D_loss = D_real - k*D_fake
            G_loss = D_fake
            D_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(D_loss, var_list=theta_D))
            G_solver = (tf.train.AdamOptimizer(learning_rate=lr)
                        .minimize(G_loss, var_list=theta_G))
            sess = tf.Session()
            sess.run(tf.global_variables_initializer())
            if not os.path.exists('out/'):
                os.makedirs('out/')
            i = 0
            for it in range(1000000):
                X_mb, _ = mnist.train.next_batch(mb_size)
                _, D_real_curr = sess.run(
                    [D_solver, D_real],
                    feed_dict={X: X_mb, z: sample_z(mb_size, z_dim), k: k_curr}
                )
                _, D_fake_curr = sess.run(
                    [G_solver, D_fake],
                    feed_dict={X: X_mb, z: sample_z(mb_size, z_dim)}
                )
                k_curr = k_curr + lam * (gamma*D_real_curr - D_fake_curr)
                if it % 1000 == 0:
                    measure = D_real_curr + np.abs(gamma*D_real_curr - D_fake_curr)
                    print('Iter-{}; Convergence measure: {:.4}'
                          .format(it, measure))
                    samples = sess.run(G_sample, feed_dict={z: sample_z(16, z_dim)})
                    fig = plot(samples)
                    plt.savefig('out/{}.png'
                                .format(str(i).zfill(3)), bbox_inches='tight')
                    i += 1
            plt.close(fig)
            \end{lstlisting}
        \subsubsection{BEGAN实验}
            \par
            关于BEGAN模型更详细的网络设置可以参考BEGAN原文，也可以参考上面的BEGAN程序。下面，介绍一些BEGAN的实验结果。
            \paragraph{图像多样性和质量}作者将BEGAN和EBGAN进行了对比，图(\ref{fig:BEGAN的Figure2})给出了一些具有代表性的生成图像
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/BEGAN_Figure2.jpg}
                \caption{BEGAN的Figure2}
                \label{fig:BEGAN的Figure2}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：BEGAN的Figure2}\\
            图像大小(分辨率)为$128\times 128$。尽管像常见的那样：训练高分辨率的图像会使图像的清晰度下降，但这也许可以通过超参数来进行调节。这可能是目前为止Stack GAN之外，第2好的分辨率结果。Stack GAN在花和鸟数据集上有$256\times 256$的分辨率。
            \par
            我们可以从生成的图像中看到不同的姿态、表情、性别、肤色、光照和面部毛发等，然而并没有眼睛。但是，值得一提的是，由于BEGAN和EBGAN在不同的训练集上进行训练，因此一般不对他们进行直接比较。
            \par
            在图(\ref{fig:BEGAN的Figure3})中，我们比较了不同参数$\gamma$带来的效果。当$\gamma$在一定范围内时，模型表现出很好的性能，仍然保持一定的图像多样性。当$\gamma$较小时，生成的脸看起来相似，随着$\gamma$的增加，图像多样性增加。这似乎与其它文献中“多样性与图像质量无关”的论断相矛盾。
                \begin{figure}[H]
                \centering
                \includegraphics[width=8cm]{images/BEGAN_Figure3.jpg}
                \caption{BEGAN的Figure3}
                \label{fig:BEGAN的Figure3}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：BEGAN的Figure3}
            \paragraph{Space continuity} 为了估计(评价)BEGAN中G的收敛性，我们使真实图像$x_r$和生成$G(z_r)$相一致。用Adam来做，就是找一个$z_r$，最小化$e_r = |x_r - G(z_r)|$。求真实数据的映射并不是模型的目标，但是它提供一个测量生成器G生成能力的方法。通过将$z_r$埋藏在两个真实图像中，我们验证，该模型会概括图像的内容而不是简单的记住图像。
            \par
            图(\ref{fig:BEGAN的Figure4})显示$z_r$在$128\times 128$的分辨率之间的插值。这些图像并不是训练数据的一部分。第一列和最后一列是需要表示和插值的真实图像，紧邻它们的图像是它们相应的近似值，而两列之间的其他图像是线性插值的结果。我们将结果和其它模型进行比较，选用ALI插值的$64\times 64$分辨率和Pixel GNN插值的$32\times 32$分辨率作为比较对象，对不同的数据集进行训练。此外，图(\ref{fig:BEGAN的Figure4})d展示了图像和其镜像的插值结果。
                \begin{figure}[H]
                \centering
                \includegraphics[width=12cm]{images/BEGAN_Figure4.jpg}
                \caption{BEGAN的Figure4}
                \label{fig:BEGAN的Figure4}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：BEGAN的Figure4}
            \paragraph{收敛性度量和图像质量}收敛性度量$\mathcal{M}_{global}$用于度量BEGAN的收敛性，像在图(\ref{fig:BEGAN的Figure5})中看到的那样，$\mathcal{M}_{global}$度量和图像精度(fidelity)有很高的相关性。我们也可以从plot中看出，模型收敛性是较快的，这似乎证明了，快速收敛会导致像素损失。
                \begin{figure}[H]
                \centering
                \includegraphics[width=10cm]{images/BEGAN_Figure5.jpg}
                \caption{BEGAN的Figure5}
                \label{fig:BEGAN的Figure5}
                \end{figure}
            % \textcolor[rgb]{1 0 0}{todo:图片：BEGAN的Figure5}
            \paragraph{Equilibrium for unbalanced networks}为了测试平衡技术的鲁棒性，作者进行了一个实验，图(\ref{fig:BEGAN的Figure6})展示了这个结果。令人吃惊的是，低纬度的$h$对图像多样性和图像质量的影响不大。
                \begin{figure}[H]
                \centering
                \includegraphics[width=6cm]{images/BEGAN_Figure6.jpg}
                \caption{BEGAN的Figure6}
                \label{fig:BEGAN的Figure6}
                \end{figure}


    % \subsection{Generative Adversarial Parallelization}
    % \subsection{Auxiliary Classifier GAN}
    % \subsection{Energy Based GAN}
    % \subsection{DiscoGAN}


% \bibliography{part-MLDL-chap-DeepLearn}%bib文件名称

